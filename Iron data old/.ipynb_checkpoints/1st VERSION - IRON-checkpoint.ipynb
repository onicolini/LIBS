{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import stdout\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from math import sqrt\n",
    "from scipy.signal import savgol_filter\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4094)\n",
      "(4094,)\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#x_df = pd.read_csv('data_with_avg_intesities_reduced.csv', sep = ',')\n",
    "x_df = pd.read_csv('data_with_avg_intesities_reduced.csv', sep = ',')\n",
    "values = x_df.values\n",
    "#wl=x_df.columns.values\n",
    "#print(wl.shape)\n",
    "\n",
    "#print(values)\n",
    "#print(type(values))\n",
    "print(values.shape)\n",
    "print(values[1].shape)\n",
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188.1951 188.2601 188.325  ... 440.6714 440.7245 440.7775]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOydd5xU1fXAv2dmO70sHQUVCxBFQMTeexJNYowm+UmqsaWoKZqiJtFYYotdVIK9G0FFERVFlCq9s3SWhd1le512f3/Mm92Znfdm3puZ3Zld7vfzWZi577Y3u3PPu+ece44opdBoNBqNxgxXuieg0Wg0msxFCwmNRqPRWKKFhEaj0Wgs0UJCo9FoNJZoIaHRaDQaS7LSPYFE6d+/vxoxYkS6p6HRaDSdhv79+zN79uzZSqnz7bbptEJixIgRLF26NN3T0Gg0mk6FiPR3Ul+rmzQajUZjiRYSGo1Go7FECwmNRqPRWKKFhEaj0Wgs0UJCo9FoNJZoIaHRaDQaS7SQ0Gg0Go0lWkhoNJoDmtWrV9PU1JTuaWQsWkhoNJoDltLSUt566y3eeeeddE8lY9FCQqPRHLB4vV4Aampq0jyTzEULCY1Go9FYooWERqM54NFpnK3ptAH+NBqNJlmavH5WeQfhb3CneyoZixYSGo3mgGX1tr0cnb2X8qru6Z5KxqLVTRqN5oClzucDwCWBNM8kc9FCQqPRmKKUorm5Od3TaFeqAkHhoJA0zyRz0UJCo9GYMm/ePO666y7q6+vTPZV2o7K0AgCFNlxboYWERqMxZc2aNQBdWkgo45yE3kdYo4WERqOJSZd2D+3Ct5YqtJDQaDSmNDY2AnRtu4RqYPIJrzGgz650zyRjiSskRCRPRBaLyEoRWSsifzfKp4vINhFZYfyMM8pFRB4WkSIRWSUi48P6miIim42fKWHlE0RktdHmYRHRuz+NJs2EhERXVjf1UZvIzvZw9IgF6Z5KxmLnnEQzcKZSqk5EsoH5IvKBce0PSqk329S/ABhl/BwPPAEcLyJ9gduAiQQ3eV+LyEylVKVR5ypgITALOB/4AI1GkzYaAm5y8VPd6E33VNqN3EA9tfRAtNrJkrg7CRWkznibbfzE+kgvBp432i0EeovIYOA8YI5SqsIQDHOA841rPZVSC1RQ+fk8cEkS96TRaFJAcyC4oS+p9qR5Ju1HDQVcLdN5L/fb6Z5KxmLLJiEibhFZAZQSXOgXGZfuNFRKD4pIrlE2FAhX8O02ymKV7zYpN5vHVSKyVESWlpWV2Zm6RqNJkIDh81NS35jmmbQfte5uAKzKOjrNM8lcbAkJpZRfKTUOGAZMEpGxwC3AkcBxQF/gT0Z1M3uCSqDcbB5TlVITlVITCwsL7Uxdo9EkimEabKqpTvNE2o8cv47ZFA9H3k1KqSrgM+B8pVSJoVJqBv4LTDKq7QaGhzUbBuyJUz7MpFyj0aSR1ie1rutH4m5x7+2695gsdrybCkWkt/E6Hzgb2GDYEjA8kS4B1hhNZgJXGl5Ok4FqpVQJMBs4V0T6iEgf4FxgtnGtVkQmG31dCcxI7W1qNBqnCAFyc+sIqK4b18gXujctIyyx4900GHhORNwEhcrrSqn3RORTESkk+PGuAK426s8CLgSKgAbgpwBKqQoR+SewxKj3D6VUhfH6GmA6kE/Qq0l7Nmk0aWbMIQs5ZNgalu84Kt1TaTc8yvDc0t5NlsQVEkqpVcCxJuVnWtRXwHUW16YB00zKlwJj481Fo9F0HP1672Urh5Ln6bqpPcWvdxLx0CeuNRqNKS/kXcnf5F6aXE3pnkq74Qr40z2FjEcLCY1GY8p21wgAmrrwMpHlD+qZtLbJmq7729doNEkR0sBkd2E30a4cuzBVaCGh0Whi4gp0Xe+mkCjUJglrtJDQaDQxCXRpZYxWN8VDCwmNRhMTj6frRoHV4iE+WkhoNJqYuH3aA+hARgsJjUZz4KKNEXHRQkKj0cSmS2tktJSIhxYSGo0mNgfEOnpA3GRCaCGh0WhMka69hQDQGelsoIWERqOJSVc+cKb0BiIuWkhoNJqYSIoW0s8//5x77rknNZ1pOgwtJDQaTUxUipaJuXPn0tiYYalQw7YS9957L/Pnz0/jZDITLSQ0Gk0cuq6+Kdzu0tDQwMcff9yu4906Yw2zVpe06xipRgsJjUZzwNNRYvD5BTu49qVlHTRaatBCQqPRxMRHgF27diXdjz8DrcSqg11fu0sz2fg6dMxksZPjOk9EFovIShFZKyJ/N8pHisgiEdksIq+JSI5Rnmu8LzKujwjr6xajfKOInBdWfr5RViQiN6f+NjUaTTK89957SffhNvxNm5ub8Xg8SffXHtSr7Hbt/9LcVVyavbJdx0g1dnYSzcCZSqljgHHA+SIyGbgHeFApNQqoBH5u1P85UKmUOgx40KiHiIwGLgfGAOcDj4uI28id/RhwATAauMKoq9FouiB33XUXDz30ULqnAUSfBekm3nYfM9fduUKvxxUSKkid8Tbb+FHAmcCbRvlzwCXG64uN9xjXzxIRMcpfVUo1K6W2AUXAJOOnSCm1VSnlAV416mo0mgxAEFSKD0s0NDSktD9N+2HLJmE88a8ASoE5wBagSikVUq7tBoYar4cCuwCM69VAv/DyNm2sys3mcZWILBWRpWVlZXamrtFokqQukE1xU06HjaeUori4uKNG66BxOi+2hIRSyq+UGgcMI/jkf5RZNeN/M0uQSqDcbB5TlVITlVITCwsL409co9EkTEgVowqguCp15xuqA3nUK2uhs2rVKp5++mnWrVuXsjEt0TIiLo68m5RSVcBnwGSgt4hkGZeGAXuM17uB4QDG9V5ARXh5mzZW5RqNJkPo5Uqdeuhz7yHM9hxheT2kJdi/f3/KxrSm9Rl1xMiv6dVrbweM2bmw491UKCK9jdf5wNnAemAucKlRbQoww3g903iPcf1TFVRozgQuN7yfRgKjgMXAEmCU4S2VQ9C4PTMVN6fRaFJDKlxFu3ffz5Ah6/l27jq+m7s6/pgdEjSqVQEyfPg6jj5mTgeM2bnIil+FwcBzhheSC3hdKfWeiKwDXhWRO4DlwLNG/WeBF0SkiOAO4nIApdRaEXkdWAf4gOuUUn4AEbkemA24gWlKqbUpu0ONRpMCkl+wh4z/ml0cHFdP4A0o1vgGcWqg/YVEeFyqrRxKIaXtOt6nx41hREXnOnEdV0gopVYBx5qUbyVon2hb3gR836KvO4E7TcpnAbNszFej0XQQqT5m9gcexi9ZXM07Met9XFTL2Ky9fLplKIeM2E5+fj4DBw5M8WyChIuhv8m9DFQlLW6a7cGmglFsKhjVjiOkHn3iWqPRxMWVgp2EX+woLiBQF7RJlO7YxPTp03niiSeSHtuKtoJwnwxut7E6K1pIaDSamBw5+gtG9V7fYeOVe4OHzepy8ztgtMwLFZJp2BPtGo3mgOagQ9akrK/s7EaUivF8qkInktt/AQ8Zx7UnrDVaSGg0mpiUU0jflqALyTP5hFCghrvMKxgrdmOzu911HalKqNSV0eomjUYTkwflZv6X990OH9fv74CdhMlupWNcbzsPWkhoNJq4rHOnLubm73mY+/mT5fXh7GHkIUuZmLsjZWM64dW39TGtcLS6SaPRWKDCXqXuqb5EhlJiHp4NgLHDlzJwWBEeTz6DB2+ivq5vysZuS9sosAAbVy+H7+kYoyH0TkKj0WQU9fTlYW6i2Z1Nfn4d/Qt3tvuY4UJQa5si0TsJjUYTF7Mn7vbi814ns0hOpFfPJvqzlRyaO2xs0MbstmghodFo4tKRaT5dhoJDAb+TJwFob7N5RwpBp/h8Pnbs2MGhhx6alvG1ukmj0WQYwQW7Z8+OyxnT0bmunfDxxx/zwgsvsHv37rSMr4WERqMxJV3LZsgF1e32xamZPGKygXC7Myv/dihkerqy+WkhodFoMorQwt1I+4flMFMyjf3GJ+0+rhMCCsoDBWkbXwsJjUaTUYTsA+9Kxx/gA8jrWZ2Wca34ZG8u870j2VzelJbxtZDQaDQZRbM7EL9SyohWqj3M7ztw/Ph4Gyu4JHctG/aVp2V8LSQ0Go0Fmevx054sl4npnkIE3VTQFlHZqHcSGo1G08HuqJ1BEAbn6KurTcvoWkhoNJoDmMx1fQ0ROgFe35ChOwkRGS4ic0VkvYisFZHfGuW3i0ixiKwwfi4Ma3OLiBSJyEYROS+s/HyjrEhEbg4rHykii0Rks4i8JiI5qb5RjUbTSVAduXBn/k7ikG5bmHjcO/RSmWuT8AE3KaWOAiYD14lIKCTkg0qpccbPLADj2uXAGOB84HERcYuIG3gMuAAYDVwR1s89Rl+jgErg5ym6P41GkyBmZwg6gm7dKyyvKaXYu3dvysZK1z064ciDl+LKb2ZY7uq0jB9XSCilSpRSy4zXtcB6iBHCES4GXlVKNSultgFFwCTjp0gptVUp5QFeBS4WEQHOBEKZSJ6Dds1FrtFobNChD/RhZLm9ltdWrFjBk08+yaZNmzpwRunly9yT+Jm8QlVut7SM78gmISIjgGOBRUbR9SKySkSmiUgfo2wosCus2W6jzKq8H1CllPK1KTcb/yoRWSoiS8vKOu7Ivkaj6Ti2M9Ly2r59+wAoL0+t6iWTw3KsyBkPwH5XrGfz9sO2kBCR7sBbwO+UUjXAE8ChwDigBLg/VNWkuUqgPLpQqalKqYlKqYmFhYV2p67RHLDU1tbi8yUW3iJdqpgVMVxQ/X4/AIFAR56laH8qKip45ZVX8HrNdlHBZTpXZXfspCJGj4OIZBMUEC8ppd4GUErtU0r5lVIB4GmC6iQI7gSGhzUfBuyJUV4O9BaRrDblGo0mSe6//37efPPN+BU7CTt2BYPc7di5K05NZ6Q7CuyHH37Ixo0b2bp1q3WlNCW6sOPdJMCzwHql1ANh5YPDqn0HWGO8nglcLiK5IjISGAUsBpYAowxPphyCxu2ZKhjNay5wqdF+CjAjudvSaDQhNmzYkO4ppIx15cFd0dd7GlPToaHHyGR1U0ix4sXaVtOe2MkncRLwf8BqEVlhlP2ZoHfSOIJ3sB34FYBSaq2IvA6sI+gZdZ1Syg8gItcDswE3ME0ptdbo70/AqyJyB7CcoFDSaDRJ4lUu3HQd1UwtQn9gv79r3NO+ffsoKiqitCHAJl9/mrx+68oxLrUncYWEUmo+5naDWTHa3AncaVI+y6ydUmorreoqjUaTIl5qnsChrsSMvNJOOa6TIRRGXPnbP4x4KmlctYrtl/0Annglonzq1Kn4/X7KpA+HZ1Xy1bqdHDN2tEUv6UGfuNZoujhbAv3TPYWUkZtVz5FHfU62q2NTmiZL6aefs2fI4KjykCHeZ3gJ7Iuxk3ClyVivhYRG00VRSnG4u5Seklg4h3AzaboNuyGOHzaPLYXDGNf/qxT12DE7pLn7qvji1FOjyvcH8lnjG0jA+Hxra6zjM7mUFhIajSbFnJi9g2/mrEu6n0xRNy3qdjKPyE0UFYxJ91Qc4bGwC9WqPMZm7cOFj/79d9DUFL1DUhL67NPzO7BjuNZoNJ2YHEmTxbMdqHP3BqDJ3TMl/XXUslvnq4fc6OxyI9yVAJw48lOGDd1E/cYBln2kS0zrnYRG00XpagfOAMRYKl0pWjIDHaRG87jdMa83FWRzD38lH2sng3Qp/PROQqPpoiil6NdvJ7W1/dI9laTxeDw0NaU+VLZ00PO5O+ABcqPKCwoq6dt3D691u4zVMpZv5O/ukPk4QQsJjaYLM3rM5zQ3FwD/dtw2M6wQQaa/8BJ7du2AcYMAUCl6ru6o0CPNWdl8MOb4qPJjx8/C5QqAJxjTNC+Q3zETcoBWN2k0XZRAILgC5uY2pHkmybNn1w7jlXFOAmUR58gZypASrcbh9mHJwaPZ0T/aBfYz11lcxzPtOnayaCGh0XRRMsNpNbWEnvwloFi+fHl6J+MAH+aG9mflaqpaAmhDQJkdEkzvb1ILCY2mixJQih/JW/yP76V7Kimn2a1aDqIlR8co1XJtLrV+EyERcj/W3k0ajSalBIxF9E35YULtI8NyZArBmQREsXBtjIipzrprd3r3KumYgdoBLSQ0mi5KIIWhpTPlxHULImwtS4WtJWTjaN/ndJfbnmeW259hnzNaSGg0XRaPx5OyvjLlxHU4DakI8tdB7k12P71MzLmthYRG00VR6Yot3Q64XD6ysyNzSPhcqVi+nAm/zzaWMuLm99mxvz4FY7diRwinKeeQFhIaTVfF62mfcNpffPYZ99x1V7v0bcWYsZ8y+YTWDHt9+haT67IOhmcXp/ujmYu3cdbOpSzfUZn02JHElwDpUvlpIaHRdFH83vYJp/3JZ5/R2NyxoboX9J7IjTyKGI/Tr8qVHFO4NGX9211+j1zwNsMPV8jiz531b3OATFTraSGh0XRRvClMzFPiHppw26KiIm6//fakxn9RfsY+GRzx6L+6W/QJZqe0rt32FufGnGA8rIZa+zuJL+5uFW7WZJ5wCGEnx/VwEZkrIutFZK2I/NYo7ysic0Rks/F/H6NcRORhESkSkVUiMj6srylG/c0iMiWsfIKIrDbaPGzk1dZoNEkQ8KbOcJ0MCxYsSFlfgbClwZ2GhdWbFQzU5wnYt/cUL55HU1bnDbZoZyfhA25SSh0FTAauE5HRwM3AJ0qpUcAnxnuAC4BRxs9VwBMQFCrAbcDxBFOV3hYSLEadq8LanZ/8rWk0BzYqkIGuMkkjFq8Tw+kn5MkJhrtrDNgPCbL90BFxZ9oaFiTzfmdxhYRSqkQptcx4XQusB4YCFwPPGdWeAy4xXl8MPK+CLAR6i8hg4DxgjlKqQilVCcwBzjeu9VRKLVDBBLbPh/Wl0XQ4zc3N1NXVpXsaSdPsSyy2UdnmbSyYHJ1FLVG21mfxXNPElPUXwp9C7y27S7MYJ6JdjRW2+/Zm24mjmnnCIYQjm4SIjACOBRYBA5VSJRAUJEAoW8ZQYFdYs91GWazy3SblZuNfJSJLRWRpWVmZk6lrNLZ5/PHHue+++9I9jaRRCYat+OrhZ6nqFZ0gJ1FWl3qYkpc6I3OIJlfHq3CqJI/qvG5UOJC/fhtCwo7BOl1nKGwLCRHpDrwF/E4pVROrqkmZSqA8ulCpqUqpiUqpiYWFhfGmrNEkRHV1dbqnkBICCaqbyvKERSdMJlVPt/2x/9QdDxXjXVsq6j088NFGm5+DPdXViuFH8Mrx57C5V3REVysas3NY0X2s7fqZhi0hISLZBAXES0qpt43ifYaqCOP/UqN8NzA8rPkwYE+c8mEm5RpNWtiterFWDUr3NJIm4EvsSbvJNBJp4qhUngJzYIb46/9W8sZny5i3OYbWweHUfP27BafR3X761I/GTKY0xzotaaZjx7tJgGeB9UqpB8IuzQRCHkpTgBlh5VcaXk6TgWpDHTUbOFdE+hgG63OB2ca1WhGZbIx1ZVhfGk2H83Hz4SxpHh6/YobjdWBcDafZ37FnIBImjhNkz52LOS9nI/uLd8Ss54Ru3YK7om49q2y3qTfJbd2WdEd6jYWdncRJwP8BZ4rICuPnQuBu4BwR2QycY7wHmAVsBYqAp4FrAZRSFcA/gSXGzz+MMoBrgGeMNluAD1JwbxrNAY0Tm4S3pATP7mIA/NmpXaqGuUoYPHhjVPnWrc6juIbr7quzYj/Nd68PRl6tWxXfHmL7EJuxK8pW9gWwS+zv6Mw2Nuk+YBfXoqKUmo+1gDvLpL4CrrPoaxowzaR8KdB5lXaaLsWhrnL6uVIbmyctBOyrjb667Acol3D65/ZPEtfV1ZGXl0dWVuxl5PBDl+MZFL07ef7555M6ZLeg96SE24ZIVBGmsL/wZ+c0AN0THCn96BzXGk0bTsnZlu4ppASf3/5CNvesMwE4HajOG8Drk04myxW5sAcCAVxhQfXuu+8+Ro8ezWWXXRaz7497nsm7cqHtuaSKiqwCdgwdRq/Scss6IY2VU2HhpH7qYi6lZ0ehhYRG04a8vBpychvjV8x0AokZrlcMP5La/G5At4hyr89Pbk6khnrdunVx+9uSfYhp+XzPiITmZ5dlRx/Ohr6H0a/xS8s6TsNyJFa7c6OFhEbThuMmdQ2/Cb+D0BGRmC+BAZ8PcrIjy5J4SD45Z3vijW3g6hYMSyLdY9kPQkLP7o0YSYpSHLc73XaHWOgAfxpNF0WpxHYS3V3mMZ98Pj8+X6Sdw5W5axsuY0HvRizbTGixd3gjaTnYpkOFazSaFOLzJ+YCm997r2m5t7mJO+64I4Ee07O4hZb9vJjbHRX2r8YMLSQ0mjZ4yaKRvHRPI2lUivMlNzd58CrB5fKRk5N8fumevfY5bpPQHcU4HOg03nS7bZwyeEembRIaTRtu5W52ykjMn6c7D6mOAtvY1Ey2KMaM/ZTevfexaeMJVFcPTLi/Y475KIFWzldTvUtIDi0kNJo27JSR6Z5CSgg48OW3Q2NzMDLuzN4XMVsuot8RZXzb/7+E+3uYm6IPWqWQkOupshUZL4Mf5cNYsGABubm5jB8/Pn7lFKHVTRpNF8WfoAusFU1NwXMTs+UiAPZLIf/NuipuO6vld5GcmMAsnO8LJMZ5EdXyf3r1TnbHnz17NjNnzkzt4HHQOwmNposScJBv4eMjJ+B3ubkdLBMy+5oaycurTcncQjQ0NFBQYD8suXJgROgcewP7KKA6kNvitdVR6J2ERtNVcWC4Lho4nG2FQ2LWqWtq4LhJ7yQ7qwjefPPNlPbnlETPJ6R6mbarEOvlaqaHhYtye6GFhEbTRQmkOOR3wONlIc5VRBLj4Nn+6tTuTMxI5YIeuhezUBub99Vy/L8+pqw2MpxJqsJypGtnpIWERtNFSdQF1mox8jTV84jclPiETPigsr+j+gndkY3VNRXL+NOfbWRk1To+WV+SQGvrSYbvdvr0KU7IdTgZtE1Co+miBFJ8TsLjS11O6RCDAqUtr/ft2xcRQNAcB8/TzqLwOcJMTVW4+iMKCjw0ff0FTBrhrEObk635hoc8YiUGTT16J6HRJIDX6+X222/nyy+tg8elG5Vi/YTXl3pdeF9aQ7I/8cQTPPbYY47aL168mEASXlziMCxHLNWR8gbvpWm/852EXdvIY3ID98stjvtPBi0kNJoEaGwMRomdN29emmdijXKQGMcOfn+iQsJ6Yc3PqUuqr1mzZrFq1SrTmi3nJDpIm+93BceLDofSuc9paCGh0SRAQ11wcWtuztxUn4EURyr1J6xusl4AJ4+enXRfW7ZscdhHNKn4pEqzC5h7xLFUNLcNM5+5AsAOWkhoNAlQWWpk3k3xQpxKVIpNCD5fancmACXZgxzVN/u0m/faM+QqpfjVC0v5aot1EiLbmKz7K8YeycZBB7PmoBGOu8vcvyIbQkJEpolIqYisCSu7XUSK2+S8Dl27RUSKRGSjiJwXVn6+UVYkIjeHlY8UkUUisllEXhORnFTeoEbTLhiHujL5y+1PseHaKhbU5s2bE95RPZV3taP6ZjaBtRXm0rClrrGg13v8zF67j188Z5bzOvmn/d4F1QAUdm+n1LdpeiCxs5OYDpxvUv6gUmqc8TMLQERGA5cDY4w2j4uIW0TcwGPABcBo4AqjLsA9Rl+jgErg58nckEbTEdTW+xDxo1TmOggqByeu7WAVevyll17ihdfeSulYbREjN4aZfaGx2Z6tRIDRldvI97RGsE2lvSJ0EjpbIg3pqUtfmh7iCgml1DygwmZ/FwOvKqWalVLbgCJgkvFTpJTaqpTyAK8CF4uIAGcCoWOXzwGXOLwHjabDKSsrZ+gpCzjoUHOjaUaQsNOP+aLmt9hJeJWLRUWlptfij2R3kTb3Qpo7YQw1OcGwHl9//TU1Ndbuof7GRiYNLucnpXMSmGnb2UTPu+XTCTg/xGjPEy09to1kbBLXi8gqQx3VxygbCuwKq7PbKLMq7wdUKdVyNDRUboqIXCUiS0VkaVlZWRJT12iSo85XxV/lPt4aarbJzgxUgk+wVktRwCIdarYE6CZNpteKi4tjPkmLrQit1mzsPoqsQ6C2tpZ3332Xl19+ubVv4//QAhzwBnccVUP6RfVjV1jZqeVkdxLaIWWyaTtRIfEEcCgwDigB7jfKze5VJVBuilJqqlJqolJqYmFhobMZazQpJNBUCcAW12Fpnok1KsVRYAOxLOEWgfeefvrpmKKqnNbvcd7QfeQOcb4jyaWBZq+f5b4hrCkPf4qPHNnXHLQV+N3uqD5si6oYFf0tWzfngi+mYEmzBElIoaqUanEnEJGngfeMt7uB4WFVhwF7jNdm5eVAbxHJMnYT4fU1mozFW1MPQzLbcJ3ITqJp40br/iwMp2PGfsLW7cdYtImdz8Eb5qfy0GG/sqwnGJ+1yYKpgMXb9nFs1h7KvN2sx2puYmv/IQys3h/ZcappJwNzp4rdJCKDw95+Bwh5Ps0ELheRXBEZCYwCFgNLgFGGJ1MOQeP2TBX8q5sLXGq0nwLMSGROGk1H4vGH1CsZrChQzncS2y62NgkGLGwStX2zOeLwhabXnKYHTZQ6bzO5ufUWaq/gJCq9io/GTGLWuMlJj5f6A3rx+0vXA0ncnYSIvAKcDvQXkd3AbcDpIjKO4Ly3A78CUEqtFZHXgXWAD7hOqeAeVUSuB2YDbmCaUmqtMcSfgFdF5A5gOfBsyu5Oo2knMlg0tJDIolJ02KF4XeYtlYUl/M/yAKfmfWbhcaLa37snEGDHirlMOv5t9u45JHzoCGrqKoB8avPzTTpxGJbDZHe0uGCivfl2MuIKCaXUFSbFlgu5UupO4E6T8lnALJPyrQS9nzSaToMy9uAdFfIhERLJcf31xIkELBb1WCe4t7jNbTMHj1/A/7KTf3IPLc6mcxOorSphKtdyev+54cVAmF9UowfIRyVoil1TXB3zuhLzfu0IyUxWW+oT1xpNF8VsUX/qqad4661EzzRYL2UBi6Xklh73si9CO21OKBZWPPwWMrnW3YPP5Swezrmxpaz1qT/YyGt4N5nN1c4i/c1H5tuaY1IPDib6uXQ/iGghodEkgMQNaZ1+zAzXu/bsZcWqNSa14xPrALc/yaXkjTfftlXPagpul9/yemtZtLrMSTrUA5XM/0vXaDKRThCWA5NzDSQKNKEAACAASURBVCt9Q1nqH2bZpLh3f/bkmMdTinWvVjsJu2zausNWPbNzFQoYefDK6LotMw7+7/UEjdqBsCdzJyLikKriMBVWjCRBjuSOCvvXXt2OJnNjCmg0GYy06Psz90nUbEmZkL07Zpt3jzk5xlVrb6lE9fwhKvzZMa+HFvxFBcebXBRm9vw2AFXSN3xSLdcBAqHQHuKOqmLn9/jT2nm8JafErdfV0DsJjSYhMlc4hEj0xLV1f+13z9kFDTGvx9up1El3y2stKiWJPkTn5I62jGo1zsfaLST2KRmtYp2xSNO2VQsJjcYCq8Nj4dcyW90UXXTcpLcZPebThLqzcoENXktOgHhGx/4kAyYLfOvY5guzvRk5TUyk4vYd6isQULy2ZKfNXsXo17rndAUK1EJCo7EglpAIJB49r8PwmxymK84bRHO/9l1slFLs3h1brdWWrTlJhjcx+V21zUxn9nmElns7n0hR4VCWFkwwvfbuax+HTwaANxZvZ+E9j9roObPRQkKjsSBm7uQkZcTfbr2dW+/4DwAej90gyw4xmeOtci9/kEcS6s7u0/bixYt55plnWL9+fULjJILY+IUo06RJ8XcGIT4efRw+yTZatbYo3VPGYbf9Oqp+/pz3uGrNuzZ6ji2k0r1b1UJCo7HAKjQ2hB/qcq5mafD4cLvA5atk796ZfDH/OGpq2iPkeKqXF3v9LVi4BICFi5fZqh8IBJKynygxV8VI1AsTF9g2/zsYteWVv6lNKBDDBpLVWE/RoYc67jnT0EJCo7HAH8smkWBCn/defp+ZP/5Ry/uKyq8AqK1LzVP31l0lNBlJeJINw92WQCy3z7DXO0uD+b83FdmL1Tn11RlJCYlml8Ltss7hEOrb7LS2E++mCMLOVyhfIx+deVpUlabKjXx93ERnAf8y0B9Cu8BqNBb4vF7ItcimGwg+Xzk12G5dNJeK0Ue1vK/aGzxpXFVaz9Ahic0zRG1DI88/+xSunJ6ccsoJ7G1MLKVoslTl5tJteCl7dve3Vb9xy2bo6yzXdThKYL17jMmFyN2e2c5QnB1qaO067HVNWTGVAyLnX/X5PKqqG2EgMaMctkS3tRPgL00H//ROQqOxoNlrvciaG0Hj02Q8lq0Ydhg7+wygoTY4Rn21edIeJ1SWBnMxBJqr+fyT2TSlOJ9EzPU07FruEc08PeJK+gy3zhIXzhZfLjXZPRKel8dl/qwbpW5ynjDOFi535DKqgMWfLKY+J5sFh4yhGYsHjXAyODOd3kloNBY0NtRDn74WVxNzgfXk9AAUCw8dC8DFexfRvTtUVVQmPM8Qfk/QMBtA2uXpL/a9ti5glfnBRJXePOvcDuEEhtWzwzUy4Xkt6G/ucdTWu8k8QGHyrsxNARdPnhYZA3d/bSlzTzqHlcNH2eoj3cbpWOidhEZjgd8T4+k+wW91XU4fPj1ifMv72qD5gH31yT/mVlXVsvmovjT2zMYvLrwWT9gA5eXleL1m3j4xiPEgG/5xtKzFyt49ubuZhe62TwDrMxTQOjd/wOH92sRMrVcbqLaMCpsoGZtPQqM5UGlosD4FHEjQKLzoyFFsGtQaFVVJcIHxeu1FQY1FaU0Fnww4lZ79q8lt9lGWH53LOcSjjz7K6NGjueyyy2z37/iO7Rps2ymTW0sQ2LYFpjg1XLe+rNlTB8Mi7S+N2TksMHaLjju0RB+m02gyimbDS8iUNkZRuxR0izwToQgJidhhKezgqd4b/F+yYwoIgJnNo3lpg7MxbRtOW/Ly2BUSiXmK2SVkSzFVNiX4tB/eVyDQRsALLBppns41ObThWqPJKAKGuqm5uZkXXniByspWu0EoRIVT7yZXloXgMVlQ65uaeeC2e9hXas9e4W22vxv5du46+vuSt4OY4tALJ8Weui242ooFU0N+8oP7A6VRZQGsY0mFI7ZsIhLxX0cTV0iIyDQRKRWRNWFlfUVkjohsNv7vY5SLiDwsIkUiskpExoe1mWLU3ywiU8LKJ4jIaqPNwyI6wLsmM2gyktRsWLuWLVu28MmHH7ZcS9C5KZoWhXm0/v6tR5+lRhp59b4HbXXld7C7KRywlYNy99qcZJBYOwllU6nToRgTCe0krDLuBasmvuy0/VtQCDkxYk11NuzsJKYD57cpuxn4RCk1CvjEeA9wATDK+LkKeAKCQoVgbuzjCaYqvS0kWIw6V4W1azuWRpMWaquqAGhcE3w+alq3LqpOsgtigbGC9fRHS53a2v3B8Ymh9grDyTJ35JFfcuzRH8e0u7QlEDPRksno7bVFcEwMfVOyfQLNJg4OeT3LUjlYWokrJJRS84C2wWUuBp4zXj8HLTnQLwaeV0EWAr1FZDBwHjBHKVWhlKoE5gDnG9d6KqUWqGA0tefD+tJo0sqXS5cCUGUspFVh11K13rgMtVVWINpDprlR0ezOwu+yp7pwMqkfyVt8lTeZqc9Ms90mEEMKVUvvsHeGy6ldIZG04dq8fZQLrFlqvRToLVSbAyRKwJUV/yBjZABJG4fpOpnheqBSqgTA+H+AUT4U2BVWb7dRFqt8t0m5KSJylYgsFZGlZWVdR1JrMpOAO3gIylMX/Jpk0bP1YoILW1Srln6Cxtva2nUEAkHV09aeQ/nvyd9k44CDbfXtd3h6+A33FZSX2Q8uGHA5Cb4NInZ1cu2sYW6HVA3hH3VbNZzdvnbf9HtHY6ZLE59qw7XZXViFe49VbopSaqpSaqJSamJhYWGCU9Ro7JGfGzQEixGCwx3hj5+Yd5OVXlwJ1NVtYvGSb7F16/0A+IcE1Uy1I2z2bdg1rPTrmzZtinhfL92pys7B57N3nkG5HS4Xefb6bb+lT7V5F/l++ZydcY6R2xwlasdkr8+yOXNa+7AzTidLOrTPUBVh/B8y7+8GhofVGwbsiVM+zKRcc4DS5A/wwu6ymLkcOoojxs4zXkV7oLRVMSROq+eKx1MO0BIRNicrGCjPnW0vZEcgRtDBQCDA4y++HVVeMa4bjz34sL3+bT7JhoRUSXbi8ZicYT6v1nzUxv9tXG2/eqsobh+2Rve1aSvYWtE/OP+clte2DOeZ6t1kwUwg5KE0BZgRVn6l4eU0Gag21FGzgXNFpI9hsD4XmG1cqxWRyYZX05VhfWkOQK6f/wX//OhPTN+wKX7ldub5/J8CsN14Qq8PO8GsJDEXWCsPIQV4moKLWFODN6zUPgG/tZBo9vrYE+gVVb43ty+V9fZiLNkVEiFsn5NIWtce3X7F2h0tdvOWzzxG6PdkvJv8bUKQK8RWBN6GHr3xi5PzzBmqbhKRV4AFwBEisltEfg7cDZwjIpuBc4z3ALOArUAR8DRwLYBSqgL4J7DE+PmHUQZwDfCM0WYL8EFqbk3TGVm2fhqnbVrEjOUz0z0VlsrxADT4heHDV+N2hYd1SOwLuzzvWNNyQVFdFlRv1VZEnnewu4QGAtY+9x5/gPHdN0eVK8R2lj1l0yYRouPSbUbPK/vSC2ibLcJs85eocIhw+U1w7X7v6BNtjhX9qiOJK8aUUldYXDrLpK4CrrPoZxoQ5UqhlFoKODm/runC/HhBGUN7fI/1a6MXtHRxUI81DBi5guocHw0N11BQUBAzt4IjwlaYJiN5jd/YuTgdQbXsJKJbepvqOG7SDIKb9Ui2Ht07qsy0f4fqJrtCoj2ej9/4wWX4XJF2o1g5upOizSE9JfFDkG8pq2Nfr9in4tuiQ4VrNMDgo3vR/7svMTw3+dDZTtmwYQO1tbVR5RXuLH4kb7Gy2xCemvo0YC9dph3Cl9HifdUAeGwaktsSyybhbarnfv5kem1/fh/T8rY43knYVDcl/3xs0YNqs4NI2QlIIiRbIIYay4qlny6JeJ+Muqu90UJCk1G4CoMHyKR7xybM8fl8vPTKq0x9+pmoa9sKBgKwJO84KiqDpyWcrgu7Fy7h3cv/z7qCQEl58N4DrqC6qVVZYm8BiZWTu6augWUyKap8T/YQSxVYVP9ObRKOaidD9EgvH3c2X/aIVOe0Vx7ptl5TdgJt5K37MqGR0oGOAqvJKELxdtwd/H3weH24Baqrqy3r5OXV0ad3MJSF0wV8xnPPU3akSb7j0GOuhHmEhxc5oNUmYaJuaqwFk+Q3kYfgYmNX9+5U3ZQsDRKdt6KmwOQAYkzJnrhIa3vIUInEXc8bG0sSGEmrmzQaml3deZkryZbkcgw4pa62HpfLC2ZqJOMJ+is5lbJvRC6AdoVEdff49+My8hIk+qWMpXNvqKpLsNdW7BymC9/NRAXYSxMtuvw20ynv4aI+OxfTi/H6DDdcJxDFdk33gQ5qp1cVpYWEJqN4p9cFvC8Xs6zPEe0+ls/nY/Xq1SilqKrcz+STX2fUqEhdcVNTU4TP+8uuoOHX6TmJ5rz+bO0/2PK6APlNQe8pd4KLayyVu9efvPouduymIG99NA+vy5iITZtEey+BVpnpnriwN8+PudCok/hSqPaWR74X4t5Ucd/RzsfROwmNBryG37hT/XciPPLOXL710k7mLV9HSfEOrpQ3+GTwSRF17r7zX3hNviVOZ/fpmCP5aMzx0RdarapQZ4TuNvRMbQ+DxSMQQ0p4GpIXEn4buRfmL9+IyzhDYvszaucNR8uuL4bQSmYBrujRVt0lcY323XvsjnifLs8lO2ghockoOs63Hl7c4eUIdynTN5Tx6dxgGPA50iYIsdtFU5jlrsUWYTsuURBPL4twHMBuhhuLVCCsNJz4C8imk09B7dlneT3gTd6zx2djJ1HYbR2LugUN5B35u7RFzNhNDhfpsOqNuXmOp+J2O0+lmq7PUwsJTUbSEVvrM/wL+MWx0/Bt+5pAdoFpnc9HHUN1QeuTYkgt4fTrmpVlvih80WMCf5KHKOo2DCVB3bZPAvzz1tsdBetZPmQwNbnRhukQ3ubkbRI+d/wcCfv7t0bZsX/iur0JzcNaUCby9/bhzXcB8Nz4iyP7kvhiXUxCw8elk4Xl0Gjahey86HMK7UFjYyMThn1F3757OKHPSnr2CUYVbvu0tn7ISD7rc6plP3YXF6+FI+Gu3KCdojQn/KyCwh/+zbTh5rR+9Ghqe1qHFPd6nT+5tsXOTqKdM5EmSPB31LR9t2UNp0LCK4pun7yTcF8uBwLUqSddqtFCQpNZuKxDKKSSNdv2UO3uyWP8loLe5XQfsxOwv6V3+oy8M2uEjVrBm66RnuyJOI3rLES3qQtsIPnVW9lYLSKfkDNlJxGkKoYEc5rr2udWfHGaeVgNW3+7qu1bbZPQaBzhbucn0rnrtvFh33P4Sk5l+6BB/F3+BcQXEq1f5lCoh+RoMapKa59397iFmeNOSbLnSLwee9ntYmEnFEn4pqe9Bb1TanrZPxMSjzl9T2dv4RCLqzYSCFnsDjNRWGghockoSgh+8XKG7miX/uvr61m4cCHdiz9nizt4uO1J+Y3jflq1Ban7UntcQZ1/pTiL6dNCy3GA6Dk1e1LgAmvjaTtcyLaNoB2jUcoY5LfO2/3s8d9J2TgBcTPzWHM1pJ0Hh/psqysxPLC0TULTmblv8XxGP/tLdtdYn1i2Q5EEz0dkZSevQzfjL9Nncuu766lv9lIm0Qea4u8kol8lQ7huOnU5KqLx+ROLBxWO38ZhunBjdXmWPWGXSqVU90DyBnozfBXRGfysDhfacWedMeSCyDYtp9Rj0MmSDmk0EZROv5d/zhzBM++/npL+mmifE9d5pVv41uB51GSZuy02Szx3RsHv95M6t/aQukliLBDJrw4+X/L6O1s7iTAhsSYvDcGd20HO7nrlVab+MTrVqJWNRhHrdxmbmD5POgqspjMzZuhwev92GgO2BUN8N/oDlDY72w2EH3Z6QX5mO62mE8Yd+Tn9R28gPzcxLyqFcNu/WzO5OTV4RtNq27BOSGRzcTCqmSWy8ccI/mcXewcc06tTbw+d/kvLv2bniOi4WzHHaoeo5On6ZLWQ0KSEnkcsA8DtDmayPe3lP3PJM6c56mN+0c6I900JGFurvT4e2bEvKgRDiA/6nM0N8gQN+dbuovHom7OJRodhs62Ipd6y62nl3Rc8RBdLWxUwotcmg9fGLXsSisyYyuUv9UvpmqFjmX7SRVHlVkIikdPTLX1lnt1aCwlNNE1NTRQXFztqU+Puzcv8Hzm+4IGua7/w8Yuy7zvqY+WSjyP7NMntEI9bNhdz59YS5lWat93gPjLYd3ZiQiIgbtaOG4QnPzUKYo8R50gJCVkmaz/7jKLTTmfjwOHs6GXlbQNNOfEPwsWjwW1+4DCcuixLi6wlbaOoJoMCAinw5Aqncpj1IUUzUnk/4aTLoVgLCU0EPp+Pnz34X7754pKWA1gej4e6ujrWrN5G8e5y03bTu13J+3IJO7sHF6ohl77Lwac+6mjs7L0rI95XV5qPFYtqb1D37rEIC+0y9ADJxIZ6Xy5m4eFHJdw+nFY9v1jqnGM9mdasXMmS4yYy98gJzB1pEhvKoLy789ARbVmfG/+e3x96juN+Uxm3SCF8cfJJ8Ss6ICe33nIsJ+X2aE/LVGIklU9CRLYDtYAf8CmlJopIX+A1YASwHbhMKVUpIgL8B7gQaAB+opRaZvQzBfir0e0dSqnnkpmXJnEemvEJh1bt5LgBqymrPY0hffvwr8enU1LTyOBAJS5fLrfecUtUOy/BJ8hQApaKrD4UMyw6x20MKhsjbRg1Vc5VJH5lL7icP8nHo/Uue0bZpopKSr5YCD3NI8Au7jERMF8A7Cw2Kxqa2HqoSZ6KTkSqhcTcCy+KKmsPUqluskUndoE9Qyk1Tik10Xh/M/CJUmoU8InxHuACYJTxcxXwBIAhVG4DjgcmAbeJiL18ipqUs3HFCk4/73WOPnY2mzdvBKBnYAUTBn3FsFO/ZOCxC80btlGp/omH+Lf81byuBTmenhHv60JRUR2wa9cWAJatXht1rampqSXHgS+/Y9Kjvn7D73lu+aK49RQStZFoXYTMnyG9xcV4ym16LXWAzsCXgHoQUq9u+uKwoyMLk+zfaXMF+B1mjIplk0h3hNj2+NO5GAjtBJ4DLgkrf14FWQj0FpHBwHnAHKVUhVKqEpgDnN+2U03HcNZhn/EBF/EjeYt9m5YDsH5cIQ8cdjV/lX9zW9+/8957c6Pahf7IQ1+N+K6kraxcuZLy8nLyJ62PKG9KYNHJyQ4KlvrilVHXrrlnastOp7jXAMd9J8KGESPY0Td+gpngQqBoCHf9lagXEcy6+hpW9rCnf28HZ5soZv3iuoTapXYRFNYOPSSiJGkhZJVC28KzzedSNDs04FdI31hDGXROF1gFfCQiX4vIVUbZQKVUCYDxf+jbOBTYFdZ2t1FmVR6FiFwlIktFZGlZWVmSU9eYsbb3EbwoPwOgujp4gOhd+Q5VYZu7FSs+su6gzV+5pzn+IvbCmx9y46NvkJcfKRQamxpszjp6AqomehfyjZ7ryXYHTx6b5XtuDz47egIffOOEuPUUwv6cAn4pL0aUxWL5hPG259GYkxu/UpIsPXxEQu1SeYbQrK9Aksuc0xDd5Vl9mDXgXEdtzNyWW+mYeGZWJCskTlJKjSeoSrpORKzDZZqLQRWjPLpQqalKqYlKqYmFhYXOZ6uJy1d5rYtno9f8nELpidHnH0ILWlazi/X7WvP3ltuwK0w4eSYnDJ/HW1weUd7cnEAoCeOp1C3R3jwzjzmZjeI8I1gy1PWy51WkECqy2hwglFCK1OR5ffSFKeglNp99Y0JC7cycCE6vWZxQX2bhyZVL8Drclfpralr7dDiHDflHOmxhj04pJJRSe4z/S4H/EbQp7DPUSBj/lxrVdwPDw5oPA/bEKNekmYBF5NDX5cdRZaGvZv/jFvLsK62HzSrKrWPphLgh5zHeHHkBSyXSO8frbRUStRVN1JQ3mrbfunEDleUhTygjvIFJlrYNMibuXFKNW+zZDPwCtfmRwjfeTmJv717MHjehQ1RJdtjVP7EHNzN10+itu0xqxsfsE2t0Kz599MnIMeOE6l46K2y33IFuRTGHSpOUSFhIiEg3EekReg2cC6wBZgJTjGpTgBnG65nAlRJkMlBtqKNmA+eKSB/DYH2uUaZJAf/66EV++Og1CbX1x0iHGf0lC/4Br+Fojt3duphXle+POUbIzXatHB19Lczf/YWHnuDFR81dat//6F6efeZOoDVSqWoTRnbJui0x55EsyutFmZxqtpt4p8mdw2tHtDmwFWdN+HTseLb1Go43PzNOYLkSFFdmQsKXldg9mamGPu1zGl94IuemLFykQ6ycN7/lbzyWuqlixeoEZhmDGLfdGXcSA4H5IrISWAy8r5T6ELgbOEdENgPnGO8BZgFbgSLgaeBaAKVUBfBPYInx8w+jTJMCDpv+FefuOhSv34vfYU6BWDmTn3r+pZbXnkCgZXF+U64g/8LPW67VmNgGwqmsslYD+MOC0h1x+qMcceqTpvWOHPMFx0x6N6LMR+S9vve/6THnkSwP/P4PPH/9jVHlLpuPoSX5/aPKWluarw5iHMQTV6Zk+knskdtsx+SyKW/a7hit7A/lgyODDX54ztkx+119+HD2rYj2kGvL2/feGbeOI2JJgjR5OSV8TkIptRU4xqR8P0S7x6ugWDZ1f1BKTQOmJToXjTU9r/ycfjmzufuaT1Gqhr0TTuHxq++yrG/Xp7xuywf8Y4aH35//Qx675ofwwykt197luy2vGxpqzJq3sH+vdbawRq8Xv9+P2+1mLmfhJSfqD+sP//gPL5zyBuPVYsKPcbm8kQvWjMnxjcfJ8M4pp3N4yS6uVAoRwbt3L1kDByI2n66Vy2SBjbMoZF7ugcTmY5bxzu56mIUPL60nov0WHkfZBZG2sde/c1nMfueNOprzF37GRceOjbmTeP+Mb9qbaArojDsJTSdgcc5EHuYmxn9zHxO+1cTkneCzuaPwEoyFZEbeQX0Y9elaSvbsZvyPVyKu1nofyLdaXjc0mJ9WDVG5f5/lNeleyl/uuZedxSU8I9fynPwiqk7WyRuAVm+l0BeprZpnr8s6ZEWyeD0eNvcbwftjT2HJn/9C1apVPHL33Wx89r9JJa/3tnw74/SRZj/6EIneqc9tsgz57fXWVsXlx9xRoG1vH46dHLPffQWFLKkUvpjycwIx7mzVyJG25mkb019leuM6aSHRhdi4fw+3Xv0dZqyc31L2uNzAIjmRTd0PZkf3gfQ6exa/+5c9f/Ysr+InX5rrXJsO2Uf3i2ezYOYS3ufblJh7Lcd1ga2qtc4/sWZUIUcNW8Qz/33Ass5/5VdtSmzE5U8x1WG5Bmbl5vDa2++x+pAjeLNou+1cxma7gtK8npbXwinvlrqMa8mR2KfudUUv7HbVdAOIfMhI1C5ihit/P6+NHUtR3gjLOjmu5JM5taVxx07Tcp3jWpM07957B+PP2UvJs9FRTe6RW/mH3Mk1TOOEHPPELGvaJIrP/sYW9jabZ4i7T/7Cb3mKha5dvCxTLA/PeeIEW1u0yVrv+558h7cHXMTeE1v7fuP2t2L21/JFCltj6uMYz5OlriZSpbajoCcffOMEPp54DHaPsZmls/yqj72zHDOPPMNWvfYm0UXMZyIk4nkfhShsDqqRBgf2MLFxOT6r8wYJTE2JnzcnnsHe7EGWdVwx8mYnwsbeg3j6tlvN55PSkeyjhUQXot/AGmb0uYCCSaWWdQLiZv8R5n/YHz93H4Hs1kXtnu5/ZlvOCMu+GqQbb46NfWjIG0e1NaJwVczr1a6ezJTvtbxvHvkc+/dbL/pmX6TH7n4w5hjJUlPbqu/OVm7qBgSN8Rv6Hcr2rEOsmkWwITuRgIGZoWZKFq8remE3M9GYkWUs0i4VoDhrIPtc5gt6IgusHRuAO8UOyIv6jeep7/+EOdffQOn6zZEXddIhTbKs7TOGD+TbzOh9Eb/704/ZVG5+3OS1gkujym657W5qT6lM+VkCq7MWId4aFlvIBNoshO7h5bz44h/4aNEy7n0gWm0WcqcMP6C1YezBdqfrGFF+5r/xdsv7vX3yeP3gC2K0cI5fFPVbt6a0z/agUeKHEjfDa3Lw0Y7r8ClqLrmBoAu1C0VJdoxQ6Qm46Jjt7kxqOe84DvsLevPAxMlMffqZdh7JHlpIdCGU8euUggbOOWk9H94ZHa0VWp8/X397Dv/+d9Cp7OAJX/GY3BB3jKENzsKh+OIdWhLr8NYQnVf5Bnmcu47+DUt2PcGT466wbOdxu5jzzocA7B3gLB+AU96Y3Boe441jnIfKjsey/PE89cSztlUwmcp3fOaqQrOdBGHnGC5qMA8D8/0Vq8kx3KTjOQi8PyC2y6sZdrIOllrsXJJl+cFH8O5ZpzHn4SfY7zLiOmnDtSZZlLH1nS+nc3P3f5E9zqpi8Au1QV6neMIaPB4Pt/f4h60xLto5P36l8KGM3fjekjL+fctfqK6M7RLbli3uUablj/S7jgaJTBzk9fpaNv/LRh7M2zXLeGvGB1RlJZ6FLh5K3KzvdXi79R/i5bNP4N9/ub1dx/im+h/f9LzXLn0PVsXc3M98h2W2kwC4/cX7eObe3zNio/lZmstunEaukbvb7qFFJySTcyQl5Hj5n8qmytXHmE96luuk8kloMpcyGcgX/cwDwKms4FL6eO+guua6bUW2+82xEbAvnFDI5Jdf/Rcvn3M2WU/fxg1/DNoI7r33Zjju8ljNHXHVOw+wrX9QfbUq7xhWDT+GnNK32Nrze3FadiyHezczyFPOvG72z27szhnG82fk4rvpb/TLzWLCxAnQu0dK59V9wxc09f128JisQbZqxivJBwcMKDcHjz+R2+6cwt7BQ3lqZOs5hc3Z0UK2mzvAaV9+DcCgEyZTumcOVe585vQ6OaJejpEH3dJgncyczVxzO5iyg1oFlT9N80n/p6BJGW1VqCsKzO0LW+RwXnh/Xsv7959/2LSeGVl+Z09XoSktO3gUJTKU9QcdxNdL13DzHffx+MSLHfUVjw/6R9s38UEmBQAAD0BJREFUXhuQWQIixGFbNjluU55VyMPf/B7/PutMbpX91EivlM7polG/4Rtln0WUfbd8Drev/FlE2f1Fj5KvYp9/aUvoJPQ1f3mO3ErzZee+T2/gOLWQ66unccGFl1CbD6uO78/EEy7i/ot/y6jdrSl1b1rwAgDZxjmeYvfQlHsaJRoaJJVsK2iV2M1aSGiS4Y6bp5A7KNKFtUKiQz2EWJLXGsZi01n2czxlOXxi8xhbdskKGhj9WQEe2zOT6SedTZPkR9XPCURHmO16KH7yrZ8m3LrO1YNlvaOCHQBw0f5PE+63e7fuXHLFQxFlXl8+V/9uWUTZj375TMt5hCv2fsgRvmiBd05TZM6RcPfYAlfwdzw0EBnE74d//4SXjv0Of73kYY446gQmLV/PD577AoCcrBxuvPIP/GHJgyw9JJs//Pl+IDJ8xy2+O5zcrimDVasgev6wjjtNbUaz5LA7Z1jL+/cGtro6exo7JmkWaCHRaVm5eBnzZn/W8r7o3MOYlv9L2+1fd/2o5fXb8oO49U+oW8VxjavIdqgX/fTooCphTo/TAHi/31nM6mEdtvqqFTMsr3UVslWAww+JDmiYCnb0iE6Tenzj17baHnbYWIb0a+sJFlzcp5S8EVHaTQVzffTZV88PVkcLpkcn/4jfr3mWn+58B4j0zPnFT//Eb7c8zxXLI9u5XC569rFO0NS9Z19u+uNzDDu4dYec7W/dPRz0bvzkTvG4cP3SpPtIFY0u68Rdi7763PJaqtFCopNQU1PLos9aY+xPLXmHZ2Qhfr+fO/71Jz4MC4WRas6u/Ir/fetK3r3wSpw64m3KOpIn7r/fdn13QHHx9i8dzjA1DAhYhwhJJZdsCy5EgwIlcWo65+x1X3JibWQuBndYXo7Lt70JwPA2T/EFqo7CAYOQNsbag8qCbtR3XHY751fP4hcbnwagWyAoJBQurr3xSQ5S2yPa9eozgN//+hF6lHlb6oXo3rsvt/ziAfr2OijR22zB5WvdSlQMab3PG/e9y+meBHZVWfbyf3QE1RZZnE/3f0qfPqm1R8VCC4k0sXPXTma8HfSvV0ox88UnefrZn/C3Jx/moQf+xbz3nqK2soLpTzzAHU/dwgVLPuBilcMPP7yPn7x3N2/1/C4fZZ/PP+67lbmTUnO24d2elYxoKuHzEdksHz+cG1cHnwKPLG49nPezn8d3kwU4t7LVC+rv46PiPUbwrd0LWl5nuV30byqPUbt9OKfhM2YfNYprVk/nhPolXLU++OR81o7Eniz7q1ZX4bMr53Pt2pfIVcEQ6r+++r7g//uCT4OXb3k/malHcPMNj/KHwSP5yfppfHfHaxxXv4hHTvwmUzY9yb+zVvLQz+5gRq8ylpzV+lDx8/XTeKl3tEPCm7lbuPm3wblmZ2Uz/ZI/c8fVjwFw0p41AAzICy4hJ+wJxtDKUw38es0jLX2EnI99Jh5Mk48/Ken7HVzbGhLljG/+vOX1pKxGfvjRaxwR2GC7rwJVz8nD+8WvmGZKfUMZO/7EDhtPOqvv9cSJE9XSpZmzNWyLx+OheGcxIw8byZ1PPkQNAb47ejyb169ig7+aZ44KfknPafyYOfnOfbhTzY+3f8h9P705qjzgbcKVHbntvevZO/nPIa25D/r7Kyh3B325u6k6frd9PmUNTUwdcwl22HvGOF55+THmBuDJK67mlVcf4aYhp3N22VJy/RW8PyhokL6q6BWmHhZ5NmJc3QZWdI+fCeykxkV8mX8839/7NlcfcwGPLF5EZX5PRtTuJrvZzx3X/d2y7e+e+S0/Pu2n/GPDChZ3H0e/QDn7Xdb2HoD/Nq1lyJFHsaJkLVNO/D8AXn71IfZV7OWGa+9uqRfw+3G53ews3sjdn86gPK8PPWpKef+Qi6y6NqW7quG32+fy65/dZrvNrf+5ni+PnMyHZ1xGdk7rWZJHn/4NWa5srv659Q7Q42lm3pevcfYZVwKwbdsq3nv/Ua65+nGyslrtViuXLeC86nzOqf6SFy6JPvw4671H+W/AR0VuXz4570rbcw/nP//5OX5fPtdfdx9Xfv40w8pquO/HfwFg0ZdvcFnz8JawMUPUbvbIsKg+frF9Bn+4/Df0yu/DP5/8DY8d8bOoOuG4lRe/ZCc032SZUvQ/7vml9d9rPETka6XURNv1tZCwpqR4F3uKiynIzePFr96ld52HHUN6gYIeDU1U9OzGd/OH8URWLQsLxnNB2Rcs7DeGGukZJ2dt+3Fy9WLm9wrG/Llq9UwquvdiV9++LO05mgfKv2Z5WTHTR3+HPoEKXu2TxzFJPJF4fMEcFfk5wS/g/U/dxvijxnPGqUGvpUFzV1i2PaFuGQu6j+fb++Yy9XJ7u5OtW9dx+dYidroP4qT6xYzZVsI/fn0bTZ56Dpu/jp5Us3DCeA5fFh0g7SX/NiafdDoFub0Qk9DUiTDl5fuZPTi4S7py2ys8P/IK/rjtNW78mXUodrvc89CfePCYVoE4Zd00thw8ll4N9WzofTAXrpnPzt75NOX3oG91BQ9efW/SY7YX77/7JEcfeybDh5mfJ/EFfCilyHYnv+h6PI1kZeXiCvsdF+/ezEmbymmSfOYfJBSt+5zVG9bw0TdOo29WGZM27eKmayMFYvjf7ni1GE8gn0JPDXPzg7ufO9a/x1+PChq2f7prBoMq6jnjlDOpqizlMnfQ3nROzXzm9Ix02e2rymM6lNjhj8vf4sYb/5lwey0kbHLHg7fy6Ljvxq/YwfQPlJHt81OS03qS88TKr/mqzwTyVGOLR9AoTxGbcw6LaHvp5lnccemv6N03M7bMDQ3VrC1axIoNa6jYt5eB/fuzuW4fN3zn9/TvP5gHp97CT35wE316JfelSSc+v48sd/s8EPzlqVvp0dTIzb/9d7v0rwF/wI9LXFG2mC1bVvPUVzO4+cJf0rdfq0G8omIXjU01DB0ypkWQ7D0j8tTq3pLNuF1ZFA4cybLFn/D+mo/pVuXBD1z63V9y8tY6rl83lYmHTeDrdUU8dOyPiMVI33aO37OBVw86H4APezcz7tjYkQpioYVEHEZ8usDU9bK9mFS7mtxAExO2bwUveF0u/nbTnVTtL6V3vwH4vB4am2vp0T0zFnaNRtPxLF/xCTu2b8Gdk803L/gJr7z8OOXVe/n+d3/C4EGHAnD7f/5Ioyube36dXDa8TiskROR84D+AG3hGKXV3rPqJColYKhCAM6u/YmfBAL69chkVPQsoqG8ix+/jvFMv4tjjTwmGtEj3cX2NRqNJEKdCIiPCcoiIG3iMYE7s3cASEZmplFqX6rGuLHqf5w+7iBu/foM//v5ONq1byeGjww8mGVvHc6MjpRqTTfWUNBqNJmPJiJ2EiJwA3K6UOs94fwuAUsrSApjp3k0ajUaTiTjdSWTKOYmhQPjpnt1GWQQicpWILBWRpWVlzkJWazQajcY5mSIkzHQ4UVscpdRUpdREpdTEwsLCDpiWRqPRHNhkipDYDQwPez8MME+rptFoNJoOI1OExBJglIiMFJEc4HJgZprnpNFoNAc8GeHdpJTyicj1wGyCLrDTlFJr0zwtjUajOeDJCCEBoJSaBcxK9zw0Go1G00qmqJs0Go1Gk4FoIaHRaDQaSzLiMF0iiEgZsKODh+0PdHyyg/RxoN0vHHj3rO+3a9P2fssBlFLn2+2g0wqJdCAiS52cVOzsHGj3CwfePev77dqk4n61ukmj0Wg0lmghodFoNBpLtJBwxtR0T6CDOdDuFw68e9b327VJ+n61TUKj0Wg0luidhEaj0Wgs0UJCo9FoNJZoIWEgIsNFZK6IrBeRtSLyW6O8r4jMEZHNxv99jHIRkYdFpEhEVonI+PTegXNi3PPtIlIsIiuMnwvD2txi3PNGETkvfbN3jojkichiEVlp3O/fjfKRIrLI+B2/ZgSZRERyjfdFxvUR6Zy/U2Lc73QR2Rb2+x1nlHf6v2kIZroUkeUi8p7xvkv+fkOY3G9qf79KKf0TtMsMBsYbr3sAm4DRwL3AzUb5zcA9xusLgQ8I5sKYDCxK9z2k8J5vB35vUn80sBLIBUYCWwB3uu/Dwf0K0N14nQ0sMn53rwOXG+VPAtcYr68FnjReXw68lu57SNH9TgcuNanf6f+mjfu4EXgZeM943yV/vzHuN6W/X72TMFBKlSillhmva4H1BLPjXQw8Z1R7DrjEeH0x8LwKshDoLSKDO3jaSRHjnq24GHhVKdWslNoGFAGT2n+mqcH4XdUZb7ONHwWcCbxplLf9HYd+928CZ4l0niTnMe7Xik7/Ny3/397Zu2YNRWH8dwapgmBpURE6aEVQEKmgIujg4OAXgtBBUOw/4OCkFMHNUe0iDn4NVhBEwa5idRbEUgsqdnAr7SCtm6A9DvekDW+T+hX6mvD84CXJzQnk4Qk5uede3mvWAxwH7sSx0VB/YaneX/BX/ipJFBDdzt2kL6+N7j4F6aUKbIiw31pytS60aAY4H13Se1mJjQZojq75GDADPCf1hmbd/XuE5DUt6I3zc0D3yt7xv9Gq190zf6+GvzfMrCPaau8vMARcBObjuJsG+8tSvRmV+ask0YKZrQWeABfc/etyoQVttZxPXKD5FrAV6AOmgGtZaMHltdLs7j/cvY+0+uE+YEdRWGwbp9fMdgKDwHZgL9AFXIrwWus1sxPAjLu/yTcXhDbC3xK9ULG/ShI5zGwV6WX50N2fRvN01iWL7Uy0N2LJ1SLN7j4dL5d54DaLJaVGaAZw91ngFak222lm2doqeU0LeuP8OuDLyt5pNeT0Hokyo7v7N+A+zfH3AHDSzD4Dj0hlpiGa6+8SvWY2XLW/ShJB1CLvAu/d/Xru1AgwEPsDwLNc+7mYMbAfmMvKUnWhTHNLnfIUMBH7I8DpmBWyBdgGvF6p+/1XzGy9mXXG/hrgMGkc5iXQH2GtHmfe9wOjHiOAdaBE74fcR4+R6vN5f2v7TLv7oLv3uPtm0kD0qLufoaH+lug9W7m/7RqR/99+wEFS12scGIvfMVKN8gXwKbZdEW/ATVJN+x2wp90aKtT8IDSNx4O1KXfN5dD8ETjabg1/qHcX8DZ0TQBXor2XlOwmgcdAR7SvjuPJON/bbg0V6R0NfyeAYRZnQNX+mc5pP8TibJ9G+ruM3kr91d9yCCGEKEXlJiGEEKUoSQghhChFSUIIIUQpShJCCCFKUZIQQghRipKEEEKIUpQkhBBClPITAgCHK3K8c5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is just for visualizing the various plots of the samples\n",
    "\n",
    "df = pd.read_csv('./data/040_A07_Zanardi_QS277us_200Hz_delay1us_exp1ms', sep = '\\t')\n",
    "df1=df.drop(columns=['Pixels'])\n",
    "df1=df1.dropna(axis=1)\n",
    "data=df1.values\n",
    "wl= data[0]\n",
    "print(wl)\n",
    "\n",
    "for i in range(len(values)):\n",
    "    plt.plot(wl, values[i])\n",
    "    #plt.show() #comment this one to have unique plot instead of multiple ones\n",
    "#range(len(dfs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(20, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample Name</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mn</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Mo</th>\n",
       "      <th>Mg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B16</td>\n",
       "      <td>93.63</td>\n",
       "      <td>2.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B15</td>\n",
       "      <td>93.55</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B14</td>\n",
       "      <td>93.65</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B13</td>\n",
       "      <td>91.68</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.180</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B12</td>\n",
       "      <td>92.47</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B11</td>\n",
       "      <td>93.23</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B10</td>\n",
       "      <td>93.24</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A01</td>\n",
       "      <td>92.94</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A02</td>\n",
       "      <td>93.35</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A03</td>\n",
       "      <td>94.15</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A04</td>\n",
       "      <td>93.70</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A05</td>\n",
       "      <td>94.33</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A06</td>\n",
       "      <td>94.51</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A07</td>\n",
       "      <td>94.01</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C17</td>\n",
       "      <td>92.27</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C18</td>\n",
       "      <td>92.79</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.0470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C19</td>\n",
       "      <td>91.81</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.0542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C20</td>\n",
       "      <td>91.81</td>\n",
       "      <td>2.42</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.060</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.0442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C21</td>\n",
       "      <td>92.37</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.0504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C22</td>\n",
       "      <td>92.07</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.0468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample Name     Fe    Si    Mn    Cu     Ni     Cr     Mo      Mg\n",
       "0          B16  93.63  2.48  0.12  0.13  0.052  0.024  0.012  0.0300\n",
       "1          B15  93.55  2.53  0.13  0.13  0.093  0.024  0.012  0.0330\n",
       "2          B14  93.65  2.49  0.12  0.13  0.110  0.024  0.012  0.0360\n",
       "3          B13  91.68  2.46  0.19  0.64  1.180  0.023  0.270  0.0580\n",
       "4          B12  92.47  2.62  0.36  0.83  0.070  0.022  0.018  0.0490\n",
       "5          B11  93.23  2.31  0.17  0.55  0.061  0.025  0.014  0.0720\n",
       "6          B10  93.24  2.27  0.17  0.55  0.061  0.025  0.013  0.0660\n",
       "7          A01  92.94  1.84  0.19  0.64  0.420  0.022  0.269  0.0024\n",
       "8          A02  93.35  1.80  0.17  0.48  0.370  0.022  0.173  0.0017\n",
       "9          A03  94.15  1.59  0.14  0.32  0.060  0.024  0.016  0.0010\n",
       "10         A04  93.70  1.38  0.20  0.66  0.040  0.018  0.269  0.0017\n",
       "11         A05  94.33  1.63  0.12  0.11  0.090  0.019  0.019  0.0022\n",
       "12         A06  94.51  1.50  0.12  0.09  0.040  0.021  0.009  0.0009\n",
       "13         A07  94.01  1.31  0.20  0.61  0.070  0.019  0.016  0.0046\n",
       "14         C17  92.27  2.54  0.16  1.13  0.095  0.027  0.027  0.0568\n",
       "15         C18  92.79  2.40  0.21  0.65  0.071  0.019  0.265  0.0470\n",
       "16         C19  91.81  2.39  0.20  0.65  1.100  0.021  0.267  0.0542\n",
       "17         C20  91.81  2.42  0.19  0.65  1.060  0.021  0.263  0.0442\n",
       "18         C21  92.37  2.61  0.16  1.17  0.062  0.019  0.015  0.0504\n",
       "19         C22  92.07  4.40  0.20  0.14  0.053  0.022  0.012  0.0468"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.read_csv('labels_aligned.csv', sep = ',')\n",
    "print(type(df_y))\n",
    "concentration=df_y.values\n",
    "print(concentration.shape)\n",
    "#print(concentration)\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.48 2.53 2.49 2.46 2.62 2.31 2.27 1.84 1.8 1.59 1.38 1.63 1.5 1.31 2.54\n",
      " 2.4 2.39 2.42 2.61 4.4]\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "y_si = concentration[:,2]\n",
    "print(y_si)\n",
    "print(y_si.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_si= pd.DataFrame(y_si)\n",
    "#df_y_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4094) (16, 1)\n",
      "(4, 4094) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_df, df_y_si, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4094)\n",
      "(4094,)\n",
      "20\n",
      "(20, 10)\n",
      "[56.8  75.48 85.99 91.38 94.2  95.8  96.9  97.74 98.39 98.82]\n"
     ]
    }
   ],
   "source": [
    "n_components=10\n",
    "\n",
    "x_df = pd.read_csv('data_with_avg_intesities.csv', sep = ',')\n",
    "x_df = pd.read_csv('data_with_avg_intesities_reduced.csv', sep = ',')\n",
    "x = x_df.values\n",
    "print(x.shape)\n",
    "print(x[1].shape)\n",
    "print(len(x))\n",
    "\n",
    "\n",
    "# This has to be used later for regression, PCA is done on X only\n",
    "\"\"\"\n",
    "y_df = pd.read_csv('labels_aligned+.csv', sep = ',')\n",
    "concentration=y_df.values\n",
    "#print(concentration)\n",
    "multi_y = concentration[:,2:]\n",
    "#print (multi_y)\n",
    "print (multi_y.shape)\n",
    "multi_y= np.array(multi_y, dtype=np.float)\n",
    "y=np.around(multi_y, decimals=4)\n",
    "#print(y)\n",
    "\"\"\"\n",
    "\n",
    "# PCA\n",
    "\n",
    "X_std = StandardScaler().fit_transform(x)\n",
    "#print(X_std)\n",
    "\n",
    "pca = PCA(n_components= n_components)\n",
    "PC=pca.fit(X_std)\n",
    "\n",
    "principalComponents = pca.fit_transform(X_std)\n",
    "print(principalComponents.shape)\n",
    "#principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "#print(principalDf)\n",
    "\n",
    "\n",
    "#print(pca.explained_variance_ratio_)\n",
    "print(np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100))\n",
    "#print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the *mathematical* way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cov_mat = np.cov(X_std.T) #covariance matrix\\n#print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))\\n\\neig_vals, eig_vecs = np.linalg.eig(cov_mat)\\n\\n#print('Eigenvectors \\n%s' %eig_vecs)\\n#print('\\nEigenvalues \\n%s' %eig_vals)\\n\\ntot = sum(eig_vals)\\nprint(tot)\\nvar_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\\ncum_var_exp = np.cumsum(var_exp)\\nprint(cum_var_exp)\\n\\n#print(np.round(cum_var_exp[:10].real, decimals=2)) # same as above but only first 10 elements\\n\\nwith plt.style.context('seaborn-whitegrid'):\\n    plt.figure(figsize=(6, 4))\\n\\n    plt.bar(range(4094), var_exp, alpha=0.5, align='center', label='individual explained variance')\\n    plt.step(range(4094), cum_var_exp, where='mid', label='cumulative explained variance')\\n    plt.ylabel('Explained variance ratio')\\n    plt.xlabel('Principal components')\\n    plt.legend(loc='best')\\n    plt.tight_layout()\\n\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"cov_mat = np.cov(X_std.T) #covariance matrix\n",
    "#print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "print(tot)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(cum_var_exp)\n",
    "\n",
    "#print(np.round(cum_var_exp[:10].real, decimals=2)) # same as above but only first 10 elements\n",
    "\n",
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    plt.bar(range(4094), var_exp, alpha=0.5, align='center', label='individual explained variance')\n",
    "    plt.step(range(4094), cum_var_exp, where='mid', label='cumulative explained variance')\n",
    "    plt.ylabel('Explained variance ratio')\n",
    "    plt.xlabel('Principal components')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "this is ordinary least square regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 10) (16, 1)\n",
      "(4, 10) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(principalComponents, df_y_si, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# fit a model\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real, predictions]\n",
      "[[2.62 3.071153127423933]\n",
      " [1.38 1.1167439690023766]\n",
      " [1.59 1.6175511010014416]\n",
      " [1.8 1.803715399015911]]\n"
     ]
    }
   ],
   "source": [
    "b=np.append(y_test, predictions, axis=1)\n",
    "\n",
    "print(\"[real, predictions]\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.2615414640153909\n",
      "R^2:  0.6904361481009691\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R^2: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Least Square Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"   \\n    # Fit a line to the CV vs response\\n    z = np.polyfit(y, y_c, 1)\\n    with plt.style.context(('ggplot')):\\n        fig, ax = plt.subplots(figsize=(9, 5))\\n        ax.scatter(y_c, y, c='red', edgecolors='k')\\n        #Plot the best fit line\\n        ax.plot(np.polyval(z,y), y, c='blue', linewidth=1)\\n        #Plot the ideal 1:1 line\\n        ax.plot(y, y, color='green', linewidth=1)\\n        plt.title('$R^{2}$ (CV): '+str(score_cv))\\n        plt.xlabel('Predicted $^{\\\\circ}$Brix')\\n        plt.ylabel('Measured $^{\\\\circ}$Brix')\\n        plt.show()\\n    return\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def optimise_pls_cv(X, y, n_comp, plot_components=True):\n",
    "    '''Run PLS including a variable number of components, up to n_comp,\n",
    "       and calculate MSE '''\n",
    "    mse = []\n",
    "    component = np.arange(1, n_comp)\n",
    "    for i in component:\n",
    "        pls = PLSRegression(n_components=i)\n",
    "        # Cross-validation\n",
    "        y_cv = cross_val_predict(pls, X, y, cv=10)\n",
    "        mse.append(mean_squared_error(y, y_cv))\n",
    "        comp = 100*(i+1)/40\n",
    "        # Trick to update status on the same line\n",
    "        stdout.write(\"\\r%d%% completed\" % comp)\n",
    "        stdout.flush()\n",
    "    stdout.write(\"\\n\")\n",
    "    # Calculate and print the position of minimum in MSE\n",
    "    msemin = np.argmin(mse)\n",
    "    print(\"Suggested number of components: \", msemin+1)\n",
    "    stdout.write(\"\\n\")\n",
    "    if plot_components is True:\n",
    "        with plt.style.context(('ggplot')):\n",
    "            plt.plot(component, np.array(mse), '-v', color = 'blue', mfc='blue')\n",
    "            plt.plot(component[msemin], np.array(mse)[msemin], 'P', ms=10, mfc='red')\n",
    "            plt.xlabel('Number of PLS components')\n",
    "            plt.ylabel('MSE')\n",
    "            plt.title('PLS')\n",
    "            plt.xlim(left=-1)\n",
    "        plt.show()\n",
    "    # Define PLS object with optimal number of components\n",
    "    pls_opt = PLSRegression(n_components=msemin+1)\n",
    "    # Fir to the entire dataset\n",
    "    pls_opt.fit(X, y)\n",
    "    y_c = pls_opt.predict(X)\n",
    "    # Cross-validation\n",
    "    y_cv = cross_val_predict(pls_opt, X, y, cv=10)\n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    "    # Calculate mean squared error for calibration and cross validation\n",
    "    mse_c = mean_squared_error(y, y_c)\n",
    "    mse_cv = mean_squared_error(y, y_cv)\n",
    "    print('R2 calib: %5.3f'  % score_c)\n",
    "    print('R2 CV: %5.3f'  % score_cv)\n",
    "    print('MSE calib: %5.3f' % mse_c)\n",
    "    print('MSE CV: %5.3f' % mse_cv)\n",
    "    \n",
    "    return\n",
    "    # Plot regression and figures of merit\n",
    "    rangey = max(y) - min(y)\n",
    "    rangex = max(y_c) - min(y_c)\n",
    "\"\"\"   \n",
    "    # Fit a line to the CV vs response\n",
    "    z = np.polyfit(y, y_c, 1)\n",
    "    with plt.style.context(('ggplot')):\n",
    "        fig, ax = plt.subplots(figsize=(9, 5))\n",
    "        ax.scatter(y_c, y, c='red', edgecolors='k')\n",
    "        #Plot the best fit line\n",
    "        ax.plot(np.polyval(z,y), y, c='blue', linewidth=1)\n",
    "        #Plot the ideal 1:1 line\n",
    "        ax.plot(y, y, color='green', linewidth=1)\n",
    "        plt.title('$R^{2}$ (CV): '+str(score_cv))\n",
    "        plt.xlabel('Predicted $^{\\circ}$Brix')\n",
    "        plt.ylabel('Measured $^{\\circ}$Brix')\n",
    "        plt.show()\n",
    "    return\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% completed\n",
      "Suggested number of components:  10\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 calib: 1.000\n",
      "R2 CV: 0.690\n",
      "MSE calib: 0.000\n",
      "MSE CV: 0.134\n"
     ]
    }
   ],
   "source": [
    "optimise_pls_cv(x_df,df_y_si, 40, plot_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 4094) (16, 1)\n",
      "(4, 4094) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_df, df_y_si, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% completed\n",
      "Suggested number of components:  9\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 calib: 0.999\n",
      "R2 CV: 0.565\n",
      "MSE calib: 0.000\n",
      "MSE CV: 0.214\n"
     ]
    }
   ],
   "source": [
    "optimise_pls_cv(X_train,y_train, 40, plot_components=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_pred:  0.7494225314453108\n",
      "R2_cv:  0.565446374026515\n",
      "\n",
      "TEST\n",
      " [real, predictions]\n",
      "[[1.5 1.1949480732115378]\n",
      " [2.61 2.7341989769612]\n",
      " [2.46 2.24264566960154]\n",
      " [2.49 2.2827371090655926]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define PLS object\n",
    "pls = PLSRegression(n_components=9)\n",
    "# Fit\n",
    "pls.fit(X_train, y_train)\n",
    "# Cross-validation\n",
    "y_pred = pls.predict(X_test)\n",
    "y_pred1 = pls.predict(X_train)\n",
    "\n",
    "# Cross-validation\n",
    "y_cv = cross_val_predict(pls, X_train, y_train, cv=10)\n",
    "\n",
    "# Calculate scores for calibration and cross-validation\n",
    "score_pred = r2_score(y_test, y_pred)\n",
    "score_cv = r2_score(y_train, y_cv)\n",
    "\n",
    "print(\"R2_pred: \", score_pred)\n",
    "print(\"R2_cv: \",score_cv)\n",
    "print(\"\")\n",
    "\n",
    "b=np.append(y_test, y_pred, axis=1)\n",
    "\n",
    "print(\"TEST\\n [real, predictions]\")\n",
    "print(b)\n",
    "print(\"\")\n",
    "\n",
    "c=np.append(y_train, y_pred1, axis=1)\n",
    "\n",
    "#print(\"TRAIN\\n [real, predictions]\")\n",
    "#print(c)\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.scatter(y_train, y_pred1)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet,ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.0001, R2:1.00, MSE:0.07, RMSE:0.27\n",
      "Alpha:0.0010, R2:1.00, MSE:0.02, RMSE:0.15\n",
      "Alpha:0.0100, R2:1.00, MSE:0.06, RMSE:0.24\n",
      "Alpha:0.1000, R2:1.00, MSE:0.07, RMSE:0.26\n",
      "Alpha:0.3000, R2:1.00, MSE:0.02, RMSE:0.13\n",
      "Alpha:0.5000, R2:1.00, MSE:0.00, RMSE:0.03\n",
      "Alpha:0.7000, R2:1.00, MSE:0.00, RMSE:0.03\n",
      "Alpha:1.0000, R2:1.00, MSE:0.00, RMSE:0.03\n"
     ]
    }
   ],
   "source": [
    "for a in alphas:\n",
    "    model = ElasticNet(alpha=a).fit(X_train,y_train)   \n",
    "    score = model.score(X_train, y_train)\n",
    "    pred_y = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, pred_y)   \n",
    "    print(\"Alpha:{0:.4f}, R2:{1:.2f}, MSE:{2:.2f}, RMSE:{3:.2f}\".format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9999992080529491\n",
      "RMSE:  0.23785190057536498\n",
      "R^2:  0.7145994369665113\n"
     ]
    }
   ],
   "source": [
    "model = ElasticNet(alpha=0.01).fit(X_train,y_train)   \n",
    "score = model.score(X_train, y_train)\n",
    "print(\"Train score: \", score)\n",
    "pred_y = model.predict(X_test)\n",
    "\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test, pred_y))\n",
    "r2 = r2_score(y_test, pred_y)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R^2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, Reshape #, MaxPooling1D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.optimizers import Adam\n",
    "#for CNN\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import normalize, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               1048320   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,065,825\n",
      "Trainable params: 1,065,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DROPOUT = 0.5\n",
    "\n",
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=4094, activation='relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "[INFO] training model...\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 37 samples, validate on 10 samples\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 3.6068 - val_loss: 3.3483\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.6045 - val_loss: 3.3471\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.6046 - val_loss: 3.3459\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 0s 566us/step - loss: 3.6012 - val_loss: 3.3447\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.6000 - val_loss: 3.3435\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.5953 - val_loss: 3.3423\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 0s 971us/step - loss: 3.5948 - val_loss: 3.3413\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 0s 728us/step - loss: 3.5969 - val_loss: 3.3407\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.5973 - val_loss: 3.3399\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.5942 - val_loss: 3.3390\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5938 - val_loss: 3.3377\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5919 - val_loss: 3.3362\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5900 - val_loss: 3.3349\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.5866 - val_loss: 3.3333\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5863 - val_loss: 3.3317\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5868 - val_loss: 3.3303\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5896 - val_loss: 3.3288\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.5850 - val_loss: 3.3273\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5782 - val_loss: 3.3258\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5812 - val_loss: 3.3241\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 0s 620us/step - loss: 3.5806 - val_loss: 3.3225\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.5783 - val_loss: 3.3207\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5768 - val_loss: 3.3189\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5766 - val_loss: 3.3173\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.5762 - val_loss: 3.3156\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5743 - val_loss: 3.3138\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.5714 - val_loss: 3.3122\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.5676 - val_loss: 3.3106\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5735 - val_loss: 3.3091\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5658 - val_loss: 3.3075\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.5664 - val_loss: 3.3060\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.5664 - val_loss: 3.3045\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5663 - val_loss: 3.3031\n",
      "Epoch 34/200\n",
      "37/37 [==============================] - 0s 566us/step - loss: 3.5635 - val_loss: 3.3014\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5592 - val_loss: 3.2997\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5576 - val_loss: 3.2982\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5533 - val_loss: 3.2966\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 0s 647us/step - loss: 3.5528 - val_loss: 3.2950\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5515 - val_loss: 3.2935\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5524 - val_loss: 3.2921\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 0s 566us/step - loss: 3.5505 - val_loss: 3.2907\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5434 - val_loss: 3.2890\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5446 - val_loss: 3.2875\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5422 - val_loss: 3.2858\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 0s 566us/step - loss: 3.5422 - val_loss: 3.2839\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.5413 - val_loss: 3.2820\n",
      "Epoch 47/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5401 - val_loss: 3.2802\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 0s 593us/step - loss: 3.5381 - val_loss: 3.2783\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5404 - val_loss: 3.2766\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.5331 - val_loss: 3.2748\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5319 - val_loss: 3.2730\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 0s 566us/step - loss: 3.5292 - val_loss: 3.2712\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.5249 - val_loss: 3.2693\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 0s 809us/step - loss: 3.5247 - val_loss: 3.2674\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 0s 647us/step - loss: 3.5278 - val_loss: 3.2656\n",
      "Epoch 56/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.5218 - val_loss: 3.2637\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.5199 - val_loss: 3.2618\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.5219 - val_loss: 3.2599\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 0s 472us/step - loss: 3.5170 - val_loss: 3.2580\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 0s 540us/step - loss: 3.5178 - val_loss: 3.2561\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.5202 - val_loss: 3.2542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "37/37 [==============================] - 0s 513us/step - loss: 3.5115 - val_loss: 3.2523\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 0s 540us/step - loss: 3.5061 - val_loss: 3.2503\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.5079 - val_loss: 3.2484\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 0s 500us/step - loss: 3.5115 - val_loss: 3.2466\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 0s 472us/step - loss: 3.5060 - val_loss: 3.2446\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 0s 499us/step - loss: 3.5067 - val_loss: 3.2427\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 0s 445us/step - loss: 3.5002 - val_loss: 3.2408\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.5061 - val_loss: 3.2390\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.4979 - val_loss: 3.2370\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.4970 - val_loss: 3.2350\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 0s 635us/step - loss: 3.4955 - val_loss: 3.2330\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.4964 - val_loss: 3.2311\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.4887 - val_loss: 3.2290\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.4897 - val_loss: 3.2270\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 0s 540us/step - loss: 3.4892 - val_loss: 3.2250\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 0s 553us/step - loss: 3.4916 - val_loss: 3.2230\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.4827 - val_loss: 3.2209\n",
      "Epoch 79/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4861 - val_loss: 3.2187\n",
      "Epoch 80/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4786 - val_loss: 3.2165\n",
      "Epoch 81/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4777 - val_loss: 3.2144\n",
      "Epoch 82/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4755 - val_loss: 3.2122\n",
      "Epoch 83/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.4778 - val_loss: 3.2101\n",
      "Epoch 84/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4755 - val_loss: 3.2079\n",
      "Epoch 85/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4653 - val_loss: 3.2056\n",
      "Epoch 86/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4676 - val_loss: 3.2034\n",
      "Epoch 87/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4636 - val_loss: 3.2012\n",
      "Epoch 88/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4570 - val_loss: 3.1989\n",
      "Epoch 89/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4632 - val_loss: 3.1965\n",
      "Epoch 90/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4611 - val_loss: 3.1942\n",
      "Epoch 91/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4498 - val_loss: 3.1919\n",
      "Epoch 92/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4587 - val_loss: 3.1897\n",
      "Epoch 93/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4571 - val_loss: 3.1873\n",
      "Epoch 94/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4528 - val_loss: 3.1850\n",
      "Epoch 95/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4497 - val_loss: 3.1827\n",
      "Epoch 96/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4500 - val_loss: 3.1803\n",
      "Epoch 97/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4424 - val_loss: 3.1779\n",
      "Epoch 98/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4387 - val_loss: 3.1754\n",
      "Epoch 99/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4347 - val_loss: 3.1729\n",
      "Epoch 100/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4345 - val_loss: 3.1704\n",
      "Epoch 101/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.4407 - val_loss: 3.1680\n",
      "Epoch 102/200\n",
      "37/37 [==============================] - 0s 566us/step - loss: 3.4308 - val_loss: 3.1655\n",
      "Epoch 103/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.4213 - val_loss: 3.1628\n",
      "Epoch 104/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.4186 - val_loss: 3.1601\n",
      "Epoch 105/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.4208 - val_loss: 3.1575\n",
      "Epoch 106/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4278 - val_loss: 3.1550\n",
      "Epoch 107/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4230 - val_loss: 3.1523\n",
      "Epoch 108/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.4225 - val_loss: 3.1497\n",
      "Epoch 109/200\n",
      "37/37 [==============================] - 0s 513us/step - loss: 3.4147 - val_loss: 3.1471\n",
      "Epoch 110/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.4111 - val_loss: 3.1445\n",
      "Epoch 111/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.4098 - val_loss: 3.1419\n",
      "Epoch 112/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.4040 - val_loss: 3.1391\n",
      "Epoch 113/200\n",
      "37/37 [==============================] - 0s 461us/step - loss: 3.4185 - val_loss: 3.1366\n",
      "Epoch 114/200\n",
      "37/37 [==============================] - 0s 621us/step - loss: 3.4057 - val_loss: 3.1340\n",
      "Epoch 115/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.4081 - val_loss: 3.1312\n",
      "Epoch 116/200\n",
      "37/37 [==============================] - 0s 541us/step - loss: 3.3903 - val_loss: 3.1284\n",
      "Epoch 117/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.3874 - val_loss: 3.1255\n",
      "Epoch 118/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.3885 - val_loss: 3.1227\n",
      "Epoch 119/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.3860 - val_loss: 3.1199\n",
      "Epoch 120/200\n",
      "37/37 [==============================] - 0s 541us/step - loss: 3.3782 - val_loss: 3.1170\n",
      "Epoch 121/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.3861 - val_loss: 3.1141\n",
      "Epoch 122/200\n",
      "37/37 [==============================] - 0s 446us/step - loss: 3.3657 - val_loss: 3.1110\n",
      "Epoch 123/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.3770 - val_loss: 3.1081\n",
      "Epoch 124/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.3719 - val_loss: 3.1051\n",
      "Epoch 125/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.3628 - val_loss: 3.1021\n",
      "Epoch 126/200\n",
      "37/37 [==============================] - 0s 488us/step - loss: 3.3637 - val_loss: 3.0990\n",
      "Epoch 127/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.3647 - val_loss: 3.0960\n",
      "Epoch 128/200\n",
      "37/37 [==============================] - 0s 567us/step - loss: 3.3672 - val_loss: 3.0931\n",
      "Epoch 129/200\n",
      "37/37 [==============================] - 0s 554us/step - loss: 3.3610 - val_loss: 3.0900\n",
      "Epoch 130/200\n",
      "37/37 [==============================] - 0s 539us/step - loss: 3.3522 - val_loss: 3.0868\n",
      "Epoch 131/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.3474 - val_loss: 3.0835\n",
      "Epoch 132/200\n",
      "37/37 [==============================] - 0s 512us/step - loss: 3.3580 - val_loss: 3.0805\n",
      "Epoch 133/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.3402 - val_loss: 3.0772\n",
      "Epoch 134/200\n",
      "37/37 [==============================] - 0s 485us/step - loss: 3.3468 - val_loss: 3.0740\n",
      "Epoch 135/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.3308 - val_loss: 3.0707\n",
      "Epoch 136/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.3238 - val_loss: 3.0672\n",
      "Epoch 137/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.3371 - val_loss: 3.0639\n",
      "Epoch 138/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.3202 - val_loss: 3.0604\n",
      "Epoch 139/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.3273 - val_loss: 3.0570\n",
      "Epoch 140/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.3144 - val_loss: 3.0535\n",
      "Epoch 141/200\n",
      "37/37 [==============================] - 0s 541us/step - loss: 3.2992 - val_loss: 3.0498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.3151 - val_loss: 3.0463\n",
      "Epoch 143/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.3003 - val_loss: 3.0426\n",
      "Epoch 144/200\n",
      "37/37 [==============================] - 0s 513us/step - loss: 3.2980 - val_loss: 3.0390\n",
      "Epoch 145/200\n",
      "37/37 [==============================] - 0s 515us/step - loss: 3.3081 - val_loss: 3.0355\n",
      "Epoch 146/200\n",
      "37/37 [==============================] - 0s 488us/step - loss: 3.2945 - val_loss: 3.0318\n",
      "Epoch 147/200\n",
      "37/37 [==============================] - 0s 433us/step - loss: 3.2913 - val_loss: 3.0281\n",
      "Epoch 148/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.2824 - val_loss: 3.0243\n",
      "Epoch 149/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.2808 - val_loss: 3.0205\n",
      "Epoch 150/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.2749 - val_loss: 3.0166\n",
      "Epoch 151/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.2893 - val_loss: 3.0126\n",
      "Epoch 152/200\n",
      "37/37 [==============================] - 0s 461us/step - loss: 3.2864 - val_loss: 3.0087\n",
      "Epoch 153/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.2757 - val_loss: 3.0046\n",
      "Epoch 154/200\n",
      "37/37 [==============================] - 0s 513us/step - loss: 3.2706 - val_loss: 3.0004\n",
      "Epoch 155/200\n",
      "37/37 [==============================] - 0s 461us/step - loss: 3.2657 - val_loss: 2.9960\n",
      "Epoch 156/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.2552 - val_loss: 2.9917\n",
      "Epoch 157/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.2673 - val_loss: 2.9874\n",
      "Epoch 158/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.2486 - val_loss: 2.9828\n",
      "Epoch 159/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.2460 - val_loss: 2.9784\n",
      "Epoch 160/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.2432 - val_loss: 2.9738\n",
      "Epoch 161/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.2412 - val_loss: 2.9693\n",
      "Epoch 162/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.2086 - val_loss: 2.9644\n",
      "Epoch 163/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.2313 - val_loss: 2.9596\n",
      "Epoch 164/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.2394 - val_loss: 2.9551\n",
      "Epoch 165/200\n",
      "37/37 [==============================] - 0s 621us/step - loss: 3.2026 - val_loss: 2.9500\n",
      "Epoch 166/200\n",
      "37/37 [==============================] - 0s 595us/step - loss: 3.2251 - val_loss: 2.9452\n",
      "Epoch 167/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.2116 - val_loss: 2.9405\n",
      "Epoch 168/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.2147 - val_loss: 2.9356\n",
      "Epoch 169/200\n",
      "37/37 [==============================] - 0s 811us/step - loss: 3.2046 - val_loss: 2.9306\n",
      "Epoch 170/200\n",
      "37/37 [==============================] - 0s 623us/step - loss: 3.2123 - val_loss: 2.9257\n",
      "Epoch 171/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.1832 - val_loss: 2.9204\n",
      "Epoch 172/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.1758 - val_loss: 2.9151\n",
      "Epoch 173/200\n",
      "37/37 [==============================] - 0s 513us/step - loss: 3.1895 - val_loss: 2.9101\n",
      "Epoch 174/200\n",
      "37/37 [==============================] - 0s 527us/step - loss: 3.1714 - val_loss: 2.9048\n",
      "Epoch 175/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.1570 - val_loss: 2.8996\n",
      "Epoch 176/200\n",
      "37/37 [==============================] - 0s 473us/step - loss: 3.1703 - val_loss: 2.8942\n",
      "Epoch 177/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.1787 - val_loss: 2.8890\n",
      "Epoch 178/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.1627 - val_loss: 2.8838\n",
      "Epoch 179/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.1527 - val_loss: 2.8784\n",
      "Epoch 180/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.1566 - val_loss: 2.8729\n",
      "Epoch 181/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.1616 - val_loss: 2.8675\n",
      "Epoch 182/200\n",
      "37/37 [==============================] - 0s 461us/step - loss: 3.1284 - val_loss: 2.8617\n",
      "Epoch 183/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.1359 - val_loss: 2.8561\n",
      "Epoch 184/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.1210 - val_loss: 2.8503\n",
      "Epoch 185/200\n",
      "37/37 [==============================] - 0s 459us/step - loss: 3.0972 - val_loss: 2.8442\n",
      "Epoch 186/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.1262 - val_loss: 2.8385\n",
      "Epoch 187/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.1082 - val_loss: 2.8326\n",
      "Epoch 188/200\n",
      "37/37 [==============================] - 0s 514us/step - loss: 3.0835 - val_loss: 2.8263\n",
      "Epoch 189/200\n",
      "37/37 [==============================] - 0s 513us/step - loss: 3.1169 - val_loss: 2.8204\n",
      "Epoch 190/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.0753 - val_loss: 2.8142\n",
      "Epoch 191/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.0752 - val_loss: 2.8080\n",
      "Epoch 192/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.1045 - val_loss: 2.8021\n",
      "Epoch 193/200\n",
      "37/37 [==============================] - 0s 488us/step - loss: 3.0476 - val_loss: 2.7956\n",
      "Epoch 194/200\n",
      "37/37 [==============================] - 0s 486us/step - loss: 3.0657 - val_loss: 2.7892\n",
      "Epoch 195/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.0514 - val_loss: 2.7827\n",
      "Epoch 196/200\n",
      "37/37 [==============================] - 0s 472us/step - loss: 3.0193 - val_loss: 2.7760\n",
      "Epoch 197/200\n",
      "37/37 [==============================] - 0s 458us/step - loss: 3.0329 - val_loss: 2.7695\n",
      "Epoch 198/200\n",
      "37/37 [==============================] - 0s 460us/step - loss: 3.0316 - val_loss: 2.7630\n",
      "Epoch 199/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.0637 - val_loss: 2.7568\n",
      "Epoch 200/200\n",
      "37/37 [==============================] - 0s 487us/step - loss: 3.0411 - val_loss: 2.7503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c99437cc8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Adam(lr=2e-3, decay=1e-3 / 200)\n",
    "#model.compile(loss=\"mean_squared_error\", optimizer=opt)\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.Adadelta(lr=0.01))    \n",
    "    \n",
    "#model.compile(optimizer = \"opt\", loss = root_mean_squared_error, metrics =[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(X_train, y_train, epochs=200, validation_split=0.2, batch_size=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37 samples, validate on 10 samples\n",
      "Epoch 1/600\n",
      " - 1s - loss: 0.4555 - val_loss: 1.5627\n",
      "Epoch 2/600\n",
      " - 1s - loss: 0.4546 - val_loss: 1.5401\n",
      "Epoch 3/600\n",
      " - 1s - loss: 0.4720 - val_loss: 1.5792\n",
      "Epoch 4/600\n",
      " - 1s - loss: 0.4518 - val_loss: 1.5307\n",
      "Epoch 5/600\n",
      " - 1s - loss: 0.4465 - val_loss: 1.5420\n",
      "Epoch 6/600\n",
      " - 1s - loss: 0.4340 - val_loss: 1.5079\n",
      "Epoch 7/600\n",
      " - 1s - loss: 0.4562 - val_loss: 1.5052\n",
      "Epoch 8/600\n",
      " - 1s - loss: 0.4474 - val_loss: 1.4902\n",
      "Epoch 9/600\n",
      " - 1s - loss: 0.4409 - val_loss: 1.4584\n",
      "Epoch 10/600\n",
      " - 1s - loss: 0.4424 - val_loss: 1.4471\n",
      "Epoch 11/600\n",
      " - 1s - loss: 0.4418 - val_loss: 1.5361\n",
      "Epoch 12/600\n",
      " - 1s - loss: 0.4470 - val_loss: 1.5424\n",
      "Epoch 13/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.5291\n",
      "Epoch 14/600\n",
      " - 1s - loss: 0.4433 - val_loss: 1.5477\n",
      "Epoch 15/600\n",
      " - 1s - loss: 0.4445 - val_loss: 1.5546\n",
      "Epoch 16/600\n",
      " - 1s - loss: 0.4454 - val_loss: 1.5831\n",
      "Epoch 17/600\n",
      " - 1s - loss: 0.4408 - val_loss: 1.5605\n",
      "Epoch 18/600\n",
      " - 1s - loss: 0.4538 - val_loss: 1.5612\n",
      "Epoch 19/600\n",
      " - 1s - loss: 0.4502 - val_loss: 1.5299\n",
      "Epoch 20/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.5143\n",
      "Epoch 21/600\n",
      " - 1s - loss: 0.4511 - val_loss: 1.5278\n",
      "Epoch 22/600\n",
      " - 1s - loss: 0.4341 - val_loss: 1.5813\n",
      "Epoch 23/600\n",
      " - 1s - loss: 0.4468 - val_loss: 1.5692\n",
      "Epoch 24/600\n",
      " - 1s - loss: 0.4559 - val_loss: 1.5837\n",
      "Epoch 25/600\n",
      " - 1s - loss: 0.4507 - val_loss: 1.5863\n",
      "Epoch 26/600\n",
      " - 1s - loss: 0.4348 - val_loss: 1.5775\n",
      "Epoch 27/600\n",
      " - 1s - loss: 0.4449 - val_loss: 1.5185\n",
      "Epoch 28/600\n",
      " - 1s - loss: 0.4388 - val_loss: 1.5581\n",
      "Epoch 29/600\n",
      " - 1s - loss: 0.4407 - val_loss: 1.5737\n",
      "Epoch 30/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.5870\n",
      "Epoch 31/600\n",
      " - 1s - loss: 0.4366 - val_loss: 1.5815\n",
      "Epoch 32/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.5331\n",
      "Epoch 33/600\n",
      " - 1s - loss: 0.4475 - val_loss: 1.5258\n",
      "Epoch 34/600\n",
      " - 2s - loss: 0.4537 - val_loss: 1.5476\n",
      "Epoch 35/600\n",
      " - 1s - loss: 0.4509 - val_loss: 1.5561\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 36/600\n",
      " - 1s - loss: 0.4288 - val_loss: 1.5681\n",
      "Epoch 37/600\n",
      " - 1s - loss: 0.4624 - val_loss: 1.5576\n",
      "Epoch 38/600\n",
      " - 1s - loss: 0.4346 - val_loss: 1.5404\n",
      "Epoch 39/600\n",
      " - 1s - loss: 0.4429 - val_loss: 1.5350\n",
      "Epoch 40/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5132\n",
      "Epoch 41/600\n",
      " - 1s - loss: 0.4403 - val_loss: 1.5057\n",
      "Epoch 42/600\n",
      " - 1s - loss: 0.4459 - val_loss: 1.5095\n",
      "Epoch 43/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5008\n",
      "Epoch 44/600\n",
      " - 1s - loss: 0.4304 - val_loss: 1.5054\n",
      "Epoch 45/600\n",
      " - 1s - loss: 0.4251 - val_loss: 1.5113\n",
      "Epoch 46/600\n",
      " - 1s - loss: 0.4405 - val_loss: 1.5297\n",
      "Epoch 47/600\n",
      " - 1s - loss: 0.4392 - val_loss: 1.5435\n",
      "Epoch 48/600\n",
      " - 1s - loss: 0.4460 - val_loss: 1.5571\n",
      "Epoch 49/600\n",
      " - 1s - loss: 0.4425 - val_loss: 1.5320\n",
      "Epoch 50/600\n",
      " - 1s - loss: 0.4456 - val_loss: 1.5258\n",
      "Epoch 51/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.5202\n",
      "Epoch 52/600\n",
      " - 1s - loss: 0.4424 - val_loss: 1.5253\n",
      "Epoch 53/600\n",
      " - 1s - loss: 0.4208 - val_loss: 1.5266\n",
      "Epoch 54/600\n",
      " - 1s - loss: 0.4266 - val_loss: 1.5317\n",
      "Epoch 55/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.5110\n",
      "Epoch 56/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.5121\n",
      "Epoch 57/600\n",
      " - 1s - loss: 0.4428 - val_loss: 1.5033\n",
      "Epoch 58/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.5203\n",
      "Epoch 59/600\n",
      " - 1s - loss: 0.4223 - val_loss: 1.5083\n",
      "Epoch 60/600\n",
      " - 1s - loss: 0.4615 - val_loss: 1.5163\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 61/600\n",
      " - 1s - loss: 0.4411 - val_loss: 1.5156\n",
      "Epoch 62/600\n",
      " - 1s - loss: 0.4350 - val_loss: 1.5111\n",
      "Epoch 63/600\n",
      " - 1s - loss: 0.4297 - val_loss: 1.5146\n",
      "Epoch 64/600\n",
      " - 1s - loss: 0.4220 - val_loss: 1.5092\n",
      "Epoch 65/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.5184\n",
      "Epoch 66/600\n",
      " - 1s - loss: 0.4380 - val_loss: 1.5242\n",
      "Epoch 67/600\n",
      " - 1s - loss: 0.4217 - val_loss: 1.5264\n",
      "Epoch 68/600\n",
      " - 1s - loss: 0.4443 - val_loss: 1.5261\n",
      "Epoch 69/600\n",
      " - 2s - loss: 0.4377 - val_loss: 1.5196\n",
      "Epoch 70/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.5151\n",
      "Epoch 71/600\n",
      " - 1s - loss: 0.4438 - val_loss: 1.5140\n",
      "Epoch 72/600\n",
      " - 1s - loss: 0.4233 - val_loss: 1.5113\n",
      "Epoch 73/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5081\n",
      "Epoch 74/600\n",
      " - 1s - loss: 0.4421 - val_loss: 1.5108\n",
      "Epoch 75/600\n",
      " - 1s - loss: 0.4421 - val_loss: 1.5130\n",
      "Epoch 76/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.5080\n",
      "Epoch 77/600\n",
      " - 1s - loss: 0.4483 - val_loss: 1.5104\n",
      "Epoch 78/600\n",
      " - 1s - loss: 0.4310 - val_loss: 1.5157\n",
      "Epoch 79/600\n",
      " - 1s - loss: 0.4208 - val_loss: 1.5125\n",
      "Epoch 80/600\n",
      " - 1s - loss: 0.4371 - val_loss: 1.5115\n",
      "Epoch 81/600\n",
      " - 1s - loss: 0.4264 - val_loss: 1.5180\n",
      "Epoch 82/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.5166\n",
      "Epoch 83/600\n",
      " - 1s - loss: 0.4358 - val_loss: 1.5189\n",
      "Epoch 84/600\n",
      " - 1s - loss: 0.4242 - val_loss: 1.5191\n",
      "Epoch 85/600\n",
      " - 1s - loss: 0.4489 - val_loss: 1.5232\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 86/600\n",
      " - 1s - loss: 0.4376 - val_loss: 1.5261\n",
      "Epoch 87/600\n",
      " - 1s - loss: 0.4426 - val_loss: 1.5268\n",
      "Epoch 88/600\n",
      " - 1s - loss: 0.4409 - val_loss: 1.5303\n",
      "Epoch 89/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.5312\n",
      "Epoch 90/600\n",
      " - 1s - loss: 0.4269 - val_loss: 1.5344\n",
      "Epoch 91/600\n",
      " - 1s - loss: 0.4351 - val_loss: 1.5335\n",
      "Epoch 92/600\n",
      " - 1s - loss: 0.4316 - val_loss: 1.5324\n",
      "Epoch 93/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.5325\n",
      "Epoch 94/600\n",
      " - 1s - loss: 0.4299 - val_loss: 1.5336\n",
      "Epoch 95/600\n",
      " - 1s - loss: 0.4317 - val_loss: 1.5326\n",
      "Epoch 96/600\n",
      " - 1s - loss: 0.4385 - val_loss: 1.5341\n",
      "Epoch 97/600\n",
      " - 1s - loss: 0.4313 - val_loss: 1.5357\n",
      "Epoch 98/600\n",
      " - 1s - loss: 0.4472 - val_loss: 1.5346\n",
      "Epoch 99/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.5302\n",
      "Epoch 100/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.5304\n",
      "Epoch 101/600\n",
      " - 1s - loss: 0.4426 - val_loss: 1.5328\n",
      "Epoch 102/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.5344\n",
      "Epoch 103/600\n",
      " - 1s - loss: 0.4440 - val_loss: 1.5307\n",
      "Epoch 104/600\n",
      " - 1s - loss: 0.4513 - val_loss: 1.5286\n",
      "Epoch 105/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.5267\n",
      "Epoch 106/600\n",
      " - 1s - loss: 0.4338 - val_loss: 1.5269\n",
      "Epoch 107/600\n",
      " - 1s - loss: 0.4292 - val_loss: 1.5284\n",
      "Epoch 108/600\n",
      " - 1s - loss: 0.4312 - val_loss: 1.5285\n",
      "Epoch 109/600\n",
      " - 1s - loss: 0.4386 - val_loss: 1.5250\n",
      "Epoch 110/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.5276\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 111/600\n",
      " - 1s - loss: 0.4419 - val_loss: 1.5263\n",
      "Epoch 112/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.5282\n",
      "Epoch 113/600\n",
      " - 1s - loss: 0.4335 - val_loss: 1.5284\n",
      "Epoch 114/600\n",
      " - 1s - loss: 0.4424 - val_loss: 1.5283\n",
      "Epoch 115/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.5286\n",
      "Epoch 116/600\n",
      " - 1s - loss: 0.4303 - val_loss: 1.5280\n",
      "Epoch 117/600\n",
      " - 1s - loss: 0.4214 - val_loss: 1.5283\n",
      "Epoch 118/600\n",
      " - 1s - loss: 0.4352 - val_loss: 1.5289\n",
      "Epoch 119/600\n",
      " - 1s - loss: 0.4242 - val_loss: 1.5304\n",
      "Epoch 120/600\n",
      " - 1s - loss: 0.4312 - val_loss: 1.5301\n",
      "Epoch 121/600\n",
      " - 1s - loss: 0.4407 - val_loss: 1.5304\n",
      "Epoch 122/600\n",
      " - 1s - loss: 0.4285 - val_loss: 1.5303\n",
      "Epoch 123/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.5298\n",
      "Epoch 124/600\n",
      " - 1s - loss: 0.4250 - val_loss: 1.5295\n",
      "Epoch 125/600\n",
      " - 1s - loss: 0.4463 - val_loss: 1.5285\n",
      "Epoch 126/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.5299\n",
      "Epoch 127/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.5283\n",
      "Epoch 128/600\n",
      " - 1s - loss: 0.4392 - val_loss: 1.5275\n",
      "Epoch 129/600\n",
      " - 1s - loss: 0.4402 - val_loss: 1.5287\n",
      "Epoch 130/600\n",
      " - 1s - loss: 0.4467 - val_loss: 1.5297\n",
      "Epoch 131/600\n",
      " - 1s - loss: 0.4301 - val_loss: 1.5293\n",
      "Epoch 132/600\n",
      " - 1s - loss: 0.4460 - val_loss: 1.5279\n",
      "Epoch 133/600\n",
      " - 1s - loss: 0.4410 - val_loss: 1.5263\n",
      "Epoch 134/600\n",
      " - 1s - loss: 0.4443 - val_loss: 1.5245\n",
      "Epoch 135/600\n",
      " - 1s - loss: 0.4526 - val_loss: 1.5238\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 136/600\n",
      " - 1s - loss: 0.4455 - val_loss: 1.5235\n",
      "Epoch 137/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.5240\n",
      "Epoch 138/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.5240\n",
      "Epoch 139/600\n",
      " - 1s - loss: 0.4295 - val_loss: 1.5242\n",
      "Epoch 140/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.5237\n",
      "Epoch 141/600\n",
      " - 1s - loss: 0.4480 - val_loss: 1.5244\n",
      "Epoch 142/600\n",
      " - 1s - loss: 0.4363 - val_loss: 1.5240\n",
      "Epoch 143/600\n",
      " - 1s - loss: 0.4470 - val_loss: 1.5243\n",
      "Epoch 144/600\n",
      " - 1s - loss: 0.4430 - val_loss: 1.5251\n",
      "Epoch 145/600\n",
      " - 1s - loss: 0.4305 - val_loss: 1.5258\n",
      "Epoch 146/600\n",
      " - 1s - loss: 0.4298 - val_loss: 1.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/600\n",
      " - 1s - loss: 0.4302 - val_loss: 1.5266\n",
      "Epoch 148/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.5270\n",
      "Epoch 149/600\n",
      " - 1s - loss: 0.4239 - val_loss: 1.5273\n",
      "Epoch 150/600\n",
      " - 1s - loss: 0.4376 - val_loss: 1.5266\n",
      "Epoch 151/600\n",
      " - 1s - loss: 0.4414 - val_loss: 1.5272\n",
      "Epoch 152/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.5276\n",
      "Epoch 153/600\n",
      " - 1s - loss: 0.4285 - val_loss: 1.5278\n",
      "Epoch 154/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.5277\n",
      "Epoch 155/600\n",
      " - 1s - loss: 0.4462 - val_loss: 1.5271\n",
      "Epoch 156/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.5268\n",
      "Epoch 157/600\n",
      " - 1s - loss: 0.4324 - val_loss: 1.5270\n",
      "Epoch 158/600\n",
      " - 1s - loss: 0.4311 - val_loss: 1.5266\n",
      "Epoch 159/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.5263\n",
      "Epoch 160/600\n",
      " - 1s - loss: 0.4452 - val_loss: 1.5257\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 161/600\n",
      " - 1s - loss: 0.4243 - val_loss: 1.5258\n",
      "Epoch 162/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5258\n",
      "Epoch 163/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.5258\n",
      "Epoch 164/600\n",
      " - 1s - loss: 0.4358 - val_loss: 1.5260\n",
      "Epoch 165/600\n",
      " - 1s - loss: 0.4322 - val_loss: 1.5258\n",
      "Epoch 166/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.5260\n",
      "Epoch 167/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.5260\n",
      "Epoch 168/600\n",
      " - 1s - loss: 0.4441 - val_loss: 1.5258\n",
      "Epoch 169/600\n",
      " - 1s - loss: 0.4371 - val_loss: 1.5257\n",
      "Epoch 170/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.5259\n",
      "Epoch 171/600\n",
      " - 1s - loss: 0.4457 - val_loss: 1.5254\n",
      "Epoch 172/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.5250\n",
      "Epoch 173/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.5246\n",
      "Epoch 174/600\n",
      " - 1s - loss: 0.4316 - val_loss: 1.5249\n",
      "Epoch 175/600\n",
      " - 1s - loss: 0.4435 - val_loss: 1.5250\n",
      "Epoch 176/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.5247\n",
      "Epoch 177/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.5246\n",
      "Epoch 178/600\n",
      " - 1s - loss: 0.4406 - val_loss: 1.5249\n",
      "Epoch 179/600\n",
      " - 1s - loss: 0.4363 - val_loss: 1.5245\n",
      "Epoch 180/600\n",
      " - 1s - loss: 0.4383 - val_loss: 1.5251\n",
      "Epoch 181/600\n",
      " - 1s - loss: 0.4294 - val_loss: 1.5252\n",
      "Epoch 182/600\n",
      " - 1s - loss: 0.4406 - val_loss: 1.5255\n",
      "Epoch 183/600\n",
      " - 1s - loss: 0.4536 - val_loss: 1.5259\n",
      "Epoch 184/600\n",
      " - 1s - loss: 0.4462 - val_loss: 1.5257\n",
      "Epoch 185/600\n",
      " - 1s - loss: 0.4432 - val_loss: 1.5256\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Epoch 186/600\n",
      " - 1s - loss: 0.4421 - val_loss: 1.5258\n",
      "Epoch 187/600\n",
      " - 1s - loss: 0.4419 - val_loss: 1.5257\n",
      "Epoch 188/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.5257\n",
      "Epoch 189/600\n",
      " - 1s - loss: 0.4406 - val_loss: 1.5255\n",
      "Epoch 190/600\n",
      " - 1s - loss: 0.4449 - val_loss: 1.5255\n",
      "Epoch 191/600\n",
      " - 1s - loss: 0.4256 - val_loss: 1.5256\n",
      "Epoch 192/600\n",
      " - 1s - loss: 0.4406 - val_loss: 1.5256\n",
      "Epoch 193/600\n",
      " - 1s - loss: 0.4230 - val_loss: 1.5256\n",
      "Epoch 194/600\n",
      " - 1s - loss: 0.4479 - val_loss: 1.5255\n",
      "Epoch 195/600\n",
      " - 1s - loss: 0.4347 - val_loss: 1.5255\n",
      "Epoch 196/600\n",
      " - 1s - loss: 0.4273 - val_loss: 1.5254\n",
      "Epoch 197/600\n",
      " - 1s - loss: 0.4399 - val_loss: 1.5252\n",
      "Epoch 198/600\n",
      " - 1s - loss: 0.4387 - val_loss: 1.5251\n",
      "Epoch 199/600\n",
      " - 1s - loss: 0.4453 - val_loss: 1.5252\n",
      "Epoch 200/600\n",
      " - 1s - loss: 0.4457 - val_loss: 1.5253\n",
      "Epoch 201/600\n",
      " - 1s - loss: 0.4335 - val_loss: 1.5254\n",
      "Epoch 202/600\n",
      " - 1s - loss: 0.4349 - val_loss: 1.5256\n",
      "Epoch 203/600\n",
      " - 1s - loss: 0.4520 - val_loss: 1.5255\n",
      "Epoch 204/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.5254\n",
      "Epoch 205/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.5254\n",
      "Epoch 206/600\n",
      " - 1s - loss: 0.4243 - val_loss: 1.5252\n",
      "Epoch 207/600\n",
      " - 1s - loss: 0.4380 - val_loss: 1.5251\n",
      "Epoch 208/600\n",
      " - 1s - loss: 0.4246 - val_loss: 1.5252\n",
      "Epoch 209/600\n",
      " - 1s - loss: 0.4341 - val_loss: 1.5252\n",
      "Epoch 210/600\n",
      " - 1s - loss: 0.4319 - val_loss: 1.5250\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Epoch 211/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.5251\n",
      "Epoch 212/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.5251\n",
      "Epoch 213/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.5250\n",
      "Epoch 214/600\n",
      " - 1s - loss: 0.4454 - val_loss: 1.5250\n",
      "Epoch 215/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.5249\n",
      "Epoch 216/600\n",
      " - 1s - loss: 0.4418 - val_loss: 1.5249\n",
      "Epoch 217/600\n",
      " - 1s - loss: 0.4220 - val_loss: 1.5248\n",
      "Epoch 218/600\n",
      " - 1s - loss: 0.4403 - val_loss: 1.5249\n",
      "Epoch 219/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5250\n",
      "Epoch 220/600\n",
      " - 1s - loss: 0.4494 - val_loss: 1.5251\n",
      "Epoch 221/600\n",
      " - 1s - loss: 0.4315 - val_loss: 1.5250\n",
      "Epoch 222/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.5251\n",
      "Epoch 223/600\n",
      " - 1s - loss: 0.4464 - val_loss: 1.5252\n",
      "Epoch 224/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.5252\n",
      "Epoch 225/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.5252\n",
      "Epoch 226/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.5251\n",
      "Epoch 227/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.5252\n",
      "Epoch 228/600\n",
      " - 1s - loss: 0.4535 - val_loss: 1.5251\n",
      "Epoch 229/600\n",
      " - 1s - loss: 0.4464 - val_loss: 1.5251\n",
      "Epoch 230/600\n",
      " - 1s - loss: 0.4274 - val_loss: 1.5251\n",
      "Epoch 231/600\n",
      " - 1s - loss: 0.4532 - val_loss: 1.5250\n",
      "Epoch 232/600\n",
      " - 1s - loss: 0.4250 - val_loss: 1.5249\n",
      "Epoch 233/600\n",
      " - 1s - loss: 0.4380 - val_loss: 1.5250\n",
      "Epoch 234/600\n",
      " - 1s - loss: 0.4316 - val_loss: 1.5250\n",
      "Epoch 235/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.5250\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Epoch 236/600\n",
      " - 1s - loss: 0.4230 - val_loss: 1.5250\n",
      "Epoch 237/600\n",
      " - 1s - loss: 0.4418 - val_loss: 1.5250\n",
      "Epoch 238/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.5250\n",
      "Epoch 239/600\n",
      " - 1s - loss: 0.4303 - val_loss: 1.5250\n",
      "Epoch 240/600\n",
      " - 1s - loss: 0.4515 - val_loss: 1.5250\n",
      "Epoch 241/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.5250\n",
      "Epoch 242/600\n",
      " - 1s - loss: 0.4504 - val_loss: 1.5250\n",
      "Epoch 243/600\n",
      " - 1s - loss: 0.4313 - val_loss: 1.5251\n",
      "Epoch 244/600\n",
      " - 1s - loss: 0.4497 - val_loss: 1.5250\n",
      "Epoch 245/600\n",
      " - 1s - loss: 0.4244 - val_loss: 1.5250\n",
      "Epoch 246/600\n",
      " - 1s - loss: 0.4445 - val_loss: 1.5250\n",
      "Epoch 247/600\n",
      " - 1s - loss: 0.4461 - val_loss: 1.5250\n",
      "Epoch 248/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.5250\n",
      "Epoch 249/600\n",
      " - 1s - loss: 0.4441 - val_loss: 1.5250\n",
      "Epoch 250/600\n",
      " - 1s - loss: 0.4269 - val_loss: 1.5250\n",
      "Epoch 251/600\n",
      " - 1s - loss: 0.4222 - val_loss: 1.5250\n",
      "Epoch 252/600\n",
      " - 1s - loss: 0.4313 - val_loss: 1.5250\n",
      "Epoch 253/600\n",
      " - 1s - loss: 0.4283 - val_loss: 1.5251\n",
      "Epoch 254/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.5250\n",
      "Epoch 255/600\n",
      " - 1s - loss: 0.4420 - val_loss: 1.5250\n",
      "Epoch 256/600\n",
      " - 1s - loss: 0.4386 - val_loss: 1.5250\n",
      "Epoch 257/600\n",
      " - 1s - loss: 0.4226 - val_loss: 1.5250\n",
      "Epoch 258/600\n",
      " - 1s - loss: 0.4370 - val_loss: 1.5250\n",
      "Epoch 259/600\n",
      " - 1s - loss: 0.4213 - val_loss: 1.5250\n",
      "Epoch 260/600\n",
      " - 1s - loss: 0.4356 - val_loss: 1.5250\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Epoch 261/600\n",
      " - 1s - loss: 0.4298 - val_loss: 1.5251\n",
      "Epoch 262/600\n",
      " - 1s - loss: 0.4408 - val_loss: 1.5251\n",
      "Epoch 263/600\n",
      " - 1s - loss: 0.4419 - val_loss: 1.5251\n",
      "Epoch 264/600\n",
      " - 1s - loss: 0.4128 - val_loss: 1.5251\n",
      "Epoch 265/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.5250\n",
      "Epoch 266/600\n",
      " - 1s - loss: 0.4401 - val_loss: 1.5250\n",
      "Epoch 267/600\n",
      " - 1s - loss: 0.4484 - val_loss: 1.5250\n",
      "Epoch 268/600\n",
      " - 1s - loss: 0.4299 - val_loss: 1.5250\n",
      "Epoch 269/600\n",
      " - 1s - loss: 0.4302 - val_loss: 1.5250\n",
      "Epoch 270/600\n",
      " - 1s - loss: 0.4499 - val_loss: 1.5250\n",
      "Epoch 271/600\n",
      " - 1s - loss: 0.4424 - val_loss: 1.5251\n",
      "Epoch 272/600\n",
      " - 1s - loss: 0.4344 - val_loss: 1.5250\n",
      "Epoch 273/600\n",
      " - 1s - loss: 0.4211 - val_loss: 1.5250\n",
      "Epoch 274/600\n",
      " - 1s - loss: 0.4553 - val_loss: 1.5250\n",
      "Epoch 275/600\n",
      " - 1s - loss: 0.4439 - val_loss: 1.5250\n",
      "Epoch 276/600\n",
      " - 1s - loss: 0.4391 - val_loss: 1.5250\n",
      "Epoch 277/600\n",
      " - 1s - loss: 0.4262 - val_loss: 1.5250\n",
      "Epoch 278/600\n",
      " - 1s - loss: 0.4286 - val_loss: 1.5250\n",
      "Epoch 279/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.5250\n",
      "Epoch 280/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.5250\n",
      "Epoch 281/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.5250\n",
      "Epoch 282/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.5250\n",
      "Epoch 283/600\n",
      " - 1s - loss: 0.4286 - val_loss: 1.5250\n",
      "Epoch 284/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.5250\n",
      "Epoch 285/600\n",
      " - 1s - loss: 0.4496 - val_loss: 1.5250\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "Epoch 286/600\n",
      " - 1s - loss: 0.4294 - val_loss: 1.5250\n",
      "Epoch 287/600\n",
      " - 1s - loss: 0.4454 - val_loss: 1.5250\n",
      "Epoch 288/600\n",
      " - 1s - loss: 0.4356 - val_loss: 1.5250\n",
      "Epoch 289/600\n",
      " - 1s - loss: 0.4407 - val_loss: 1.5250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.5250\n",
      "Epoch 291/600\n",
      " - 1s - loss: 0.4405 - val_loss: 1.5250\n",
      "Epoch 292/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.5250\n",
      "Epoch 293/600\n",
      " - 1s - loss: 0.4381 - val_loss: 1.5250\n",
      "Epoch 294/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.5250\n",
      "Epoch 295/600\n",
      " - 1s - loss: 0.4245 - val_loss: 1.5250\n",
      "Epoch 296/600\n",
      " - 1s - loss: 0.4494 - val_loss: 1.5250\n",
      "Epoch 297/600\n",
      " - 1s - loss: 0.4350 - val_loss: 1.5250\n",
      "Epoch 298/600\n",
      " - 1s - loss: 0.4225 - val_loss: 1.5250\n",
      "Epoch 299/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.5250\n",
      "Epoch 300/600\n",
      " - 1s - loss: 0.4387 - val_loss: 1.5250\n",
      "Epoch 301/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.5249\n",
      "Epoch 302/600\n",
      " - 1s - loss: 0.4533 - val_loss: 1.5249\n",
      "Epoch 303/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.5249\n",
      "Epoch 304/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.5249\n",
      "Epoch 305/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.5249\n",
      "Epoch 306/600\n",
      " - 1s - loss: 0.4271 - val_loss: 1.5249\n",
      "Epoch 307/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.5249\n",
      "Epoch 308/600\n",
      " - 1s - loss: 0.4238 - val_loss: 1.5249\n",
      "Epoch 309/600\n",
      " - 1s - loss: 0.4498 - val_loss: 1.5249\n",
      "Epoch 310/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.5249\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "Epoch 311/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.5249\n",
      "Epoch 312/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.5249\n",
      "Epoch 313/600\n",
      " - 1s - loss: 0.4452 - val_loss: 1.5249\n",
      "Epoch 314/600\n",
      " - 1s - loss: 0.4346 - val_loss: 1.5249\n",
      "Epoch 315/600\n",
      " - 1s - loss: 0.4503 - val_loss: 1.5249\n",
      "Epoch 316/600\n",
      " - 1s - loss: 0.4260 - val_loss: 1.5249\n",
      "Epoch 317/600\n",
      " - 1s - loss: 0.4467 - val_loss: 1.5249\n",
      "Epoch 318/600\n",
      " - 1s - loss: 0.4263 - val_loss: 1.5249\n",
      "Epoch 319/600\n",
      " - 1s - loss: 0.4110 - val_loss: 1.5249\n",
      "Epoch 320/600\n",
      " - 1s - loss: 0.4373 - val_loss: 1.5249\n",
      "Epoch 321/600\n",
      " - 1s - loss: 0.4226 - val_loss: 1.5249\n",
      "Epoch 322/600\n",
      " - 1s - loss: 0.4552 - val_loss: 1.5249\n",
      "Epoch 323/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.5249\n",
      "Epoch 324/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.5249\n",
      "Epoch 325/600\n",
      " - 1s - loss: 0.4269 - val_loss: 1.5249\n",
      "Epoch 326/600\n",
      " - 1s - loss: 0.4474 - val_loss: 1.5249\n",
      "Epoch 327/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.5249\n",
      "Epoch 328/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.5249\n",
      "Epoch 329/600\n",
      " - 1s - loss: 0.4459 - val_loss: 1.5249\n",
      "Epoch 330/600\n",
      " - 1s - loss: 0.4292 - val_loss: 1.5249\n",
      "Epoch 331/600\n",
      " - 1s - loss: 0.4461 - val_loss: 1.5249\n",
      "Epoch 332/600\n",
      " - 1s - loss: 0.4497 - val_loss: 1.5249\n",
      "Epoch 333/600\n",
      " - 1s - loss: 0.4389 - val_loss: 1.5249\n",
      "Epoch 334/600\n",
      " - 1s - loss: 0.4410 - val_loss: 1.5249\n",
      "Epoch 335/600\n",
      " - 1s - loss: 0.4562 - val_loss: 1.5249\n",
      "\n",
      "Epoch 00335: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.\n",
      "Epoch 336/600\n",
      " - 1s - loss: 0.4327 - val_loss: 1.5249\n",
      "Epoch 337/600\n",
      " - 1s - loss: 0.4448 - val_loss: 1.5249\n",
      "Epoch 338/600\n",
      " - 1s - loss: 0.4524 - val_loss: 1.5249\n",
      "Epoch 339/600\n",
      " - 1s - loss: 0.4222 - val_loss: 1.5249\n",
      "Epoch 340/600\n",
      " - 1s - loss: 0.4220 - val_loss: 1.5249\n",
      "Epoch 341/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.5249\n",
      "Epoch 342/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.5249\n",
      "Epoch 343/600\n",
      " - 1s - loss: 0.4264 - val_loss: 1.5249\n",
      "Epoch 344/600\n",
      " - 1s - loss: 0.4388 - val_loss: 1.5249\n",
      "Epoch 345/600\n",
      " - 1s - loss: 0.4384 - val_loss: 1.5249\n",
      "Epoch 346/600\n",
      " - 1s - loss: 0.4102 - val_loss: 1.5249\n",
      "Epoch 347/600\n",
      " - 1s - loss: 0.4240 - val_loss: 1.5249\n",
      "Epoch 348/600\n",
      " - 1s - loss: 0.4245 - val_loss: 1.5249\n",
      "Epoch 349/600\n",
      " - 1s - loss: 0.4486 - val_loss: 1.5249\n",
      "Epoch 350/600\n",
      " - 1s - loss: 0.4254 - val_loss: 1.5249\n",
      "Epoch 351/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.5249\n",
      "Epoch 352/600\n",
      " - 1s - loss: 0.4300 - val_loss: 1.5249\n",
      "Epoch 353/600\n",
      " - 1s - loss: 0.4416 - val_loss: 1.5249\n",
      "Epoch 354/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.5249\n",
      "Epoch 355/600\n",
      " - 1s - loss: 0.4371 - val_loss: 1.5249\n",
      "Epoch 356/600\n",
      " - 1s - loss: 0.4340 - val_loss: 1.5249\n",
      "Epoch 357/600\n",
      " - 1s - loss: 0.4334 - val_loss: 1.5249\n",
      "Epoch 358/600\n",
      " - 1s - loss: 0.4476 - val_loss: 1.5249\n",
      "Epoch 359/600\n",
      " - 1s - loss: 0.4447 - val_loss: 1.5249\n",
      "Epoch 360/600\n",
      " - 1s - loss: 0.4389 - val_loss: 1.5249\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 361/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.5249\n",
      "Epoch 362/600\n",
      " - 1s - loss: 0.4369 - val_loss: 1.5249\n",
      "Epoch 363/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.5249\n",
      "Epoch 364/600\n",
      " - 1s - loss: 0.4293 - val_loss: 1.5249\n",
      "Epoch 365/600\n",
      " - 1s - loss: 0.4282 - val_loss: 1.5249\n",
      "Epoch 366/600\n",
      " - 1s - loss: 0.4227 - val_loss: 1.5249\n",
      "Epoch 367/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.5249\n",
      "Epoch 368/600\n",
      " - 1s - loss: 0.4222 - val_loss: 1.5249\n",
      "Epoch 369/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.5249\n",
      "Epoch 370/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.5249\n",
      "Epoch 371/600\n",
      " - 1s - loss: 0.4434 - val_loss: 1.5249\n",
      "Epoch 372/600\n",
      " - 1s - loss: 0.4381 - val_loss: 1.5249\n",
      "Epoch 373/600\n",
      " - 1s - loss: 0.4432 - val_loss: 1.5249\n",
      "Epoch 374/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.5249\n",
      "Epoch 375/600\n",
      " - 1s - loss: 0.4363 - val_loss: 1.5249\n",
      "Epoch 376/600\n",
      " - 1s - loss: 0.4288 - val_loss: 1.5249\n",
      "Epoch 377/600\n",
      " - 1s - loss: 0.4489 - val_loss: 1.5249\n",
      "Epoch 378/600\n",
      " - 1s - loss: 0.4293 - val_loss: 1.5249\n",
      "Epoch 379/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.5249\n",
      "Epoch 380/600\n",
      " - 1s - loss: 0.4377 - val_loss: 1.5249\n",
      "Epoch 381/600\n",
      " - 1s - loss: 0.4341 - val_loss: 1.5249\n",
      "Epoch 382/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.5249\n",
      "Epoch 383/600\n",
      " - 1s - loss: 0.4258 - val_loss: 1.5249\n",
      "Epoch 384/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.5249\n",
      "Epoch 385/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.5249\n",
      "Epoch 386/600\n",
      " - 1s - loss: 0.4390 - val_loss: 1.5249\n",
      "Epoch 387/600\n",
      " - 1s - loss: 0.4441 - val_loss: 1.5249\n",
      "Epoch 388/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.5249\n",
      "Epoch 389/600\n",
      " - 1s - loss: 0.4489 - val_loss: 1.5249\n",
      "Epoch 390/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.5249\n",
      "Epoch 391/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.5249\n",
      "Epoch 392/600\n",
      " - 1s - loss: 0.4451 - val_loss: 1.5249\n",
      "Epoch 393/600\n",
      " - 1s - loss: 0.4256 - val_loss: 1.5249\n",
      "Epoch 394/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.5249\n",
      "Epoch 395/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.5249\n",
      "Epoch 396/600\n",
      " - 1s - loss: 0.4289 - val_loss: 1.5249\n",
      "Epoch 397/600\n",
      " - 1s - loss: 0.4344 - val_loss: 1.5249\n",
      "Epoch 398/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.5249\n",
      "Epoch 399/600\n",
      " - 1s - loss: 0.4345 - val_loss: 1.5249\n",
      "Epoch 400/600\n",
      " - 1s - loss: 0.4261 - val_loss: 1.5249\n",
      "Epoch 401/600\n",
      " - 1s - loss: 0.4320 - val_loss: 1.5249\n",
      "Epoch 402/600\n",
      " - 1s - loss: 0.4240 - val_loss: 1.5249\n",
      "Epoch 403/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.5249\n",
      "Epoch 404/600\n",
      " - 1s - loss: 0.4484 - val_loss: 1.5249\n",
      "Epoch 405/600\n",
      " - 1s - loss: 0.4391 - val_loss: 1.5249\n",
      "Epoch 406/600\n",
      " - 1s - loss: 0.4288 - val_loss: 1.5249\n",
      "Epoch 407/600\n",
      " - 1s - loss: 0.4286 - val_loss: 1.5249\n",
      "Epoch 408/600\n",
      " - 1s - loss: 0.4265 - val_loss: 1.5249\n",
      "Epoch 409/600\n",
      " - 1s - loss: 0.4250 - val_loss: 1.5249\n",
      "Epoch 410/600\n",
      " - 1s - loss: 0.4304 - val_loss: 1.5249\n",
      "Epoch 411/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.5249\n",
      "Epoch 412/600\n",
      " - 1s - loss: 0.4383 - val_loss: 1.5249\n",
      "Epoch 413/600\n",
      " - 1s - loss: 0.4527 - val_loss: 1.5249\n",
      "Epoch 414/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.5249\n",
      "Epoch 415/600\n",
      " - 1s - loss: 0.4566 - val_loss: 1.5249\n",
      "Epoch 416/600\n",
      " - 1s - loss: 0.4197 - val_loss: 1.5249\n",
      "Epoch 417/600\n",
      " - 1s - loss: 0.4289 - val_loss: 1.5249\n",
      "Epoch 418/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.5249\n",
      "Epoch 419/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.5249\n",
      "Epoch 420/600\n",
      " - 1s - loss: 0.4355 - val_loss: 1.5249\n",
      "Epoch 421/600\n",
      " - 1s - loss: 0.4360 - val_loss: 1.5249\n",
      "Epoch 422/600\n",
      " - 1s - loss: 0.4369 - val_loss: 1.5249\n",
      "Epoch 423/600\n",
      " - 1s - loss: 0.4322 - val_loss: 1.5249\n",
      "Epoch 424/600\n",
      " - 1s - loss: 0.4350 - val_loss: 1.5249\n",
      "Epoch 425/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.5249\n",
      "Epoch 426/600\n",
      " - 1s - loss: 0.4300 - val_loss: 1.5249\n",
      "Epoch 427/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.5249\n",
      "Epoch 428/600\n",
      " - 1s - loss: 0.4373 - val_loss: 1.5249\n",
      "Epoch 429/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.5249\n",
      "Epoch 430/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.5249\n",
      "Epoch 431/600\n",
      " - 1s - loss: 0.4324 - val_loss: 1.5249\n",
      "Epoch 432/600\n",
      " - 1s - loss: 0.4504 - val_loss: 1.5249\n",
      "Epoch 433/600\n",
      " - 1s - loss: 0.4440 - val_loss: 1.5249\n",
      "Epoch 434/600\n",
      " - 1s - loss: 0.4316 - val_loss: 1.5249\n",
      "Epoch 435/600\n",
      " - 1s - loss: 0.4376 - val_loss: 1.5249\n",
      "Epoch 436/600\n",
      " - 1s - loss: 0.4290 - val_loss: 1.5249\n",
      "Epoch 437/600\n",
      " - 1s - loss: 0.4297 - val_loss: 1.5249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/600\n",
      " - 1s - loss: 0.4252 - val_loss: 1.5249\n",
      "Epoch 439/600\n",
      " - 1s - loss: 0.4310 - val_loss: 1.5249\n",
      "Epoch 440/600\n",
      " - 1s - loss: 0.4183 - val_loss: 1.5249\n",
      "Epoch 441/600\n",
      " - 1s - loss: 0.4329 - val_loss: 1.5249\n",
      "Epoch 442/600\n",
      " - 1s - loss: 0.4314 - val_loss: 1.5249\n",
      "Epoch 443/600\n",
      " - 1s - loss: 0.4366 - val_loss: 1.5249\n",
      "Epoch 444/600\n",
      " - 1s - loss: 0.4486 - val_loss: 1.5249\n",
      "Epoch 445/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.5249\n",
      "Epoch 446/600\n",
      " - 1s - loss: 0.4323 - val_loss: 1.5249\n",
      "Epoch 447/600\n",
      " - 1s - loss: 0.4377 - val_loss: 1.5249\n",
      "Epoch 448/600\n",
      " - 1s - loss: 0.4347 - val_loss: 1.5249\n",
      "Epoch 449/600\n",
      " - 1s - loss: 0.4247 - val_loss: 1.5249\n",
      "Epoch 450/600\n",
      " - 1s - loss: 0.4408 - val_loss: 1.5249\n",
      "Epoch 451/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.5249\n",
      "Epoch 452/600\n",
      " - 1s - loss: 0.4201 - val_loss: 1.5249\n",
      "Epoch 453/600\n",
      " - 1s - loss: 0.4600 - val_loss: 1.5249\n",
      "Epoch 454/600\n",
      " - 1s - loss: 0.4514 - val_loss: 1.5249\n",
      "Epoch 455/600\n",
      " - 1s - loss: 0.4278 - val_loss: 1.5249\n",
      "Epoch 456/600\n",
      " - 1s - loss: 0.4421 - val_loss: 1.5249\n",
      "Epoch 457/600\n",
      " - 1s - loss: 0.4380 - val_loss: 1.5249\n",
      "Epoch 458/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.5249\n",
      "Epoch 459/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.5249\n",
      "Epoch 460/600\n",
      " - 1s - loss: 0.4515 - val_loss: 1.5249\n",
      "Epoch 461/600\n",
      " - 1s - loss: 0.4410 - val_loss: 1.5249\n",
      "Epoch 462/600\n",
      " - 1s - loss: 0.4198 - val_loss: 1.5249\n",
      "Epoch 463/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.5249\n",
      "Epoch 464/600\n",
      " - 1s - loss: 0.4411 - val_loss: 1.5249\n",
      "Epoch 465/600\n",
      " - 1s - loss: 0.4393 - val_loss: 1.5249\n",
      "Epoch 466/600\n",
      " - 1s - loss: 0.4409 - val_loss: 1.5249\n",
      "Epoch 467/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.5249\n",
      "Epoch 468/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.5249\n",
      "Epoch 469/600\n",
      " - 1s - loss: 0.4346 - val_loss: 1.5249\n",
      "Epoch 470/600\n",
      " - 1s - loss: 0.4439 - val_loss: 1.5249\n",
      "Epoch 471/600\n",
      " - 1s - loss: 0.4298 - val_loss: 1.5249\n",
      "Epoch 472/600\n",
      " - 1s - loss: 0.4426 - val_loss: 1.5249\n",
      "Epoch 473/600\n",
      " - 1s - loss: 0.4415 - val_loss: 1.5249\n",
      "Epoch 474/600\n",
      " - 1s - loss: 0.4425 - val_loss: 1.5249\n",
      "Epoch 475/600\n",
      " - 1s - loss: 0.4452 - val_loss: 1.5249\n",
      "Epoch 476/600\n",
      " - 1s - loss: 0.4432 - val_loss: 1.5249\n",
      "Epoch 477/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.5249\n",
      "Epoch 478/600\n",
      " - 1s - loss: 0.4356 - val_loss: 1.5249\n",
      "Epoch 479/600\n",
      " - 1s - loss: 0.4304 - val_loss: 1.5249\n",
      "Epoch 480/600\n",
      " - 1s - loss: 0.4426 - val_loss: 1.5249\n",
      "Epoch 481/600\n",
      " - 1s - loss: 0.4296 - val_loss: 1.5249\n",
      "Epoch 482/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.5249\n",
      "Epoch 483/600\n",
      " - 1s - loss: 0.4347 - val_loss: 1.5249\n",
      "Epoch 484/600\n",
      " - 1s - loss: 0.4543 - val_loss: 1.5249\n",
      "Epoch 485/600\n",
      " - 1s - loss: 0.4331 - val_loss: 1.5249\n",
      "Epoch 486/600\n",
      " - 1s - loss: 0.4301 - val_loss: 1.5249\n",
      "Epoch 487/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.5249\n",
      "Epoch 488/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.5249\n",
      "Epoch 489/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.5249\n",
      "Epoch 490/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.5249\n",
      "Epoch 491/600\n",
      " - 1s - loss: 0.4389 - val_loss: 1.5249\n",
      "Epoch 492/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.5249\n",
      "Epoch 493/600\n",
      " - 1s - loss: 0.4470 - val_loss: 1.5249\n",
      "Epoch 494/600\n",
      " - 1s - loss: 0.4413 - val_loss: 1.5249\n",
      "Epoch 495/600\n",
      " - 1s - loss: 0.4441 - val_loss: 1.5249\n",
      "Epoch 496/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.5249\n",
      "Epoch 497/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.5249\n",
      "Epoch 498/600\n",
      " - 1s - loss: 0.4369 - val_loss: 1.5249\n",
      "Epoch 499/600\n",
      " - 1s - loss: 0.4438 - val_loss: 1.5249\n",
      "Epoch 500/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.5249\n",
      "Epoch 501/600\n",
      " - 1s - loss: 0.4549 - val_loss: 1.5249\n",
      "Epoch 502/600\n",
      " - 1s - loss: 0.4329 - val_loss: 1.5249\n",
      "Epoch 503/600\n",
      " - 1s - loss: 0.4468 - val_loss: 1.5249\n",
      "Epoch 504/600\n",
      " - 1s - loss: 0.4360 - val_loss: 1.5249\n",
      "Epoch 505/600\n",
      " - 1s - loss: 0.4246 - val_loss: 1.5249\n",
      "Epoch 506/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.5249\n",
      "Epoch 507/600\n",
      " - 1s - loss: 0.4479 - val_loss: 1.5249\n",
      "Epoch 508/600\n",
      " - 1s - loss: 0.4425 - val_loss: 1.5249\n",
      "Epoch 509/600\n",
      " - 1s - loss: 0.4491 - val_loss: 1.5249\n",
      "Epoch 510/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.5249\n",
      "Epoch 511/600\n",
      " - 1s - loss: 0.4338 - val_loss: 1.5249\n",
      "Epoch 512/600\n",
      " - 1s - loss: 0.4520 - val_loss: 1.5249\n",
      "Epoch 513/600\n",
      " - 1s - loss: 0.4440 - val_loss: 1.5249\n",
      "Epoch 514/600\n",
      " - 1s - loss: 0.4329 - val_loss: 1.5249\n",
      "Epoch 515/600\n",
      " - 1s - loss: 0.4303 - val_loss: 1.5249\n",
      "Epoch 516/600\n",
      " - 1s - loss: 0.4231 - val_loss: 1.5249\n",
      "Epoch 517/600\n",
      " - 1s - loss: 0.4240 - val_loss: 1.5249\n",
      "Epoch 518/600\n",
      " - 1s - loss: 0.4335 - val_loss: 1.5249\n",
      "Epoch 519/600\n",
      " - 1s - loss: 0.4504 - val_loss: 1.5249\n",
      "Epoch 520/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.5249\n",
      "Epoch 521/600\n",
      " - 1s - loss: 0.4255 - val_loss: 1.5249\n",
      "Epoch 522/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.5249\n",
      "Epoch 523/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.5249\n",
      "Epoch 524/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.5249\n",
      "Epoch 525/600\n",
      " - 1s - loss: 0.4439 - val_loss: 1.5249\n",
      "Epoch 526/600\n",
      " - 1s - loss: 0.4422 - val_loss: 1.5249\n",
      "Epoch 527/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5249\n",
      "Epoch 528/600\n",
      " - 1s - loss: 0.4447 - val_loss: 1.5249\n",
      "Epoch 529/600\n",
      " - 1s - loss: 0.4327 - val_loss: 1.5249\n",
      "Epoch 530/600\n",
      " - 1s - loss: 0.4379 - val_loss: 1.5249\n",
      "Epoch 531/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.5249\n",
      "Epoch 532/600\n",
      " - 1s - loss: 0.4466 - val_loss: 1.5249\n",
      "Epoch 533/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.5249\n",
      "Epoch 534/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.5249\n",
      "Epoch 535/600\n",
      " - 1s - loss: 0.4268 - val_loss: 1.5249\n",
      "Epoch 536/600\n",
      " - 1s - loss: 0.4296 - val_loss: 1.5249\n",
      "Epoch 537/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.5249\n",
      "Epoch 538/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.5249\n",
      "Epoch 539/600\n",
      " - 1s - loss: 0.4484 - val_loss: 1.5249\n",
      "Epoch 540/600\n",
      " - 1s - loss: 0.4511 - val_loss: 1.5249\n",
      "Epoch 541/600\n",
      " - 1s - loss: 0.4333 - val_loss: 1.5249\n",
      "Epoch 542/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.5249\n",
      "Epoch 543/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.5249\n",
      "Epoch 544/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.5249\n",
      "Epoch 545/600\n",
      " - 1s - loss: 0.4351 - val_loss: 1.5249\n",
      "Epoch 546/600\n",
      " - 1s - loss: 0.4387 - val_loss: 1.5249\n",
      "Epoch 547/600\n",
      " - 1s - loss: 0.4270 - val_loss: 1.5249\n",
      "Epoch 548/600\n",
      " - 1s - loss: 0.4414 - val_loss: 1.5249\n",
      "Epoch 549/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.5249\n",
      "Epoch 550/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.5249\n",
      "Epoch 551/600\n",
      " - 1s - loss: 0.4331 - val_loss: 1.5249\n",
      "Epoch 552/600\n",
      " - 1s - loss: 0.4320 - val_loss: 1.5249\n",
      "Epoch 553/600\n",
      " - 1s - loss: 0.4429 - val_loss: 1.5249\n",
      "Epoch 554/600\n",
      " - 1s - loss: 0.4310 - val_loss: 1.5249\n",
      "Epoch 555/600\n",
      " - 1s - loss: 0.4390 - val_loss: 1.5249\n",
      "Epoch 556/600\n",
      " - 1s - loss: 0.4349 - val_loss: 1.5249\n",
      "Epoch 557/600\n",
      " - 1s - loss: 0.4464 - val_loss: 1.5249\n",
      "Epoch 558/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.5249\n",
      "Epoch 559/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.5249\n",
      "Epoch 560/600\n",
      " - 1s - loss: 0.4384 - val_loss: 1.5249\n",
      "Epoch 561/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.5249\n",
      "Epoch 562/600\n",
      " - 1s - loss: 0.4473 - val_loss: 1.5249\n",
      "Epoch 563/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.5249\n",
      "Epoch 564/600\n",
      " - 1s - loss: 0.4316 - val_loss: 1.5249\n",
      "Epoch 565/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.5249\n",
      "Epoch 566/600\n",
      " - 1s - loss: 0.4271 - val_loss: 1.5249\n",
      "Epoch 567/600\n",
      " - 1s - loss: 0.4351 - val_loss: 1.5249\n",
      "Epoch 568/600\n",
      " - 1s - loss: 0.4319 - val_loss: 1.5249\n",
      "Epoch 569/600\n",
      " - 1s - loss: 0.4275 - val_loss: 1.5249\n",
      "Epoch 570/600\n",
      " - 1s - loss: 0.4290 - val_loss: 1.5249\n",
      "Epoch 571/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.5249\n",
      "Epoch 572/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.5249\n",
      "Epoch 573/600\n",
      " - 1s - loss: 0.4292 - val_loss: 1.5249\n",
      "Epoch 574/600\n",
      " - 1s - loss: 0.4254 - val_loss: 1.5249\n",
      "Epoch 575/600\n",
      " - 1s - loss: 0.4323 - val_loss: 1.5249\n",
      "Epoch 576/600\n",
      " - 1s - loss: 0.4366 - val_loss: 1.5249\n",
      "Epoch 577/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.5249\n",
      "Epoch 578/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.5249\n",
      "Epoch 579/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.5249\n",
      "Epoch 580/600\n",
      " - 1s - loss: 0.4354 - val_loss: 1.5249\n",
      "Epoch 581/600\n",
      " - 1s - loss: 0.4322 - val_loss: 1.5249\n",
      "Epoch 582/600\n",
      " - 1s - loss: 0.4314 - val_loss: 1.5249\n",
      "Epoch 583/600\n",
      " - 1s - loss: 0.4452 - val_loss: 1.5249\n",
      "Epoch 584/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.5249\n",
      "Epoch 585/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.5249\n",
      "Epoch 586/600\n",
      " - 1s - loss: 0.4180 - val_loss: 1.5249\n",
      "Epoch 587/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.5249\n",
      "Epoch 588/600\n",
      " - 1s - loss: 0.4369 - val_loss: 1.5249\n",
      "Epoch 589/600\n",
      " - 1s - loss: 0.4193 - val_loss: 1.5249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 590/600\n",
      " - 1s - loss: 0.4331 - val_loss: 1.5249\n",
      "Epoch 591/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.5249\n",
      "Epoch 592/600\n",
      " - 1s - loss: 0.4214 - val_loss: 1.5249\n",
      "Epoch 593/600\n",
      " - 1s - loss: 0.4465 - val_loss: 1.5249\n",
      "Epoch 594/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.5249\n",
      "Epoch 595/600\n",
      " - 1s - loss: 0.4265 - val_loss: 1.5249\n",
      "Epoch 596/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.5249\n",
      "Epoch 597/600\n",
      " - 1s - loss: 0.4270 - val_loss: 1.5249\n",
      "Epoch 598/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.5249\n",
      "Epoch 599/600\n",
      " - 1s - loss: 0.4340 - val_loss: 1.5249\n",
      "Epoch 600/600\n",
      " - 1s - loss: 0.4438 - val_loss: 1.5249\n"
     ]
    }
   ],
   "source": [
    "rdlr = ReduceLROnPlateau(patience=25, factor=0.5, min_lr=1e-6, monitor='val_loss', verbose=1)\n",
    "\n",
    "h = model.fit(X_train, y_train, epochs=600, batch_size=8, validation_split=0.2, callbacks=[rdlr], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33411659850997\n",
      "-1.9076098140571403\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "# model evaluation\n",
    "rmse = sqrt(mean_squared_error(y_test, y_predicted))\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R^2: \",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real, predictions]\n",
      "[[1.63 1.118012547492981]\n",
      " [2.53 1.1178892850875854]\n",
      " [2.4 1.1190111637115479]\n",
      " [2.39 1.1186038255691528]\n",
      " [2.31 1.1183782815933228]\n",
      " [1.8 1.1180356740951538]\n",
      " [2.62 1.1192641258239746]\n",
      " [4.4 1.1188957691192627]\n",
      " [1.63 1.117609977722168]\n",
      " [1.5 1.1179851293563843]\n",
      " [1.8 1.1181913614273071]\n",
      " [1.38 1.1180763244628906]]\n"
     ]
    }
   ],
   "source": [
    "b=np.append(y_test, y_predicted, axis=1)\n",
    "\n",
    "print(\"[real, predictions]\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_predicted)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>188.195100</th>\n",
       "      <th>188.260100</th>\n",
       "      <th>188.325000</th>\n",
       "      <th>188.390000</th>\n",
       "      <th>188.455000</th>\n",
       "      <th>188.520000</th>\n",
       "      <th>188.585000</th>\n",
       "      <th>188.650000</th>\n",
       "      <th>188.714900</th>\n",
       "      <th>188.779900</th>\n",
       "      <th>...</th>\n",
       "      <th>440.300000</th>\n",
       "      <th>440.353000</th>\n",
       "      <th>440.406100</th>\n",
       "      <th>440.459200</th>\n",
       "      <th>440.512300</th>\n",
       "      <th>440.565300</th>\n",
       "      <th>440.618400</th>\n",
       "      <th>440.671400</th>\n",
       "      <th>440.724500</th>\n",
       "      <th>440.777500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.039555</td>\n",
       "      <td>0.052539</td>\n",
       "      <td>0.055079</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>0.013462</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.025239</td>\n",
       "      <td>0.039833</td>\n",
       "      <td>0.052818</td>\n",
       "      <td>0.054146</td>\n",
       "      <td>0.030239</td>\n",
       "      <td>0.013039</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.006249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.038571</td>\n",
       "      <td>0.050760</td>\n",
       "      <td>0.053431</td>\n",
       "      <td>0.030757</td>\n",
       "      <td>0.013450</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.024440</td>\n",
       "      <td>0.038970</td>\n",
       "      <td>0.051471</td>\n",
       "      <td>0.053686</td>\n",
       "      <td>0.030573</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>0.006317</td>\n",
       "      <td>0.006069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.024276</td>\n",
       "      <td>0.038708</td>\n",
       "      <td>0.051270</td>\n",
       "      <td>0.054081</td>\n",
       "      <td>0.031143</td>\n",
       "      <td>0.013503</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.006225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>0.039071</td>\n",
       "      <td>0.051843</td>\n",
       "      <td>0.054894</td>\n",
       "      <td>0.031643</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>0.005899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009519</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.039226</td>\n",
       "      <td>0.051976</td>\n",
       "      <td>0.054433</td>\n",
       "      <td>0.030961</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.007150</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.006043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.039551</td>\n",
       "      <td>0.052294</td>\n",
       "      <td>0.054697</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.006189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.024951</td>\n",
       "      <td>0.039949</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.031693</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.005896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001924</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>0.024716</td>\n",
       "      <td>0.039471</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.054580</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>0.013299</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.006253</td>\n",
       "      <td>0.006003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>0.024203</td>\n",
       "      <td>0.038787</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.054596</td>\n",
       "      <td>0.031559</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.005977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.039228</td>\n",
       "      <td>0.052146</td>\n",
       "      <td>0.055048</td>\n",
       "      <td>0.031634</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  4094 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    188.195100  188.260100  188.325000  188.390000  188.455000  188.520000  \\\n",
       "35    0.001942    0.001680    0.001769    0.001555    0.001976    0.001443   \n",
       "5     0.001869    0.001621    0.001703    0.001499    0.001901    0.001392   \n",
       "44    0.001968    0.001703    0.001797    0.001579    0.002009    0.001467   \n",
       "48    0.001945    0.001683    0.001777    0.001561    0.001985    0.001447   \n",
       "15    0.001911    0.001662    0.001747    0.001534    0.001947    0.001422   \n",
       "26    0.001922    0.001664    0.001750    0.001539    0.001960    0.001427   \n",
       "12    0.002001    0.001733    0.001818    0.001602    0.002034    0.001488   \n",
       "56    0.002017    0.001751    0.001841    0.001618    0.002056    0.001502   \n",
       "34    0.001941    0.001681    0.001770    0.001555    0.001974    0.001443   \n",
       "38    0.001924    0.001666    0.001756    0.001544    0.001965    0.001434   \n",
       "24    0.001950    0.001690    0.001780    0.001560    0.001991    0.001445   \n",
       "31    0.001931    0.001673    0.001760    0.001541    0.001966    0.001436   \n",
       "\n",
       "    188.585000  188.650000  188.714900  188.779900  ...  440.300000  \\\n",
       "35    0.001811    0.001757    0.001858    0.001759  ...    0.009459   \n",
       "5     0.001744    0.001694    0.001789    0.001694  ...    0.009778   \n",
       "44    0.001832    0.001778    0.001893    0.001784  ...    0.009369   \n",
       "48    0.001813    0.001759    0.001866    0.001762  ...    0.009467   \n",
       "15    0.001784    0.001733    0.001833    0.001730  ...    0.009395   \n",
       "26    0.001789    0.001739    0.001841    0.001740  ...    0.009287   \n",
       "12    0.001860    0.001809    0.001912    0.001812  ...    0.009519   \n",
       "56    0.001885    0.001829    0.001933    0.001831  ...    0.009554   \n",
       "34    0.001805    0.001753    0.001862    0.001760  ...    0.009429   \n",
       "38    0.001792    0.001744    0.001844    0.001740  ...    0.009413   \n",
       "24    0.001819    0.001764    0.001869    0.001763  ...    0.009264   \n",
       "31    0.001795    0.001748    0.001848    0.001749  ...    0.009306   \n",
       "\n",
       "    440.353000  440.406100  440.459200  440.512300  440.565300  440.618400  \\\n",
       "35    0.024789    0.039555    0.052539    0.055079    0.031357    0.013462   \n",
       "5     0.025239    0.039833    0.052818    0.054146    0.030239    0.013039   \n",
       "44    0.024194    0.038571    0.050760    0.053431    0.030757    0.013450   \n",
       "48    0.024440    0.038970    0.051471    0.053686    0.030573    0.013225   \n",
       "15    0.024276    0.038708    0.051270    0.054081    0.031143    0.013503   \n",
       "26    0.024398    0.039071    0.051843    0.054894    0.031643    0.013588   \n",
       "12    0.024705    0.039226    0.051976    0.054433    0.030961    0.013338   \n",
       "56    0.024827    0.039551    0.052294    0.054697    0.031189    0.013492   \n",
       "34    0.024951    0.039949    0.053156    0.055755    0.031693    0.013509   \n",
       "38    0.024716    0.039471    0.052239    0.054580    0.031010    0.013299   \n",
       "24    0.024203    0.038787    0.051400    0.054596    0.031559    0.013622   \n",
       "31    0.024457    0.039228    0.052146    0.055048    0.031634    0.013594   \n",
       "\n",
       "    440.671400  440.724500  440.777500  \n",
       "35    0.007122    0.006264    0.005974  \n",
       "5     0.007087    0.006425    0.006249  \n",
       "44    0.007265    0.006472    0.006224  \n",
       "48    0.007104    0.006317    0.006069  \n",
       "15    0.007239    0.006436    0.006225  \n",
       "26    0.007146    0.006214    0.005899  \n",
       "12    0.007150    0.006321    0.006043  \n",
       "56    0.007249    0.006446    0.006189  \n",
       "34    0.007096    0.006213    0.005896  \n",
       "38    0.007079    0.006253    0.006003  \n",
       "24    0.007192    0.006274    0.005977  \n",
       "31    0.007151    0.006238    0.005933  \n",
       "\n",
       "[12 rows x 4094 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = normalize(X_train, axis=1)\n",
    "X_test = normalize(X_test, axis=1)\n",
    "#print(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters for the network\n",
    "DENSE = 128\n",
    "DROPOUT = 0.5\n",
    "C1_K  = 8 #Number of kernels/feature extractors for first layer\n",
    "C1_S  = 32 #Width of the convolutional mini networks\n",
    "C2_K  = 16\n",
    "C2_S  = 32\n",
    "\n",
    "activation='relu'\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "#The model\n",
    "def make_model():\n",
    "    model = Sequential()\n",
    "    #Adding a bit of GaussianNoise also works as regularization\n",
    "    model.add(GaussianNoise(0.05, input_shape=(input_dim,)))\n",
    "    #First two is number of filter + kernel size\n",
    "    model.add(Reshape((input_dim, 1)))\n",
    "    model.add(Conv1D(C1_K, (C1_S), activation=activation, border_mode=\"same\"))\n",
    "    model.add(Conv1D(C2_K, (C2_S), border_mode=\"same\", activation=activation))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(DENSE, activation=activation))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer=keras.optimizers.Adadelta(lr=0.01))#, metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(8, 32, activation=\"relu\", padding=\"same\")`\n",
      "C:\\Users\\olivier.nicolini\\.conda\\envs\\tf_env\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(16, 32, activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_2 (GaussianNo (None, 4094)              0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4094, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4094, 8)           264       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 4094, 16)          4112      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 65504)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 65504)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               8384640   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,389,145\n",
      "Trainable params: 8,389,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37 samples, validate on 10 samples\n",
      "Epoch 1/600\n",
      " - 1s - loss: 0.4461 - val_loss: 1.2368\n",
      "Epoch 2/600\n",
      " - 1s - loss: 0.4516 - val_loss: 1.2181\n",
      "Epoch 3/600\n",
      " - 1s - loss: 0.4393 - val_loss: 1.2502\n",
      "Epoch 4/600\n",
      " - 1s - loss: 0.4409 - val_loss: 1.2507\n",
      "Epoch 5/600\n",
      " - 1s - loss: 0.4432 - val_loss: 1.2678\n",
      "Epoch 6/600\n",
      " - 1s - loss: 0.4525 - val_loss: 1.3302\n",
      "Epoch 7/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.2931\n",
      "Epoch 8/600\n",
      " - 1s - loss: 0.4557 - val_loss: 1.2650\n",
      "Epoch 9/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.2672\n",
      "Epoch 10/600\n",
      " - 1s - loss: 0.4455 - val_loss: 1.2836\n",
      "Epoch 11/600\n",
      " - 1s - loss: 0.4488 - val_loss: 1.2653\n",
      "Epoch 12/600\n",
      " - 1s - loss: 0.4532 - val_loss: 1.2485\n",
      "Epoch 13/600\n",
      " - 1s - loss: 0.4473 - val_loss: 1.2118\n",
      "Epoch 14/600\n",
      " - 1s - loss: 0.4523 - val_loss: 1.2733\n",
      "Epoch 15/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.2439\n",
      "Epoch 16/600\n",
      " - 1s - loss: 0.4428 - val_loss: 1.2378\n",
      "Epoch 17/600\n",
      " - 1s - loss: 0.4420 - val_loss: 1.3046\n",
      "Epoch 18/600\n",
      " - 1s - loss: 0.4328 - val_loss: 1.2915\n",
      "Epoch 19/600\n",
      " - 1s - loss: 0.4448 - val_loss: 1.2443\n",
      "Epoch 20/600\n",
      " - 1s - loss: 0.4444 - val_loss: 1.2688\n",
      "Epoch 21/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2559\n",
      "Epoch 22/600\n",
      " - 1s - loss: 0.4479 - val_loss: 1.2702\n",
      "Epoch 23/600\n",
      " - 1s - loss: 0.4334 - val_loss: 1.2668\n",
      "Epoch 24/600\n",
      " - 1s - loss: 0.4432 - val_loss: 1.2707\n",
      "Epoch 25/600\n",
      " - 1s - loss: 0.4519 - val_loss: 1.2884\n",
      "Epoch 26/600\n",
      " - 1s - loss: 0.4452 - val_loss: 1.2840\n",
      "Epoch 27/600\n",
      " - 1s - loss: 0.4229 - val_loss: 1.2885\n",
      "Epoch 28/600\n",
      " - 1s - loss: 0.4440 - val_loss: 1.3198\n",
      "Epoch 29/600\n",
      " - 1s - loss: 0.4310 - val_loss: 1.3066\n",
      "Epoch 30/600\n",
      " - 1s - loss: 0.4451 - val_loss: 1.2588\n",
      "Epoch 31/600\n",
      " - 1s - loss: 0.4524 - val_loss: 1.2564\n",
      "Epoch 32/600\n",
      " - 1s - loss: 0.4235 - val_loss: 1.2601\n",
      "Epoch 33/600\n",
      " - 1s - loss: 0.4320 - val_loss: 1.2820\n",
      "Epoch 34/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.2161\n",
      "Epoch 35/600\n",
      " - 1s - loss: 0.4474 - val_loss: 1.1964\n",
      "Epoch 36/600\n",
      " - 1s - loss: 0.4458 - val_loss: 1.2608\n",
      "Epoch 37/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.2397\n",
      "Epoch 38/600\n",
      " - 1s - loss: 0.4498 - val_loss: 1.2754\n",
      "Epoch 39/600\n",
      " - 1s - loss: 0.4423 - val_loss: 1.2592\n",
      "Epoch 40/600\n",
      " - 1s - loss: 0.4436 - val_loss: 1.2378\n",
      "Epoch 41/600\n",
      " - 1s - loss: 0.4503 - val_loss: 1.2450\n",
      "Epoch 42/600\n",
      " - 1s - loss: 0.4477 - val_loss: 1.2669\n",
      "Epoch 43/600\n",
      " - 1s - loss: 0.4311 - val_loss: 1.3088\n",
      "Epoch 44/600\n",
      " - 1s - loss: 0.4560 - val_loss: 1.2658\n",
      "Epoch 45/600\n",
      " - 1s - loss: 0.4405 - val_loss: 1.2557\n",
      "Epoch 46/600\n",
      " - 1s - loss: 0.4413 - val_loss: 1.2585\n",
      "Epoch 47/600\n",
      " - 1s - loss: 0.4417 - val_loss: 1.2318\n",
      "Epoch 48/600\n",
      " - 1s - loss: 0.4464 - val_loss: 1.2622\n",
      "Epoch 49/600\n",
      " - 1s - loss: 0.4457 - val_loss: 1.2491\n",
      "Epoch 50/600\n",
      " - 1s - loss: 0.4468 - val_loss: 1.2464\n",
      "Epoch 51/600\n",
      " - 1s - loss: 0.4437 - val_loss: 1.2835\n",
      "Epoch 52/600\n",
      " - 1s - loss: 0.4530 - val_loss: 1.3085\n",
      "Epoch 53/600\n",
      " - 1s - loss: 0.4542 - val_loss: 1.2827\n",
      "Epoch 54/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2711\n",
      "Epoch 55/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.2664\n",
      "Epoch 56/600\n",
      " - 1s - loss: 0.4610 - val_loss: 1.2875\n",
      "Epoch 57/600\n",
      " - 1s - loss: 0.4242 - val_loss: 1.2604\n",
      "Epoch 58/600\n",
      " - 1s - loss: 0.4614 - val_loss: 1.2806\n",
      "Epoch 59/600\n",
      " - 1s - loss: 0.4268 - val_loss: 1.2738\n",
      "Epoch 60/600\n",
      " - 1s - loss: 0.4408 - val_loss: 1.2723\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 61/600\n",
      " - 1s - loss: 0.4461 - val_loss: 1.2559\n",
      "Epoch 62/600\n",
      " - 1s - loss: 0.4435 - val_loss: 1.2417\n",
      "Epoch 63/600\n",
      " - 1s - loss: 0.4475 - val_loss: 1.2487\n",
      "Epoch 64/600\n",
      " - 1s - loss: 0.4605 - val_loss: 1.2373\n",
      "Epoch 65/600\n",
      " - 1s - loss: 0.4407 - val_loss: 1.2565\n",
      "Epoch 66/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.2510\n",
      "Epoch 67/600\n",
      " - 1s - loss: 0.4383 - val_loss: 1.2431\n",
      "Epoch 68/600\n",
      " - 1s - loss: 0.4277 - val_loss: 1.2600\n",
      "Epoch 69/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.2379\n",
      "Epoch 70/600\n",
      " - 1s - loss: 0.4325 - val_loss: 1.2256\n",
      "Epoch 71/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.2434\n",
      "Epoch 72/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.2241\n",
      "Epoch 73/600\n",
      " - 1s - loss: 0.4399 - val_loss: 1.2349\n",
      "Epoch 74/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.2266\n",
      "Epoch 75/600\n",
      " - 1s - loss: 0.4492 - val_loss: 1.2576\n",
      "Epoch 76/600\n",
      " - 1s - loss: 0.4268 - val_loss: 1.2658\n",
      "Epoch 77/600\n",
      " - 1s - loss: 0.4477 - val_loss: 1.2583\n",
      "Epoch 78/600\n",
      " - 1s - loss: 0.4356 - val_loss: 1.2574\n",
      "Epoch 79/600\n",
      " - 1s - loss: 0.4168 - val_loss: 1.2385\n",
      "Epoch 80/600\n",
      " - 1s - loss: 0.4469 - val_loss: 1.2493\n",
      "Epoch 81/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.2428\n",
      "Epoch 82/600\n",
      " - 1s - loss: 0.4458 - val_loss: 1.2345\n",
      "Epoch 83/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.2309\n",
      "Epoch 84/600\n",
      " - 1s - loss: 0.4273 - val_loss: 1.2214\n",
      "Epoch 85/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.2214\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 86/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.2223\n",
      "Epoch 87/600\n",
      " - 1s - loss: 0.4449 - val_loss: 1.2248\n",
      "Epoch 88/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.2256\n",
      "Epoch 89/600\n",
      " - 1s - loss: 0.4170 - val_loss: 1.2180\n",
      "Epoch 90/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.2200\n",
      "Epoch 91/600\n",
      " - 1s - loss: 0.4247 - val_loss: 1.2203\n",
      "Epoch 92/600\n",
      " - 1s - loss: 0.4473 - val_loss: 1.2207\n",
      "Epoch 93/600\n",
      " - 1s - loss: 0.4352 - val_loss: 1.2171\n",
      "Epoch 94/600\n",
      " - 1s - loss: 0.4289 - val_loss: 1.2143\n",
      "Epoch 95/600\n",
      " - 1s - loss: 0.4290 - val_loss: 1.2195\n",
      "Epoch 96/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.2208\n",
      "Epoch 97/600\n",
      " - 1s - loss: 0.4377 - val_loss: 1.2284\n",
      "Epoch 98/600\n",
      " - 1s - loss: 0.4505 - val_loss: 1.2371\n",
      "Epoch 99/600\n",
      " - 1s - loss: 0.4461 - val_loss: 1.2299\n",
      "Epoch 100/600\n",
      " - 1s - loss: 0.4370 - val_loss: 1.2339\n",
      "Epoch 101/600\n",
      " - 1s - loss: 0.4221 - val_loss: 1.2371\n",
      "Epoch 102/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.2331\n",
      "Epoch 103/600\n",
      " - 1s - loss: 0.4444 - val_loss: 1.2290\n",
      "Epoch 104/600\n",
      " - 1s - loss: 0.4443 - val_loss: 1.2387\n",
      "Epoch 105/600\n",
      " - 1s - loss: 0.4434 - val_loss: 1.2435\n",
      "Epoch 106/600\n",
      " - 1s - loss: 0.4261 - val_loss: 1.2498\n",
      "Epoch 107/600\n",
      " - 1s - loss: 0.4402 - val_loss: 1.2507\n",
      "Epoch 108/600\n",
      " - 1s - loss: 0.4485 - val_loss: 1.2408\n",
      "Epoch 109/600\n",
      " - 1s - loss: 0.4442 - val_loss: 1.2429\n",
      "Epoch 110/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.2446\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "Epoch 111/600\n",
      " - 1s - loss: 0.4438 - val_loss: 1.2451\n",
      "Epoch 112/600\n",
      " - 1s - loss: 0.4464 - val_loss: 1.2416\n",
      "Epoch 113/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.2446\n",
      "Epoch 114/600\n",
      " - 1s - loss: 0.4338 - val_loss: 1.2452\n",
      "Epoch 115/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.2463\n",
      "Epoch 116/600\n",
      " - 1s - loss: 0.4338 - val_loss: 1.2456\n",
      "Epoch 117/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.2432\n",
      "Epoch 118/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.2429\n",
      "Epoch 119/600\n",
      " - 1s - loss: 0.4238 - val_loss: 1.2401\n",
      "Epoch 120/600\n",
      " - 1s - loss: 0.4423 - val_loss: 1.2370\n",
      "Epoch 121/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.2368\n",
      "Epoch 122/600\n",
      " - 1s - loss: 0.4451 - val_loss: 1.2400\n",
      "Epoch 123/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.2426\n",
      "Epoch 124/600\n",
      " - 1s - loss: 0.4403 - val_loss: 1.2415\n",
      "Epoch 125/600\n",
      " - 1s - loss: 0.4325 - val_loss: 1.2408\n",
      "Epoch 126/600\n",
      " - 1s - loss: 0.4473 - val_loss: 1.2379\n",
      "Epoch 127/600\n",
      " - 1s - loss: 0.4466 - val_loss: 1.2385\n",
      "Epoch 128/600\n",
      " - 1s - loss: 0.4311 - val_loss: 1.2409\n",
      "Epoch 129/600\n",
      " - 1s - loss: 0.4406 - val_loss: 1.2437\n",
      "Epoch 130/600\n",
      " - 1s - loss: 0.4478 - val_loss: 1.2428\n",
      "Epoch 131/600\n",
      " - 1s - loss: 0.4407 - val_loss: 1.2424\n",
      "Epoch 132/600\n",
      " - 1s - loss: 0.4518 - val_loss: 1.2395\n",
      "Epoch 133/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.2403\n",
      "Epoch 134/600\n",
      " - 1s - loss: 0.4459 - val_loss: 1.2357\n",
      "Epoch 135/600\n",
      " - 1s - loss: 0.4334 - val_loss: 1.2350\n",
      "\n",
      "Epoch 00135: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 136/600\n",
      " - 1s - loss: 0.4388 - val_loss: 1.2349\n",
      "Epoch 137/600\n",
      " - 1s - loss: 0.4421 - val_loss: 1.2357\n",
      "Epoch 138/600\n",
      " - 1s - loss: 0.4248 - val_loss: 1.2362\n",
      "Epoch 139/600\n",
      " - 1s - loss: 0.4420 - val_loss: 1.2352\n",
      "Epoch 140/600\n",
      " - 1s - loss: 0.4448 - val_loss: 1.2345\n",
      "Epoch 141/600\n",
      " - 1s - loss: 0.4476 - val_loss: 1.2363\n",
      "Epoch 142/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.2344\n",
      "Epoch 143/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.2358\n",
      "Epoch 144/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.2361\n",
      "Epoch 145/600\n",
      " - 1s - loss: 0.4436 - val_loss: 1.2347\n",
      "Epoch 146/600\n",
      " - 1s - loss: 0.4300 - val_loss: 1.2353\n",
      "Epoch 147/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.2354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/600\n",
      " - 1s - loss: 0.4224 - val_loss: 1.2348\n",
      "Epoch 149/600\n",
      " - 1s - loss: 0.4279 - val_loss: 1.2352\n",
      "Epoch 150/600\n",
      " - 1s - loss: 0.4389 - val_loss: 1.2356\n",
      "Epoch 151/600\n",
      " - 1s - loss: 0.4232 - val_loss: 1.2357\n",
      "Epoch 152/600\n",
      " - 1s - loss: 0.4232 - val_loss: 1.2348\n",
      "Epoch 153/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2341\n",
      "Epoch 154/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.2342\n",
      "Epoch 155/600\n",
      " - 1s - loss: 0.4301 - val_loss: 1.2335\n",
      "Epoch 156/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.2337\n",
      "Epoch 157/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.2344\n",
      "Epoch 158/600\n",
      " - 1s - loss: 0.4391 - val_loss: 1.2352\n",
      "Epoch 159/600\n",
      " - 1s - loss: 0.4354 - val_loss: 1.2358\n",
      "Epoch 160/600\n",
      " - 1s - loss: 0.4282 - val_loss: 1.2338\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "Epoch 161/600\n",
      " - 1s - loss: 0.4358 - val_loss: 1.2341\n",
      "Epoch 162/600\n",
      " - 1s - loss: 0.4225 - val_loss: 1.2347\n",
      "Epoch 163/600\n",
      " - 1s - loss: 0.4243 - val_loss: 1.2343\n",
      "Epoch 164/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2345\n",
      "Epoch 165/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.2341\n",
      "Epoch 166/600\n",
      " - 1s - loss: 0.4390 - val_loss: 1.2342\n",
      "Epoch 167/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2338\n",
      "Epoch 168/600\n",
      " - 1s - loss: 0.4312 - val_loss: 1.2336\n",
      "Epoch 169/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.2333\n",
      "Epoch 170/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.2326\n",
      "Epoch 171/600\n",
      " - 1s - loss: 0.4273 - val_loss: 1.2331\n",
      "Epoch 172/600\n",
      " - 1s - loss: 0.4334 - val_loss: 1.2332\n",
      "Epoch 173/600\n",
      " - 1s - loss: 0.4381 - val_loss: 1.2328\n",
      "Epoch 174/600\n",
      " - 1s - loss: 0.4488 - val_loss: 1.2336\n",
      "Epoch 175/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.2329\n",
      "Epoch 176/600\n",
      " - 1s - loss: 0.4433 - val_loss: 1.2332\n",
      "Epoch 177/600\n",
      " - 1s - loss: 0.4289 - val_loss: 1.2332\n",
      "Epoch 178/600\n",
      " - 1s - loss: 0.4408 - val_loss: 1.2332\n",
      "Epoch 179/600\n",
      " - 1s - loss: 0.4239 - val_loss: 1.2330\n",
      "Epoch 180/600\n",
      " - 1s - loss: 0.4360 - val_loss: 1.2329\n",
      "Epoch 181/600\n",
      " - 1s - loss: 0.4265 - val_loss: 1.2337\n",
      "Epoch 182/600\n",
      " - 1s - loss: 0.4371 - val_loss: 1.2339\n",
      "Epoch 183/600\n",
      " - 1s - loss: 0.4430 - val_loss: 1.2336\n",
      "Epoch 184/600\n",
      " - 1s - loss: 0.4431 - val_loss: 1.2331\n",
      "Epoch 185/600\n",
      " - 1s - loss: 0.4422 - val_loss: 1.2330\n",
      "\n",
      "Epoch 00185: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 186/600\n",
      " - 1s - loss: 0.4335 - val_loss: 1.2326\n",
      "Epoch 187/600\n",
      " - 1s - loss: 0.4282 - val_loss: 1.2326\n",
      "Epoch 188/600\n",
      " - 1s - loss: 0.4328 - val_loss: 1.2327\n",
      "Epoch 189/600\n",
      " - 1s - loss: 0.4329 - val_loss: 1.2326\n",
      "Epoch 190/600\n",
      " - 1s - loss: 0.4338 - val_loss: 1.2324\n",
      "Epoch 191/600\n",
      " - 1s - loss: 0.4469 - val_loss: 1.2324\n",
      "Epoch 192/600\n",
      " - 1s - loss: 0.4419 - val_loss: 1.2327\n",
      "Epoch 193/600\n",
      " - 1s - loss: 0.4334 - val_loss: 1.2326\n",
      "Epoch 194/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.2329\n",
      "Epoch 195/600\n",
      " - 1s - loss: 0.4346 - val_loss: 1.2330\n",
      "Epoch 196/600\n",
      " - 1s - loss: 0.4363 - val_loss: 1.2330\n",
      "Epoch 197/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.2332\n",
      "Epoch 198/600\n",
      " - 1s - loss: 0.4435 - val_loss: 1.2330\n",
      "Epoch 199/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2330\n",
      "Epoch 200/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2330\n",
      "Epoch 201/600\n",
      " - 1s - loss: 0.4420 - val_loss: 1.2331\n",
      "Epoch 202/600\n",
      " - 1s - loss: 0.4377 - val_loss: 1.2331\n",
      "Epoch 203/600\n",
      " - 1s - loss: 0.4486 - val_loss: 1.2332\n",
      "Epoch 204/600\n",
      " - 1s - loss: 0.4230 - val_loss: 1.2329\n",
      "Epoch 205/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.2332\n",
      "Epoch 206/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.2329\n",
      "Epoch 207/600\n",
      " - 1s - loss: 0.4328 - val_loss: 1.2327\n",
      "Epoch 208/600\n",
      " - 1s - loss: 0.4185 - val_loss: 1.2324\n",
      "Epoch 209/600\n",
      " - 1s - loss: 0.4293 - val_loss: 1.2322\n",
      "Epoch 210/600\n",
      " - 1s - loss: 0.4360 - val_loss: 1.2325\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
      "Epoch 211/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.2322\n",
      "Epoch 212/600\n",
      " - 1s - loss: 0.4358 - val_loss: 1.2322\n",
      "Epoch 213/600\n",
      " - 1s - loss: 0.4422 - val_loss: 1.2322\n",
      "Epoch 214/600\n",
      " - 1s - loss: 0.4341 - val_loss: 1.2322\n",
      "Epoch 215/600\n",
      " - 1s - loss: 0.4348 - val_loss: 1.2323\n",
      "Epoch 216/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.2325\n",
      "Epoch 217/600\n",
      " - 1s - loss: 0.4211 - val_loss: 1.2324\n",
      "Epoch 218/600\n",
      " - 1s - loss: 0.4292 - val_loss: 1.2325\n",
      "Epoch 219/600\n",
      " - 1s - loss: 0.4315 - val_loss: 1.2323\n",
      "Epoch 220/600\n",
      " - 1s - loss: 0.4383 - val_loss: 1.2323\n",
      "Epoch 221/600\n",
      " - 1s - loss: 0.4489 - val_loss: 1.2322\n",
      "Epoch 222/600\n",
      " - 1s - loss: 0.4319 - val_loss: 1.2322\n",
      "Epoch 223/600\n",
      " - 1s - loss: 0.4421 - val_loss: 1.2320\n",
      "Epoch 224/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.2320\n",
      "Epoch 225/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.2320\n",
      "Epoch 226/600\n",
      " - 1s - loss: 0.4271 - val_loss: 1.2318\n",
      "Epoch 227/600\n",
      " - 1s - loss: 0.4288 - val_loss: 1.2318\n",
      "Epoch 228/600\n",
      " - 1s - loss: 0.4434 - val_loss: 1.2318\n",
      "Epoch 229/600\n",
      " - 1s - loss: 0.4385 - val_loss: 1.2319\n",
      "Epoch 230/600\n",
      " - 1s - loss: 0.4326 - val_loss: 1.2320\n",
      "Epoch 231/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.2319\n",
      "Epoch 232/600\n",
      " - 1s - loss: 0.4346 - val_loss: 1.2320\n",
      "Epoch 233/600\n",
      " - 1s - loss: 0.4261 - val_loss: 1.2323\n",
      "Epoch 234/600\n",
      " - 1s - loss: 0.4246 - val_loss: 1.2323\n",
      "Epoch 235/600\n",
      " - 1s - loss: 0.4386 - val_loss: 1.2324\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Epoch 236/600\n",
      " - 1s - loss: 0.4320 - val_loss: 1.2325\n",
      "Epoch 237/600\n",
      " - 1s - loss: 0.4406 - val_loss: 1.2323\n",
      "Epoch 238/600\n",
      " - 1s - loss: 0.4443 - val_loss: 1.2323\n",
      "Epoch 239/600\n",
      " - 1s - loss: 0.4402 - val_loss: 1.2323\n",
      "Epoch 240/600\n",
      " - 1s - loss: 0.4256 - val_loss: 1.2324\n",
      "Epoch 241/600\n",
      " - 1s - loss: 0.4253 - val_loss: 1.2323\n",
      "Epoch 242/600\n",
      " - 1s - loss: 0.4413 - val_loss: 1.2324\n",
      "Epoch 243/600\n",
      " - 1s - loss: 0.4302 - val_loss: 1.2324\n",
      "Epoch 244/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.2324\n",
      "Epoch 245/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.2324\n",
      "Epoch 246/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.2323\n",
      "Epoch 247/600\n",
      " - 1s - loss: 0.4264 - val_loss: 1.2323\n",
      "Epoch 248/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.2323\n",
      "Epoch 249/600\n",
      " - 1s - loss: 0.4286 - val_loss: 1.2324\n",
      "Epoch 250/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.2324\n",
      "Epoch 251/600\n",
      " - 1s - loss: 0.4366 - val_loss: 1.2325\n",
      "Epoch 252/600\n",
      " - 1s - loss: 0.4389 - val_loss: 1.2325\n",
      "Epoch 253/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.2324\n",
      "Epoch 254/600\n",
      " - 1s - loss: 0.4504 - val_loss: 1.2324\n",
      "Epoch 255/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.2324\n",
      "Epoch 256/600\n",
      " - 1s - loss: 0.4385 - val_loss: 1.2325\n",
      "Epoch 257/600\n",
      " - 2s - loss: 0.4270 - val_loss: 1.2325\n",
      "Epoch 258/600\n",
      " - 1s - loss: 0.4238 - val_loss: 1.2325\n",
      "Epoch 259/600\n",
      " - 1s - loss: 0.4426 - val_loss: 1.2325\n",
      "Epoch 260/600\n",
      " - 1s - loss: 0.4162 - val_loss: 1.2324\n",
      "\n",
      "Epoch 00260: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
      "Epoch 261/600\n",
      " - 1s - loss: 0.4438 - val_loss: 1.2324\n",
      "Epoch 262/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.2324\n",
      "Epoch 263/600\n",
      " - 1s - loss: 0.4409 - val_loss: 1.2324\n",
      "Epoch 264/600\n",
      " - 1s - loss: 0.4402 - val_loss: 1.2324\n",
      "Epoch 265/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.2324\n",
      "Epoch 266/600\n",
      " - 1s - loss: 0.4186 - val_loss: 1.2323\n",
      "Epoch 267/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.2323\n",
      "Epoch 268/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.2323\n",
      "Epoch 269/600\n",
      " - 1s - loss: 0.4413 - val_loss: 1.2323\n",
      "Epoch 270/600\n",
      " - 1s - loss: 0.4253 - val_loss: 1.2323\n",
      "Epoch 271/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.2323\n",
      "Epoch 272/600\n",
      " - 1s - loss: 0.4458 - val_loss: 1.2323\n",
      "Epoch 273/600\n",
      " - 1s - loss: 0.4489 - val_loss: 1.2323\n",
      "Epoch 274/600\n",
      " - 1s - loss: 0.4401 - val_loss: 1.2323\n",
      "Epoch 275/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.2323\n",
      "Epoch 276/600\n",
      " - 1s - loss: 0.4391 - val_loss: 1.2322\n",
      "Epoch 277/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.2323\n",
      "Epoch 278/600\n",
      " - 1s - loss: 0.4211 - val_loss: 1.2322\n",
      "Epoch 279/600\n",
      " - 1s - loss: 0.4390 - val_loss: 1.2323\n",
      "Epoch 280/600\n",
      " - 1s - loss: 0.4180 - val_loss: 1.2323\n",
      "Epoch 281/600\n",
      " - 1s - loss: 0.4402 - val_loss: 1.2323\n",
      "Epoch 282/600\n",
      " - 1s - loss: 0.4408 - val_loss: 1.2323\n",
      "Epoch 283/600\n",
      " - 1s - loss: 0.4428 - val_loss: 1.2322\n",
      "Epoch 284/600\n",
      " - 1s - loss: 0.4324 - val_loss: 1.2322\n",
      "Epoch 285/600\n",
      " - 1s - loss: 0.4413 - val_loss: 1.2322\n",
      "\n",
      "Epoch 00285: ReduceLROnPlateau reducing learning rate to 9.765624781721272e-06.\n",
      "Epoch 286/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.2322\n",
      "Epoch 287/600\n",
      " - 1s - loss: 0.4422 - val_loss: 1.2322\n",
      "Epoch 288/600\n",
      " - 1s - loss: 0.4440 - val_loss: 1.2323\n",
      "Epoch 289/600\n",
      " - 1s - loss: 0.4455 - val_loss: 1.2323\n",
      "Epoch 290/600\n",
      " - 1s - loss: 0.4331 - val_loss: 1.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/600\n",
      " - 1s - loss: 0.4358 - val_loss: 1.2322\n",
      "Epoch 292/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.2323\n",
      "Epoch 293/600\n",
      " - 1s - loss: 0.4431 - val_loss: 1.2323\n",
      "Epoch 294/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.2323\n",
      "Epoch 295/600\n",
      " - 1s - loss: 0.4450 - val_loss: 1.2323\n",
      "Epoch 296/600\n",
      " - 1s - loss: 0.4420 - val_loss: 1.2323\n",
      "Epoch 297/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.2322\n",
      "Epoch 298/600\n",
      " - 1s - loss: 0.4425 - val_loss: 1.2322\n",
      "Epoch 299/600\n",
      " - 1s - loss: 0.4442 - val_loss: 1.2322\n",
      "Epoch 300/600\n",
      " - 1s - loss: 0.4283 - val_loss: 1.2322\n",
      "Epoch 301/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.2322\n",
      "Epoch 302/600\n",
      " - 1s - loss: 0.4380 - val_loss: 1.2322\n",
      "Epoch 303/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.2322\n",
      "Epoch 304/600\n",
      " - 1s - loss: 0.4353 - val_loss: 1.2322\n",
      "Epoch 305/600\n",
      " - 1s - loss: 0.4371 - val_loss: 1.2322\n",
      "Epoch 306/600\n",
      " - 1s - loss: 0.4327 - val_loss: 1.2322\n",
      "Epoch 307/600\n",
      " - 1s - loss: 0.4465 - val_loss: 1.2322\n",
      "Epoch 308/600\n",
      " - 1s - loss: 0.4296 - val_loss: 1.2322\n",
      "Epoch 309/600\n",
      " - 1s - loss: 0.4391 - val_loss: 1.2322\n",
      "Epoch 310/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.2322\n",
      "\n",
      "Epoch 00310: ReduceLROnPlateau reducing learning rate to 4.882812390860636e-06.\n",
      "Epoch 311/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.2322\n",
      "Epoch 312/600\n",
      " - 1s - loss: 0.4304 - val_loss: 1.2322\n",
      "Epoch 313/600\n",
      " - 1s - loss: 0.4286 - val_loss: 1.2322\n",
      "Epoch 314/600\n",
      " - 1s - loss: 0.4360 - val_loss: 1.2322\n",
      "Epoch 315/600\n",
      " - 1s - loss: 0.4271 - val_loss: 1.2322\n",
      "Epoch 316/600\n",
      " - 1s - loss: 0.4416 - val_loss: 1.2322\n",
      "Epoch 317/600\n",
      " - 1s - loss: 0.4285 - val_loss: 1.2322\n",
      "Epoch 318/600\n",
      " - 1s - loss: 0.4428 - val_loss: 1.2322\n",
      "Epoch 319/600\n",
      " - 1s - loss: 0.4310 - val_loss: 1.2322\n",
      "Epoch 320/600\n",
      " - 1s - loss: 0.4253 - val_loss: 1.2322\n",
      "Epoch 321/600\n",
      " - 1s - loss: 0.4388 - val_loss: 1.2322\n",
      "Epoch 322/600\n",
      " - 1s - loss: 0.4370 - val_loss: 1.2322\n",
      "Epoch 323/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.2322\n",
      "Epoch 324/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.2321\n",
      "Epoch 325/600\n",
      " - 1s - loss: 0.4282 - val_loss: 1.2321\n",
      "Epoch 326/600\n",
      " - 1s - loss: 0.4425 - val_loss: 1.2321\n",
      "Epoch 327/600\n",
      " - 1s - loss: 0.4393 - val_loss: 1.2321\n",
      "Epoch 328/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.2321\n",
      "Epoch 329/600\n",
      " - 1s - loss: 0.4413 - val_loss: 1.2321\n",
      "Epoch 330/600\n",
      " - 1s - loss: 0.4412 - val_loss: 1.2321\n",
      "Epoch 331/600\n",
      " - 1s - loss: 0.4457 - val_loss: 1.2321\n",
      "Epoch 332/600\n",
      " - 1s - loss: 0.4245 - val_loss: 1.2321\n",
      "Epoch 333/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.2321\n",
      "Epoch 334/600\n",
      " - 1s - loss: 0.4423 - val_loss: 1.2321\n",
      "Epoch 335/600\n",
      " - 1s - loss: 0.4392 - val_loss: 1.2321\n",
      "\n",
      "Epoch 00335: ReduceLROnPlateau reducing learning rate to 2.441406195430318e-06.\n",
      "Epoch 336/600\n",
      " - 1s - loss: 0.4349 - val_loss: 1.2321\n",
      "Epoch 337/600\n",
      " - 1s - loss: 0.4496 - val_loss: 1.2321\n",
      "Epoch 338/600\n",
      " - 1s - loss: 0.4255 - val_loss: 1.2321\n",
      "Epoch 339/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.2321\n",
      "Epoch 340/600\n",
      " - 1s - loss: 0.4471 - val_loss: 1.2321\n",
      "Epoch 341/600\n",
      " - 1s - loss: 0.4278 - val_loss: 1.2321\n",
      "Epoch 342/600\n",
      " - 1s - loss: 0.4273 - val_loss: 1.2321\n",
      "Epoch 343/600\n",
      " - 1s - loss: 0.4279 - val_loss: 1.2321\n",
      "Epoch 344/600\n",
      " - 1s - loss: 0.4299 - val_loss: 1.2321\n",
      "Epoch 345/600\n",
      " - 1s - loss: 0.4312 - val_loss: 1.2322\n",
      "Epoch 346/600\n",
      " - 1s - loss: 0.4394 - val_loss: 1.2322\n",
      "Epoch 347/600\n",
      " - 1s - loss: 0.4344 - val_loss: 1.2322\n",
      "Epoch 348/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.2322\n",
      "Epoch 349/600\n",
      " - 1s - loss: 0.4479 - val_loss: 1.2322\n",
      "Epoch 350/600\n",
      " - 1s - loss: 0.4333 - val_loss: 1.2322\n",
      "Epoch 351/600\n",
      " - 1s - loss: 0.4344 - val_loss: 1.2321\n",
      "Epoch 352/600\n",
      " - 1s - loss: 0.4343 - val_loss: 1.2321\n",
      "Epoch 353/600\n",
      " - 1s - loss: 0.4410 - val_loss: 1.2321\n",
      "Epoch 354/600\n",
      " - 1s - loss: 0.4450 - val_loss: 1.2321\n",
      "Epoch 355/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.2321\n",
      "Epoch 356/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.2321\n",
      "Epoch 357/600\n",
      " - 1s - loss: 0.4280 - val_loss: 1.2321\n",
      "Epoch 358/600\n",
      " - 1s - loss: 0.4414 - val_loss: 1.2321\n",
      "Epoch 359/600\n",
      " - 1s - loss: 0.4444 - val_loss: 1.2321\n",
      "Epoch 360/600\n",
      " - 1s - loss: 0.4451 - val_loss: 1.2321\n",
      "\n",
      "Epoch 00360: ReduceLROnPlateau reducing learning rate to 1.220703097715159e-06.\n",
      "Epoch 361/600\n",
      " - 1s - loss: 0.4410 - val_loss: 1.2322\n",
      "Epoch 362/600\n",
      " - 1s - loss: 0.4427 - val_loss: 1.2321\n",
      "Epoch 363/600\n",
      " - 1s - loss: 0.4314 - val_loss: 1.2321\n",
      "Epoch 364/600\n",
      " - 1s - loss: 0.4434 - val_loss: 1.2321\n",
      "Epoch 365/600\n",
      " - 1s - loss: 0.4349 - val_loss: 1.2321\n",
      "Epoch 366/600\n",
      " - 1s - loss: 0.4315 - val_loss: 1.2321\n",
      "Epoch 367/600\n",
      " - 1s - loss: 0.4211 - val_loss: 1.2322\n",
      "Epoch 368/600\n",
      " - 1s - loss: 0.4439 - val_loss: 1.2322\n",
      "Epoch 369/600\n",
      " - 1s - loss: 0.4379 - val_loss: 1.2322\n",
      "Epoch 370/600\n",
      " - 1s - loss: 0.4377 - val_loss: 1.2322\n",
      "Epoch 371/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.2322\n",
      "Epoch 372/600\n",
      " - 1s - loss: 0.4272 - val_loss: 1.2322\n",
      "Epoch 373/600\n",
      " - 1s - loss: 0.4237 - val_loss: 1.2322\n",
      "Epoch 374/600\n",
      " - 1s - loss: 0.4416 - val_loss: 1.2322\n",
      "Epoch 375/600\n",
      " - 1s - loss: 0.4313 - val_loss: 1.2322\n",
      "Epoch 376/600\n",
      " - 1s - loss: 0.4436 - val_loss: 1.2322\n",
      "Epoch 377/600\n",
      " - 1s - loss: 0.4502 - val_loss: 1.2322\n",
      "Epoch 378/600\n",
      " - 1s - loss: 0.4454 - val_loss: 1.2322\n",
      "Epoch 379/600\n",
      " - 1s - loss: 0.4349 - val_loss: 1.2322\n",
      "Epoch 380/600\n",
      " - 1s - loss: 0.4416 - val_loss: 1.2322\n",
      "Epoch 381/600\n",
      " - 1s - loss: 0.4243 - val_loss: 1.2322\n",
      "Epoch 382/600\n",
      " - 1s - loss: 0.4232 - val_loss: 1.2322\n",
      "Epoch 383/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.2322\n",
      "Epoch 384/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.2322\n",
      "Epoch 385/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2322\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "Epoch 386/600\n",
      " - 1s - loss: 0.4235 - val_loss: 1.2322\n",
      "Epoch 387/600\n",
      " - 1s - loss: 0.4352 - val_loss: 1.2322\n",
      "Epoch 388/600\n",
      " - 1s - loss: 0.4341 - val_loss: 1.2322\n",
      "Epoch 389/600\n",
      " - 1s - loss: 0.4271 - val_loss: 1.2322\n",
      "Epoch 390/600\n",
      " - 1s - loss: 0.4445 - val_loss: 1.2322\n",
      "Epoch 391/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2322\n",
      "Epoch 392/600\n",
      " - 1s - loss: 0.4376 - val_loss: 1.2322\n",
      "Epoch 393/600\n",
      " - 1s - loss: 0.4232 - val_loss: 1.2322\n",
      "Epoch 394/600\n",
      " - 1s - loss: 0.4307 - val_loss: 1.2322\n",
      "Epoch 395/600\n",
      " - 1s - loss: 0.4258 - val_loss: 1.2322\n",
      "Epoch 396/600\n",
      " - 1s - loss: 0.4277 - val_loss: 1.2322\n",
      "Epoch 397/600\n",
      " - 1s - loss: 0.4360 - val_loss: 1.2322\n",
      "Epoch 398/600\n",
      " - 1s - loss: 0.4435 - val_loss: 1.2322\n",
      "Epoch 399/600\n",
      " - 1s - loss: 0.4313 - val_loss: 1.2322\n",
      "Epoch 400/600\n",
      " - 1s - loss: 0.4292 - val_loss: 1.2322\n",
      "Epoch 401/600\n",
      " - 1s - loss: 0.4479 - val_loss: 1.2322\n",
      "Epoch 402/600\n",
      " - 1s - loss: 0.4469 - val_loss: 1.2322\n",
      "Epoch 403/600\n",
      " - 1s - loss: 0.4339 - val_loss: 1.2322\n",
      "Epoch 404/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.2322\n",
      "Epoch 405/600\n",
      " - 1s - loss: 0.4574 - val_loss: 1.2322\n",
      "Epoch 406/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.2321\n",
      "Epoch 407/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.2322\n",
      "Epoch 408/600\n",
      " - 1s - loss: 0.4354 - val_loss: 1.2322\n",
      "Epoch 409/600\n",
      " - 1s - loss: 0.4435 - val_loss: 1.2321\n",
      "Epoch 410/600\n",
      " - 1s - loss: 0.4382 - val_loss: 1.2322\n",
      "Epoch 411/600\n",
      " - 1s - loss: 0.4251 - val_loss: 1.2322\n",
      "Epoch 412/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.2321\n",
      "Epoch 413/600\n",
      " - 1s - loss: 0.4300 - val_loss: 1.2321\n",
      "Epoch 414/600\n",
      " - 1s - loss: 0.4333 - val_loss: 1.2321\n",
      "Epoch 415/600\n",
      " - 1s - loss: 0.4313 - val_loss: 1.2322\n",
      "Epoch 416/600\n",
      " - 1s - loss: 0.4319 - val_loss: 1.2322\n",
      "Epoch 417/600\n",
      " - 1s - loss: 0.4275 - val_loss: 1.2322\n",
      "Epoch 418/600\n",
      " - 1s - loss: 0.4315 - val_loss: 1.2322\n",
      "Epoch 419/600\n",
      " - 1s - loss: 0.4317 - val_loss: 1.2322\n",
      "Epoch 420/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.2322\n",
      "Epoch 421/600\n",
      " - 1s - loss: 0.4300 - val_loss: 1.2322\n",
      "Epoch 422/600\n",
      " - 1s - loss: 0.4437 - val_loss: 1.2322\n",
      "Epoch 423/600\n",
      " - 1s - loss: 0.4355 - val_loss: 1.2322\n",
      "Epoch 424/600\n",
      " - 1s - loss: 0.4346 - val_loss: 1.2322\n",
      "Epoch 425/600\n",
      " - 1s - loss: 0.4452 - val_loss: 1.2322\n",
      "Epoch 426/600\n",
      " - 1s - loss: 0.4308 - val_loss: 1.2322\n",
      "Epoch 427/600\n",
      " - 1s - loss: 0.4489 - val_loss: 1.2322\n",
      "Epoch 428/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.2322\n",
      "Epoch 429/600\n",
      " - 1s - loss: 0.4438 - val_loss: 1.2322\n",
      "Epoch 430/600\n",
      " - 1s - loss: 0.4379 - val_loss: 1.2322\n",
      "Epoch 431/600\n",
      " - 1s - loss: 0.4368 - val_loss: 1.2322\n",
      "Epoch 432/600\n",
      " - 1s - loss: 0.4319 - val_loss: 1.2322\n",
      "Epoch 433/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.2322\n",
      "Epoch 434/600\n",
      " - 1s - loss: 0.4349 - val_loss: 1.2322\n",
      "Epoch 435/600\n",
      " - 1s - loss: 0.4399 - val_loss: 1.2322\n",
      "Epoch 436/600\n",
      " - 1s - loss: 0.4306 - val_loss: 1.2322\n",
      "Epoch 437/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1s - loss: 0.4331 - val_loss: 1.2322\n",
      "Epoch 438/600\n",
      " - 1s - loss: 0.4289 - val_loss: 1.2322\n",
      "Epoch 439/600\n",
      " - 1s - loss: 0.4369 - val_loss: 1.2322\n",
      "Epoch 440/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2322\n",
      "Epoch 441/600\n",
      " - 1s - loss: 0.4290 - val_loss: 1.2322\n",
      "Epoch 442/600\n",
      " - 1s - loss: 0.4338 - val_loss: 1.2322\n",
      "Epoch 443/600\n",
      " - 1s - loss: 0.4387 - val_loss: 1.2322\n",
      "Epoch 444/600\n",
      " - 1s - loss: 0.4405 - val_loss: 1.2322\n",
      "Epoch 445/600\n",
      " - 1s - loss: 0.4371 - val_loss: 1.2322\n",
      "Epoch 446/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2322\n",
      "Epoch 447/600\n",
      " - 1s - loss: 0.4280 - val_loss: 1.2322\n",
      "Epoch 448/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.2322\n",
      "Epoch 449/600\n",
      " - 1s - loss: 0.4249 - val_loss: 1.2322\n",
      "Epoch 450/600\n",
      " - 1s - loss: 0.4212 - val_loss: 1.2322\n",
      "Epoch 451/600\n",
      " - 1s - loss: 0.4233 - val_loss: 1.2322\n",
      "Epoch 452/600\n",
      " - 1s - loss: 0.4354 - val_loss: 1.2322\n",
      "Epoch 453/600\n",
      " - 1s - loss: 0.4379 - val_loss: 1.2322\n",
      "Epoch 454/600\n",
      " - 1s - loss: 0.4250 - val_loss: 1.2322\n",
      "Epoch 455/600\n",
      " - 1s - loss: 0.4352 - val_loss: 1.2322\n",
      "Epoch 456/600\n",
      " - 1s - loss: 0.4260 - val_loss: 1.2322\n",
      "Epoch 457/600\n",
      " - 1s - loss: 0.4352 - val_loss: 1.2322\n",
      "Epoch 458/600\n",
      " - 1s - loss: 0.4448 - val_loss: 1.2322\n",
      "Epoch 459/600\n",
      " - 1s - loss: 0.4432 - val_loss: 1.2322\n",
      "Epoch 460/600\n",
      " - 1s - loss: 0.4289 - val_loss: 1.2322\n",
      "Epoch 461/600\n",
      " - 1s - loss: 0.4348 - val_loss: 1.2322\n",
      "Epoch 462/600\n",
      " - 1s - loss: 0.4268 - val_loss: 1.2322\n",
      "Epoch 463/600\n",
      " - 1s - loss: 0.4357 - val_loss: 1.2322\n",
      "Epoch 464/600\n",
      " - 1s - loss: 0.4364 - val_loss: 1.2322\n",
      "Epoch 465/600\n",
      " - 1s - loss: 0.4322 - val_loss: 1.2322\n",
      "Epoch 466/600\n",
      " - 1s - loss: 0.4444 - val_loss: 1.2322\n",
      "Epoch 467/600\n",
      " - 1s - loss: 0.4318 - val_loss: 1.2322\n",
      "Epoch 468/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.2322\n",
      "Epoch 469/600\n",
      " - 1s - loss: 0.4487 - val_loss: 1.2322\n",
      "Epoch 470/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.2322\n",
      "Epoch 471/600\n",
      " - 1s - loss: 0.4430 - val_loss: 1.2322\n",
      "Epoch 472/600\n",
      " - 1s - loss: 0.4235 - val_loss: 1.2322\n",
      "Epoch 473/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.2322\n",
      "Epoch 474/600\n",
      " - 1s - loss: 0.4237 - val_loss: 1.2322\n",
      "Epoch 475/600\n",
      " - 1s - loss: 0.4237 - val_loss: 1.2322\n",
      "Epoch 476/600\n",
      " - 1s - loss: 0.4358 - val_loss: 1.2322\n",
      "Epoch 477/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.2322\n",
      "Epoch 478/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.2322\n",
      "Epoch 479/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.2322\n",
      "Epoch 480/600\n",
      " - 1s - loss: 0.4274 - val_loss: 1.2322\n",
      "Epoch 481/600\n",
      " - 1s - loss: 0.4266 - val_loss: 1.2322\n",
      "Epoch 482/600\n",
      " - 1s - loss: 0.4130 - val_loss: 1.2322\n",
      "Epoch 483/600\n",
      " - 1s - loss: 0.4397 - val_loss: 1.2322\n",
      "Epoch 484/600\n",
      " - 1s - loss: 0.4375 - val_loss: 1.2322\n",
      "Epoch 485/600\n",
      " - 1s - loss: 0.4231 - val_loss: 1.2322\n",
      "Epoch 486/600\n",
      " - 1s - loss: 0.4290 - val_loss: 1.2322\n",
      "Epoch 487/600\n",
      " - 1s - loss: 0.4342 - val_loss: 1.2322\n",
      "Epoch 488/600\n",
      " - 1s - loss: 0.4253 - val_loss: 1.2322\n",
      "Epoch 489/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.2322\n",
      "Epoch 490/600\n",
      " - 1s - loss: 0.4312 - val_loss: 1.2322\n",
      "Epoch 491/600\n",
      " - 1s - loss: 0.4471 - val_loss: 1.2322\n",
      "Epoch 492/600\n",
      " - 1s - loss: 0.4442 - val_loss: 1.2322\n",
      "Epoch 493/600\n",
      " - 1s - loss: 0.4331 - val_loss: 1.2322\n",
      "Epoch 494/600\n",
      " - 1s - loss: 0.4321 - val_loss: 1.2322\n",
      "Epoch 495/600\n",
      " - 1s - loss: 0.4398 - val_loss: 1.2322\n",
      "Epoch 496/600\n",
      " - 1s - loss: 0.4451 - val_loss: 1.2322\n",
      "Epoch 497/600\n",
      " - 1s - loss: 0.4475 - val_loss: 1.2322\n",
      "Epoch 498/600\n",
      " - 1s - loss: 0.4429 - val_loss: 1.2322\n",
      "Epoch 499/600\n",
      " - 1s - loss: 0.4429 - val_loss: 1.2322\n",
      "Epoch 500/600\n",
      " - 1s - loss: 0.4528 - val_loss: 1.2322\n",
      "Epoch 501/600\n",
      " - 1s - loss: 0.4350 - val_loss: 1.2322\n",
      "Epoch 502/600\n",
      " - 1s - loss: 0.4291 - val_loss: 1.2322\n",
      "Epoch 503/600\n",
      " - 1s - loss: 0.4362 - val_loss: 1.2322\n",
      "Epoch 504/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2322\n",
      "Epoch 505/600\n",
      " - 1s - loss: 0.4546 - val_loss: 1.2322\n",
      "Epoch 506/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.2322\n",
      "Epoch 507/600\n",
      " - 1s - loss: 0.4457 - val_loss: 1.2322\n",
      "Epoch 508/600\n",
      " - 1s - loss: 0.4410 - val_loss: 1.2322\n",
      "Epoch 509/600\n",
      " - 1s - loss: 0.4409 - val_loss: 1.2322\n",
      "Epoch 510/600\n",
      " - 1s - loss: 0.4276 - val_loss: 1.2322\n",
      "Epoch 511/600\n",
      " - 1s - loss: 0.4380 - val_loss: 1.2322\n",
      "Epoch 512/600\n",
      " - 1s - loss: 0.4300 - val_loss: 1.2322\n",
      "Epoch 513/600\n",
      " - 1s - loss: 0.4354 - val_loss: 1.2322\n",
      "Epoch 514/600\n",
      " - 1s - loss: 0.4162 - val_loss: 1.2322\n",
      "Epoch 515/600\n",
      " - 1s - loss: 0.4332 - val_loss: 1.2322\n",
      "Epoch 516/600\n",
      " - 1s - loss: 0.4306 - val_loss: 1.2322\n",
      "Epoch 517/600\n",
      " - 1s - loss: 0.4376 - val_loss: 1.2322\n",
      "Epoch 518/600\n",
      " - 1s - loss: 0.4285 - val_loss: 1.2322\n",
      "Epoch 519/600\n",
      " - 1s - loss: 0.4440 - val_loss: 1.2322\n",
      "Epoch 520/600\n",
      " - 1s - loss: 0.4246 - val_loss: 1.2322\n",
      "Epoch 521/600\n",
      " - 1s - loss: 0.4507 - val_loss: 1.2322\n",
      "Epoch 522/600\n",
      " - 1s - loss: 0.4290 - val_loss: 1.2322\n",
      "Epoch 523/600\n",
      " - 1s - loss: 0.4466 - val_loss: 1.2322\n",
      "Epoch 524/600\n",
      " - 1s - loss: 0.4727 - val_loss: 1.2322\n",
      "Epoch 525/600\n",
      " - 1s - loss: 0.4392 - val_loss: 1.2322\n",
      "Epoch 526/600\n",
      " - 1s - loss: 0.4370 - val_loss: 1.2322\n",
      "Epoch 527/600\n",
      " - 1s - loss: 0.4377 - val_loss: 1.2322\n",
      "Epoch 528/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.2322\n",
      "Epoch 529/600\n",
      " - 1s - loss: 0.4439 - val_loss: 1.2322\n",
      "Epoch 530/600\n",
      " - 1s - loss: 0.4401 - val_loss: 1.2322\n",
      "Epoch 531/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.2322\n",
      "Epoch 532/600\n",
      " - 1s - loss: 0.4407 - val_loss: 1.2322\n",
      "Epoch 533/600\n",
      " - 1s - loss: 0.4446 - val_loss: 1.2322\n",
      "Epoch 534/600\n",
      " - 1s - loss: 0.4328 - val_loss: 1.2322\n",
      "Epoch 535/600\n",
      " - 1s - loss: 0.4396 - val_loss: 1.2322\n",
      "Epoch 536/600\n",
      " - 1s - loss: 0.4328 - val_loss: 1.2322\n",
      "Epoch 537/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.2322\n",
      "Epoch 538/600\n",
      " - 1s - loss: 0.4329 - val_loss: 1.2322\n",
      "Epoch 539/600\n",
      " - 1s - loss: 0.4417 - val_loss: 1.2322\n",
      "Epoch 540/600\n",
      " - 1s - loss: 0.4255 - val_loss: 1.2322\n",
      "Epoch 541/600\n",
      " - 1s - loss: 0.4276 - val_loss: 1.2322\n",
      "Epoch 542/600\n",
      " - 1s - loss: 0.4230 - val_loss: 1.2322\n",
      "Epoch 543/600\n",
      " - 1s - loss: 0.4283 - val_loss: 1.2322\n",
      "Epoch 544/600\n",
      " - 1s - loss: 0.4310 - val_loss: 1.2322\n",
      "Epoch 545/600\n",
      " - 1s - loss: 0.4351 - val_loss: 1.2322\n",
      "Epoch 546/600\n",
      " - 1s - loss: 0.4379 - val_loss: 1.2322\n",
      "Epoch 547/600\n",
      " - 1s - loss: 0.4312 - val_loss: 1.2322\n",
      "Epoch 548/600\n",
      " - 1s - loss: 0.4392 - val_loss: 1.2322\n",
      "Epoch 549/600\n",
      " - 1s - loss: 0.4282 - val_loss: 1.2322\n",
      "Epoch 550/600\n",
      " - 1s - loss: 0.4245 - val_loss: 1.2322\n",
      "Epoch 551/600\n",
      " - 1s - loss: 0.4320 - val_loss: 1.2322\n",
      "Epoch 552/600\n",
      " - 1s - loss: 0.4395 - val_loss: 1.2322\n",
      "Epoch 553/600\n",
      " - 1s - loss: 0.4363 - val_loss: 1.2322\n",
      "Epoch 554/600\n",
      " - 1s - loss: 0.4363 - val_loss: 1.2322\n",
      "Epoch 555/600\n",
      " - 1s - loss: 0.4296 - val_loss: 1.2322\n",
      "Epoch 556/600\n",
      " - 1s - loss: 0.4337 - val_loss: 1.2322\n",
      "Epoch 557/600\n",
      " - 1s - loss: 0.4454 - val_loss: 1.2322\n",
      "Epoch 558/600\n",
      " - 1s - loss: 0.4400 - val_loss: 1.2322\n",
      "Epoch 559/600\n",
      " - 1s - loss: 0.4280 - val_loss: 1.2322\n",
      "Epoch 560/600\n",
      " - 1s - loss: 0.4314 - val_loss: 1.2322\n",
      "Epoch 561/600\n",
      " - 1s - loss: 0.4351 - val_loss: 1.2322\n",
      "Epoch 562/600\n",
      " - 1s - loss: 0.4352 - val_loss: 1.2322\n",
      "Epoch 563/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.2322\n",
      "Epoch 564/600\n",
      " - 1s - loss: 0.4367 - val_loss: 1.2322\n",
      "Epoch 565/600\n",
      " - 1s - loss: 0.4485 - val_loss: 1.2322\n",
      "Epoch 566/600\n",
      " - 1s - loss: 0.4355 - val_loss: 1.2322\n",
      "Epoch 567/600\n",
      " - 1s - loss: 0.4386 - val_loss: 1.2322\n",
      "Epoch 568/600\n",
      " - 1s - loss: 0.4449 - val_loss: 1.2322\n",
      "Epoch 569/600\n",
      " - 1s - loss: 0.4348 - val_loss: 1.2322\n",
      "Epoch 570/600\n",
      " - 1s - loss: 0.4361 - val_loss: 1.2322\n",
      "Epoch 571/600\n",
      " - 1s - loss: 0.4314 - val_loss: 1.2322\n",
      "Epoch 572/600\n",
      " - 1s - loss: 0.4245 - val_loss: 1.2322\n",
      "Epoch 573/600\n",
      " - 1s - loss: 0.4336 - val_loss: 1.2322\n",
      "Epoch 574/600\n",
      " - 1s - loss: 0.4514 - val_loss: 1.2322\n",
      "Epoch 575/600\n",
      " - 1s - loss: 0.4152 - val_loss: 1.2322\n",
      "Epoch 576/600\n",
      " - 1s - loss: 0.4387 - val_loss: 1.2322\n",
      "Epoch 577/600\n",
      " - 1s - loss: 0.4284 - val_loss: 1.2322\n",
      "Epoch 578/600\n",
      " - 1s - loss: 0.4286 - val_loss: 1.2322\n",
      "Epoch 579/600\n",
      " - 1s - loss: 0.4390 - val_loss: 1.2322\n",
      "Epoch 580/600\n",
      " - 1s - loss: 0.4314 - val_loss: 1.2322\n",
      "Epoch 581/600\n",
      " - 1s - loss: 0.4215 - val_loss: 1.2322\n",
      "Epoch 582/600\n",
      " - 1s - loss: 0.4330 - val_loss: 1.2322\n",
      "Epoch 583/600\n",
      " - 1s - loss: 0.4486 - val_loss: 1.2322\n",
      "Epoch 584/600\n",
      " - 1s - loss: 0.4460 - val_loss: 1.2322\n",
      "Epoch 585/600\n",
      " - 1s - loss: 0.4299 - val_loss: 1.2322\n",
      "Epoch 586/600\n",
      " - 1s - loss: 0.4404 - val_loss: 1.2322\n",
      "Epoch 587/600\n",
      " - 1s - loss: 0.4522 - val_loss: 1.2322\n",
      "Epoch 588/600\n",
      " - 1s - loss: 0.4378 - val_loss: 1.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/600\n",
      " - 1s - loss: 0.4302 - val_loss: 1.2322\n",
      "Epoch 590/600\n",
      " - 1s - loss: 0.4345 - val_loss: 1.2322\n",
      "Epoch 591/600\n",
      " - 1s - loss: 0.4356 - val_loss: 1.2322\n",
      "Epoch 592/600\n",
      " - 1s - loss: 0.4331 - val_loss: 1.2322\n",
      "Epoch 593/600\n",
      " - 1s - loss: 0.4365 - val_loss: 1.2322\n",
      "Epoch 594/600\n",
      " - 1s - loss: 0.4393 - val_loss: 1.2322\n",
      "Epoch 595/600\n",
      " - 1s - loss: 0.4372 - val_loss: 1.2322\n",
      "Epoch 596/600\n",
      " - 1s - loss: 0.4465 - val_loss: 1.2322\n",
      "Epoch 597/600\n",
      " - 1s - loss: 0.4309 - val_loss: 1.2322\n",
      "Epoch 598/600\n",
      " - 1s - loss: 0.4497 - val_loss: 1.2322\n",
      "Epoch 599/600\n",
      " - 1s - loss: 0.4281 - val_loss: 1.2322\n",
      "Epoch 600/600\n",
      " - 1s - loss: 0.4298 - val_loss: 1.2322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rdlr = ReduceLROnPlateau(patience=25, factor=0.5, min_lr=1e-6, monitor='val_loss', verbose=1)\n",
    "\n",
    "h = model.fit(X_train, y_train, epochs=600, batch_size=8, validation_split=0.2, callbacks=[rdlr], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  1.2294385384398099\n",
      "R^2:  -1.4692337033311618\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "# model evaluation\n",
    "rmse = sqrt(mean_squared_error(y_test, y_predicted))\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R^2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real, predictions]\n",
      "[[1.63 1.2509443759918213]\n",
      " [2.53 1.2520112991333008]\n",
      " [2.4 1.2502681016921997]\n",
      " [2.39 1.2502981424331665]\n",
      " [2.31 1.251228928565979]\n",
      " [1.8 1.2509185075759888]\n",
      " [2.62 1.2504569292068481]\n",
      " [4.4 1.250625491142273]\n",
      " [1.63 1.2513407468795776]\n",
      " [1.5 1.2513595819473267]\n",
      " [1.8 1.250507116317749]\n",
      " [1.38 1.2509829998016357]]\n"
     ]
    }
   ],
   "source": [
    "b=np.append(y_test, y_predicted, axis=1)\n",
    "\n",
    "print(\"[real, predictions]\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_predicted)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "y_test=np.ravel(y_test)\n",
    "print(y_test.shape)\n",
    "y_train=np.ravel(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 2300, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.07\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.08967837143067968\n",
      "R^2:  -0.12478465768656744\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"RMSE: \", rmse)\n",
    "print(\"R^2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "<class 'numpy.ndarray'>\n",
      "(4, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_test= y_test.reshape((len(y_test), 1))\n",
    "print(y_test.shape)\n",
    "print(type(y_test))\n",
    "predictions=predictions.reshape((len(y_test), 1))\n",
    "print(predictions.shape)\n",
    "print(type(y_test))\n",
    "#print((y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real, predictions]\n",
      "[[2.39 2.341160869565214]\n",
      " [2.61 2.46456086956519]\n",
      " [2.42 2.4262739130434796]\n",
      " [2.46 2.5526913043478134]]\n"
     ]
    }
   ],
   "source": [
    "b=np.append(y_test, predictions, axis=1)\n",
    "\n",
    "print(\"[real, predictions]\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predictions')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don't remember what's this\n",
    "\n",
    "#X_train = normalize(X_train, axis=1)\n",
    "#X_test = normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiOutput Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "multi_y = concentration[:,2:]\n",
    "#print (multi_y)\n",
    "print (type(multi_y))\n",
    "df_y= pd.DataFrame(multi_y)\n",
    "print (type(df_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 4094) (47, 7)\n",
      "(12, 4094) (12, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_df, df_y, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     criterion='mse',\n",
       "                                                     max_depth=30,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=150,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=0, verbose=0,\n",
       "                                                     warm_start=False),\n",
       "                     n_jobs=None)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "max_depth = 30\n",
    "regr_multirf = MultiOutputRegressor(RandomForestRegressor(n_estimators=150,\n",
    "                                                          max_depth=max_depth,\n",
    "                                                          random_state=0))\n",
    "regr_multirf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multirf = regr_multirf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 7)\n",
      "(12, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_multirf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2:  0.9081471005969817\n",
      "RMSE:  0.09092271675402586\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test, y_multirf))\n",
    "r2 = r2_score(y_test, y_multirf)\n",
    "\n",
    "print(\"R^2: \", r2)\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[real, predictions]\n",
      "[[1.8 0.17 0.48 0.37 0.022000000000000002 0.17300000000000001 0.0017 1.69\n",
      "  0.175 0.508 0.282 0.022 0.232 0.002]\n",
      " [2.53 0.13 0.13 0.09300000000000001 0.024 0.012 0.033 2.505 0.127 0.135\n",
      "  0.139 0.024 0.012 0.035]\n",
      " [4.4 0.2 0.14 0.053 0.022000000000000002 0.012 0.0468 3.652 0.178 0.177\n",
      "  0.07 0.022 0.014 0.047]\n",
      " [2.54 0.16 1.13 0.095 0.027000000000000003 0.027000000000000003 0.0568\n",
      "  2.54 0.171 1.111 0.139 0.026 0.022 0.054]\n",
      " [1.59 0.14 0.32 0.06 0.024 0.016 0.001 1.563 0.134 0.256 0.085 0.023\n",
      "  0.015 0.002]\n",
      " [1.5 0.12 0.09 0.04 0.021 0.009000000000000001 0.0009 1.572 0.138 0.231\n",
      "  0.061 0.022 0.016 0.003]\n",
      " [2.49 0.12 0.13 0.11 0.024 0.012 0.036000000000000004 2.522 0.129 0.138\n",
      "  0.102 0.024 0.013 0.042]\n",
      " [2.48 0.12 0.13 0.052000000000000005 0.024 0.012 0.03 2.531 0.134 0.194\n",
      "  0.1 0.024 0.03 0.044]\n",
      " [2.39 0.2 0.65 1.1 0.021 0.267 0.0542 2.426 0.191 0.631 0.987 0.022\n",
      "  0.266 0.048]\n",
      " [1.5 0.12 0.09 0.04 0.021 0.009000000000000001 0.0009 1.558 0.151 0.267\n",
      "  0.062 0.022 0.017 0.003]\n",
      " [1.84 0.19 0.64 0.42 0.022000000000000002 0.26899999999999996 0.0024\n",
      "  1.797 0.21 0.644 0.484 0.022 0.255 0.009]\n",
      " [1.63 0.12 0.11 0.09 0.019 0.019 0.0022 1.582 0.127 0.145 0.092 0.019\n",
      "  0.015 0.002]]\n"
     ]
    }
   ],
   "source": [
    "b=np.append(np.around(y_test,3), np.around(y_multirf,3), axis=1)\n",
    "\n",
    "print(\"[real, predictions]\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predictions')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test, y_multirf)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(0, slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-151-fe8b5edafebb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_multirf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[real, predictions]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_index_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"get_indexer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 )\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(0, slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "b=np.append(y_test[0,:],y_multirf[0,:], axis=1)\n",
    "\n",
    "print(\"[real, predictions]\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0]shape)\n",
    "print(y_multirf[0].T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.69, 2.51, 3.65, 2.54, 1.56, 1.57, 2.52, 2.53, 2.43, 1.56, 1.8 ,\n",
       "       1.58])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=np.around(y_multirf,2)\n",
    "y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.8, 2.53, 4.4, 2.54, 1.59, 1.5, 2.49, 2.48, 2.39, 1.5, 1.84, 1.63],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real:  [1.8 2.53 4.4 2.54 1.59 1.5 2.49 2.48 2.39 1.5 1.84 1.63]\n",
      "pred:  [1.69 2.51 3.65 2.54 1.56 1.57 2.52 2.53 2.43 1.56 1.8  1.58]\n"
     ]
    }
   ],
   "source": [
    "print(\"real: \", y_test[0].values)\n",
    "print(\"pred: \", y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
